JUnit version 4.12
.2023-05-30 19:58:12,700 - DEBUG [main:Reflections@198] - going to scan these urls: [file:/home/tonypan/flaky-reproduction/systems/cassandra-17663/build/classes/fqltool/, jar:file:/home/tonypan/flaky-reproduction/systems/cassandra-17663/build/test/lib/jars/dtest-api-0.0.13.jar!/, file:/home/tonypan/flaky-reproduction/systems/cassandra-17663/build/classes/main/, file:/home/tonypan/flaky-reproduction/systems/cassandra-17663/build/test/classes/, file:/home/tonypan/flaky-reproduction/systems/cassandra-17663/build/classes/stress/]
2023-05-30 19:58:13,346 - INFO  [main:Reflections@239] - Reflections took 636 ms to scan 5 urls, producing 1405 keys and 5115 values 
2023-05-30 19:58:13,353 - DEBUG [main:Reflections@198] - going to scan these urls: [file:/home/tonypan/flaky-reproduction/systems/cassandra-17663/build/classes/fqltool/, jar:file:/home/tonypan/flaky-reproduction/systems/cassandra-17663/build/test/lib/jars/dtest-api-0.0.13.jar!/, file:/home/tonypan/flaky-reproduction/systems/cassandra-17663/build/classes/main/, file:/home/tonypan/flaky-reproduction/systems/cassandra-17663/build/test/classes/, file:/home/tonypan/flaky-reproduction/systems/cassandra-17663/build/classes/stress/]
2023-05-30 19:58:13,842 - INFO  [main:Reflections@239] - Reflections took 487 ms to scan 5 urls, producing 1405 keys and 5115 values 
Node id topology:
node 1: dc = datacenter0, rack = rack0
node 2: dc = datacenter0, rack = rack0
node 3: dc = datacenter0, rack = rack0
Configured node count: 3, nodeIdTopology size: 3
2023-05-30 19:58:15,237 - DEBUG [node1_isolatedExecutor:1:DatabaseDescriptor@384] - Syncing log with batch mode
2023-05-30 19:58:15,240 - INFO  [node1_isolatedExecutor:1:DatabaseDescriptor@422] - DiskAccessMode is standard, indexAccessMode is mmap
2023-05-30 19:58:15,242 - INFO  [node1_isolatedExecutor:1:DatabaseDescriptor@477] - Global memtable on-heap threshold is enabled at 10MB
2023-05-30 19:58:15,242 - INFO  [node1_isolatedExecutor:1:DatabaseDescriptor@481] - Global memtable off-heap threshold is enabled at 1762MB
2023-05-30 19:58:15,293 - DEBUG [node1_isolatedExecutor:1:SSLFactory@384] - Initializing hot reloading SSLContext
2023-05-30 19:58:15,335 - DEBUG [node1_isolatedExecutor:1:InternalLoggerFactory@63] - Using SLF4J as the default logging framework
2023-05-30 19:58:15,336 - DEBUG [node1_isolatedExecutor:1:InternalThreadLocalMap@83] - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2023-05-30 19:58:15,336 - DEBUG [node1_isolatedExecutor:1:InternalThreadLocalMap@86] - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2023-05-30 19:58:15,381 - INFO  [node1_ScheduledTasks:1:StorageService@159] - Overriding RING_DELAY to 15000ms
2023-05-30 19:58:15,389 - INFO  [node1_isolatedExecutor:1:MonotonicClock$AbstractEpochSamplingClock@202] - Scheduling approximate time conversion task with an interval of 10000 milliseconds
2023-05-30 19:58:15,390 - INFO  [node1_isolatedExecutor:1:MonotonicClock$SampledClock@338] - Scheduling approximate time-check task with a precision of 2 milliseconds
2023-05-30 19:58:15,391 - WARN  [node1_isolatedExecutor:1:StartupChecks$1@143] - jemalloc shared library could not be preloaded to speed up memory allocations
2023-05-30 19:58:15,391 - WARN  [node1_isolatedExecutor:1:StartupChecks$1@143] - jemalloc shared library could not be preloaded to speed up memory allocations
2023-05-30 19:58:15,788 - WARN  [node1_isolatedExecutor:1:StartupChecks$3@187] - JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.
2023-05-30 19:58:15,788 - WARN  [node1_isolatedExecutor:1:StartupChecks$3@187] - JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.
2023-05-30 19:58:15,788 - ERROR [node1_isolatedExecutor:1:StartupChecks$3@190] - cassandra.jmx.local.port missing from cassandra-env.sh, unable to start local JMX service.
2023-05-30 19:58:15,788 - ERROR [node1_isolatedExecutor:1:StartupChecks$3@190] - cassandra.jmx.local.port missing from cassandra-env.sh, unable to start local JMX service.
2023-05-30 19:58:15,789 - WARN  [node1_isolatedExecutor:1:StartupChecks$5@238] - The JVM is not configured to stop on OutOfMemoryError which can cause data corruption. Use one of the following JVM options to configure the behavior on OutOfMemoryError:  -XX:+ExitOnOutOfMemoryError, -XX:+CrashOnOutOfMemoryError, or -XX:OnOutOfMemoryError="<cmd args>;<cmd args>"
2023-05-30 19:58:15,789 - WARN  [node1_isolatedExecutor:1:StartupChecks$5@238] - The JVM is not configured to stop on OutOfMemoryError which can cause data corruption. Use one of the following JVM options to configure the behavior on OutOfMemoryError:  -XX:+ExitOnOutOfMemoryError, -XX:+CrashOnOutOfMemoryError, or -XX:OnOutOfMemoryError="<cmd args>;<cmd args>"
2023-05-30 19:58:15,790 - INFO  [node1_isolatedExecutor:1:SigarLibrary@44] - Initializing SIGAR library
2023-05-30 19:58:15,801 - DEBUG [node1_isolatedExecutor:1:SigarLog@60] - no libsigar-amd64-linux.so in java.library.path
org.hyperic.sigar.SigarException: no libsigar-amd64-linux.so in java.library.path
	at org.hyperic.sigar.Sigar.loadLibrary(Sigar.java:172)
	at org.hyperic.sigar.Sigar.<clinit>(Sigar.java:100)
	at org.apache.cassandra.utils.SigarLibrary.<init>(SigarLibrary.java:47)
	at org.apache.cassandra.utils.SigarLibrary.<clinit>(SigarLibrary.java:28)
	at org.apache.cassandra.service.StartupChecks$7.execute(StartupChecks.java:284)
	at org.apache.cassandra.service.StartupChecks.verify(StartupChecks.java:132)
	at org.apache.cassandra.service.CassandraDaemon.runStartupChecks(CassandraDaemon.java:489)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:486)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:15,803 - INFO  [node1_isolatedExecutor:1:SigarLibrary@57] - Could not initialize SIGAR library org.hyperic.sigar.Sigar.getFileSystemListNative()[Lorg/hyperic/sigar/FileSystem; 
2023-05-30 19:58:15,803 - INFO  [node1_isolatedExecutor:1:SigarLibrary@185] - Sigar could not be initialized, test for checking degraded mode omitted.
2023-05-30 19:58:15,804 - WARN  [node1_isolatedExecutor:1:StartupChecks$8@329] - Maximum number of memory map areas per process (vm.max_map_count) 65530 is too low, recommended value: 1048575, you can change it with sysctl.
2023-05-30 19:58:15,804 - WARN  [node1_isolatedExecutor:1:StartupChecks$8@329] - Maximum number of memory map areas per process (vm.max_map_count) 65530 is too low, recommended value: 1048575, you can change it with sysctl.
2023-05-30 19:58:15,809 - DEBUG [node1_isolatedExecutor:1:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node1/data0
2023-05-30 19:58:15,811 - DEBUG [node1_isolatedExecutor:1:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node1/data1
2023-05-30 19:58:15,812 - DEBUG [node1_isolatedExecutor:1:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node1/data2
2023-05-30 19:58:15,812 - DEBUG [node1_isolatedExecutor:1:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node1/commitlog
2023-05-30 19:58:15,812 - DEBUG [node1_isolatedExecutor:1:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node1/saved_caches
2023-05-30 19:58:15,812 - DEBUG [node1_isolatedExecutor:1:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node1/hints
2023-05-30 19:58:16,140 - INFO  [node1_isolatedExecutor:1:Keyspace@386] - Creating replication strategy system params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.LocalStrategy}}
2023-05-30 19:58:16,151 - DEBUG [node1_isolatedExecutor:1:Keyspace@390] - New replication settings for keyspace system - invalidating disk boundary caches
2023-05-30 19:58:16,166 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.IndexInfo
2023-05-30 19:58:16,726 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.IndexInfo
2023-05-30 19:58:16,734 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,735 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.IndexInfo
2023-05-30 19:58:16,763 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.batches
2023-05-30 19:58:16,766 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.paxos
2023-05-30 19:58:16,767 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.paxos
2023-05-30 19:58:16,767 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,767 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system.paxos
2023-05-30 19:58:16,771 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.local
2023-05-30 19:58:16,772 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.local
2023-05-30 19:58:16,772 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,772 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.local
2023-05-30 19:58:16,774 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.peers_v2
2023-05-30 19:58:16,774 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peers_v2
2023-05-30 19:58:16,775 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,775 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.peers_v2
2023-05-30 19:58:16,777 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.peers
2023-05-30 19:58:16,777 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peers
2023-05-30 19:58:16,777 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,777 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.peers
2023-05-30 19:58:16,779 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.peer_events_v2
2023-05-30 19:58:16,780 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peer_events_v2
2023-05-30 19:58:16,780 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,780 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.peer_events_v2
2023-05-30 19:58:16,782 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.peer_events
2023-05-30 19:58:16,782 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peer_events
2023-05-30 19:58:16,782 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,783 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.peer_events
2023-05-30 19:58:16,785 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.compaction_history
2023-05-30 19:58:16,785 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.compaction_history
2023-05-30 19:58:16,785 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,786 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system.compaction_history
2023-05-30 19:58:16,788 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.sstable_activity
2023-05-30 19:58:16,788 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.sstable_activity
2023-05-30 19:58:16,788 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,789 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.sstable_activity
2023-05-30 19:58:16,790 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.size_estimates
2023-05-30 19:58:16,791 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.size_estimates
2023-05-30 19:58:16,791 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,791 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.size_estimates
2023-05-30 19:58:16,793 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.table_estimates
2023-05-30 19:58:16,793 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.table_estimates
2023-05-30 19:58:16,793 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,793 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.table_estimates
2023-05-30 19:58:16,795 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.available_ranges_v2
2023-05-30 19:58:16,796 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.available_ranges_v2
2023-05-30 19:58:16,796 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,796 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.available_ranges_v2
2023-05-30 19:58:16,798 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.available_ranges
2023-05-30 19:58:16,798 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.available_ranges
2023-05-30 19:58:16,798 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,799 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.available_ranges
2023-05-30 19:58:16,800 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.transferred_ranges_v2
2023-05-30 19:58:16,801 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.transferred_ranges_v2
2023-05-30 19:58:16,801 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,801 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.transferred_ranges_v2
2023-05-30 19:58:16,803 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.transferred_ranges
2023-05-30 19:58:16,803 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.transferred_ranges
2023-05-30 19:58:16,804 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,804 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.transferred_ranges
2023-05-30 19:58:16,806 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.view_builds_in_progress
2023-05-30 19:58:16,806 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.view_builds_in_progress
2023-05-30 19:58:16,806 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,806 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.view_builds_in_progress
2023-05-30 19:58:16,808 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.built_views
2023-05-30 19:58:16,808 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.built_views
2023-05-30 19:58:16,809 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,809 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.built_views
2023-05-30 19:58:16,811 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.prepared_statements
2023-05-30 19:58:16,811 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.prepared_statements
2023-05-30 19:58:16,812 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,812 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system.prepared_statements
2023-05-30 19:58:16,814 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system.repairs
2023-05-30 19:58:16,815 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.repairs
2023-05-30 19:58:16,815 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:16,815 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system.repairs
2023-05-30 19:58:16,973 - INFO  [node1_isolatedExecutor:1:QueryProcessor@115] - Initialized prepared statement caches with 27 MB
2023-05-30 19:58:17,043 - INFO  [node1_isolatedExecutor:1:Keyspace@386] - Creating replication strategy system_schema params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.LocalStrategy}}
2023-05-30 19:58:17,043 - DEBUG [node1_isolatedExecutor:1:Keyspace@390] - New replication settings for keyspace system_schema - invalidating disk boundary caches
2023-05-30 19:58:17,045 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system_schema.keyspaces
2023-05-30 19:58:17,045 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.keyspaces
2023-05-30 19:58:17,045 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,045 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.keyspaces
2023-05-30 19:58:17,047 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system_schema.tables
2023-05-30 19:58:17,048 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.tables
2023-05-30 19:58:17,048 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,048 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.tables
2023-05-30 19:58:17,050 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system_schema.columns
2023-05-30 19:58:17,050 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.columns
2023-05-30 19:58:17,050 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,050 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.columns
2023-05-30 19:58:17,052 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system_schema.triggers
2023-05-30 19:58:17,052 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.triggers
2023-05-30 19:58:17,052 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,053 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.triggers
2023-05-30 19:58:17,054 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system_schema.dropped_columns
2023-05-30 19:58:17,055 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.dropped_columns
2023-05-30 19:58:17,055 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,055 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.dropped_columns
2023-05-30 19:58:17,057 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system_schema.views
2023-05-30 19:58:17,057 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.views
2023-05-30 19:58:17,058 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,058 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.views
2023-05-30 19:58:17,059 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system_schema.types
2023-05-30 19:58:17,060 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.types
2023-05-30 19:58:17,060 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,060 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.types
2023-05-30 19:58:17,061 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system_schema.functions
2023-05-30 19:58:17,062 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.functions
2023-05-30 19:58:17,062 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,062 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.functions
2023-05-30 19:58:17,064 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system_schema.aggregates
2023-05-30 19:58:17,064 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.aggregates
2023-05-30 19:58:17,064 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,064 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.aggregates
2023-05-30 19:58:17,066 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@385] - Initializing system_schema.indexes
2023-05-30 19:58:17,066 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.indexes
2023-05-30 19:58:17,066 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,066 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.indexes
2023-05-30 19:58:17,108 - INFO  [node1_isolatedExecutor:1:SystemKeyspaceMigrator40@76] - system.peers_v2 table was empty, migrating legacy system.peers, if this fails you should fix the issue and then truncate system.peers_v2 to have it try again.
2023-05-30 19:58:17,112 - INFO  [node1_isolatedExecutor:1:SystemKeyspaceMigrator40@100] - Migrating rows from legacy system.peers to system.peers_v2
2023-05-30 19:58:17,115 - INFO  [node1_isolatedExecutor:1:SystemKeyspaceMigrator40@119] - Migrated 0 rows from legacy system.peers to system.peers_v2
2023-05-30 19:58:17,115 - INFO  [node1_isolatedExecutor:1:SystemKeyspaceMigrator40@129] - system.peer_events_v2 table was empty, migrating legacy system.peer_events to system.peer_events_v2
2023-05-30 19:58:17,116 - INFO  [node1_isolatedExecutor:1:SystemKeyspaceMigrator40@152] - Migrated 0 rows from legacy system.peer_events to system.peer_events_v2
2023-05-30 19:58:17,116 - INFO  [node1_isolatedExecutor:1:SystemKeyspaceMigrator40@162] - system.transferred_ranges_v2 table was empty, migrating legacy system.transferred_ranges to system.transferred_ranges_v2
2023-05-30 19:58:17,117 - INFO  [node1_isolatedExecutor:1:SystemKeyspaceMigrator40@190] - Migrated 0 rows from legacy system.transferred_ranges to system.transferred_ranges_v2
2023-05-30 19:58:17,117 - INFO  [node1_isolatedExecutor:1:SystemKeyspaceMigrator40@200] - system.available_ranges_v2 table was empty, migrating legacy system.available_ranges to system.available_ranges_v2
2023-05-30 19:58:17,118 - INFO  [node1_isolatedExecutor:1:SystemKeyspaceMigrator40@226] - Migrated 0 rows from legacy system.available_ranges to system.available_ranges_v2
2023-05-30 19:58:17,118 - INFO  [node1_isolatedExecutor:1:StorageService@838] - Populating token metadata from system tables
2023-05-30 19:58:17,126 - INFO  [node1_isolatedExecutor:1:StorageService@832] - Token metadata: 
2023-05-30 19:58:17,144 - INFO  [node1_isolatedExecutor:1:CommitLog@168] - No commitlog files found; skipping replay
2023-05-30 19:58:17,144 - INFO  [node1_isolatedExecutor:1:StorageService@838] - Populating token metadata from system tables
2023-05-30 19:58:17,145 - INFO  [node1_isolatedExecutor:1:StorageService@832] - Token metadata: 
2023-05-30 19:58:17,178 - WARN  [node1_isolatedExecutor:1:NativeTransportService@165] - epoll not available
java.lang.UnsupportedOperationException: Native transport was explicit disabled with -Dio.netty.transport.noNative=true
	at io.netty.channel.epoll.Epoll.<clinit>(Epoll.java:33)
	at org.apache.cassandra.service.NativeTransportService.useEpoll(NativeTransportService.java:164)
	at org.apache.cassandra.net.SocketFactory$Provider.optimalProvider(SocketFactory.java:164)
	at org.apache.cassandra.net.SocketFactory.<init>(SocketFactory.java:185)
	at org.apache.cassandra.net.MessagingService.<init>(MessagingService.java:234)
	at org.apache.cassandra.net.MessagingService$MSHandle.<clinit>(MessagingService.java:226)
	at org.apache.cassandra.net.MessagingService.instance(MessagingService.java:231)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:529)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:17,178 - WARN  [node1_isolatedExecutor:1:NativeTransportService@165] - epoll not available
java.lang.UnsupportedOperationException: Native transport was explicit disabled with -Dio.netty.transport.noNative=true
	at io.netty.channel.epoll.Epoll.<clinit>(Epoll.java:33)
	at org.apache.cassandra.service.NativeTransportService.useEpoll(NativeTransportService.java:164)
	at org.apache.cassandra.net.SocketFactory$Provider.optimalProvider(SocketFactory.java:164)
	at org.apache.cassandra.net.SocketFactory.<init>(SocketFactory.java:185)
	at org.apache.cassandra.net.MessagingService.<init>(MessagingService.java:234)
	at org.apache.cassandra.net.MessagingService$MSHandle.<clinit>(MessagingService.java:226)
	at org.apache.cassandra.net.MessagingService.instance(MessagingService.java:231)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:529)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:17,178 - DEBUG [node1_isolatedExecutor:1:SocketFactory$Provider@154] - using netty NIO event loop for pool prefix Messaging-AcceptLoop
2023-05-30 19:58:17,183 - DEBUG [node1_isolatedExecutor:1:MultithreadEventLoopGroup@44] - -Dio.netty.eventLoopThreads: 40
2023-05-30 19:58:17,202 - DEBUG [node1_isolatedExecutor:1:NioEventLoop@106] - -Dio.netty.noKeySetOptimization: false
2023-05-30 19:58:17,202 - DEBUG [node1_isolatedExecutor:1:NioEventLoop@107] - -Dio.netty.selectorAutoRebuildThreshold: 512
2023-05-30 19:58:17,218 - DEBUG [node1_isolatedExecutor:1:PlatformDependent0@417] - -Dio.netty.noUnsafe: false
2023-05-30 19:58:17,218 - DEBUG [node1_isolatedExecutor:1:PlatformDependent0@897] - Java version: 8
2023-05-30 19:58:17,218 - DEBUG [node1_isolatedExecutor:1:PlatformDependent0@130] - sun.misc.Unsafe.theUnsafe: available
2023-05-30 19:58:17,219 - DEBUG [node1_isolatedExecutor:1:PlatformDependent0@154] - sun.misc.Unsafe.copyMemory: available
2023-05-30 19:58:17,219 - DEBUG [node1_isolatedExecutor:1:PlatformDependent0@192] - java.nio.Buffer.address: available
2023-05-30 19:58:17,220 - DEBUG [node1_isolatedExecutor:1:PlatformDependent0@257] - direct buffer constructor: available
2023-05-30 19:58:17,220 - DEBUG [node1_isolatedExecutor:1:PlatformDependent0@331] - java.nio.Bits.unaligned: available, true
2023-05-30 19:58:17,221 - DEBUG [node1_isolatedExecutor:1:PlatformDependent0@396] - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2023-05-30 19:58:17,221 - DEBUG [node1_isolatedExecutor:1:PlatformDependent0@403] - java.nio.DirectByteBuffer.<init>(long, int): available
2023-05-30 19:58:17,221 - DEBUG [node1_isolatedExecutor:1:PlatformDependent@1079] - sun.misc.Unsafe: available
2023-05-30 19:58:17,221 - DEBUG [node1_isolatedExecutor:1:PlatformDependent@1200] - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
2023-05-30 19:58:17,221 - DEBUG [node1_isolatedExecutor:1:PlatformDependent@1279] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2023-05-30 19:58:17,222 - DEBUG [node1_isolatedExecutor:1:PlatformDependent@177] - -Dio.netty.maxDirectMemory: 7393509376 bytes
2023-05-30 19:58:17,222 - DEBUG [node1_isolatedExecutor:1:PlatformDependent@184] - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2023-05-30 19:58:17,223 - DEBUG [node1_isolatedExecutor:1:CleanerJava6@92] - java.nio.ByteBuffer.cleaner(): available
2023-05-30 19:58:17,223 - DEBUG [node1_isolatedExecutor:1:PlatformDependent@204] - -Dio.netty.noPreferDirect: false
2023-05-30 19:58:17,225 - DEBUG [node1_isolatedExecutor:1:SocketFactory$Provider@154] - using netty NIO event loop for pool prefix node1_Messaging-EventLoop
2023-05-30 19:58:17,226 - DEBUG [node1_isolatedExecutor:1:SocketFactory$Provider@154] - using netty NIO event loop for pool prefix Streaming-EventLoop
2023-05-30 19:58:17,241 - INFO  [node1_isolatedExecutor:1:InboundConnectionInitiator@127] - Listening on address: (/127.0.0.1:7012), nic: lo, encryption: unencrypted
2023-05-30 19:58:17,260 - DEBUG [node1_isolatedExecutor:1:ResourceLeakDetector@129] - -Dio.netty.leakDetection.level: simple
2023-05-30 19:58:17,260 - DEBUG [node1_isolatedExecutor:1:ResourceLeakDetector@130] - -Dio.netty.leakDetection.targetRecords: 4
2023-05-30 19:58:17,265 - INFO  [node1_isolatedExecutor:1:BufferPools@49] - Global buffer pool limit is 512.000MiB for chunk-cache and 128.000MiB for networking
2023-05-30 19:58:17,271 - DEBUG [node1_isolatedExecutor:1:DefaultChannelId@79] - -Dio.netty.processId: 23968 (auto-detected)
2023-05-30 19:58:17,273 - DEBUG [node1_isolatedExecutor:1:NetUtil@135] - -Djava.net.preferIPv4Stack: false
2023-05-30 19:58:17,273 - DEBUG [node1_isolatedExecutor:1:NetUtil@136] - -Djava.net.preferIPv6Addresses: false
2023-05-30 19:58:17,274 - DEBUG [node1_isolatedExecutor:1:NetUtilInitializations@129] - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2023-05-30 19:58:17,275 - DEBUG [node1_isolatedExecutor:1:NetUtil$1@169] - /proc/sys/net/core/somaxconn: 128
2023-05-30 19:58:17,276 - DEBUG [node1_isolatedExecutor:1:DefaultChannelId@101] - -Dio.netty.machineId: f8:f2:1e:ff:fe:32:be:a1 (auto-detected)
2023-05-30 19:58:17,295 - DEBUG [node1_isolatedExecutor:1:PooledByteBufAllocator@154] - -Dio.netty.allocator.numHeapArenas: 40
2023-05-30 19:58:17,296 - DEBUG [node1_isolatedExecutor:1:PooledByteBufAllocator@155] - -Dio.netty.allocator.numDirectArenas: 40
2023-05-30 19:58:17,296 - DEBUG [node1_isolatedExecutor:1:PooledByteBufAllocator@157] - -Dio.netty.allocator.pageSize: 8192
2023-05-30 19:58:17,296 - DEBUG [node1_isolatedExecutor:1:PooledByteBufAllocator@162] - -Dio.netty.allocator.maxOrder: 11
2023-05-30 19:58:17,296 - DEBUG [node1_isolatedExecutor:1:PooledByteBufAllocator@166] - -Dio.netty.allocator.chunkSize: 16777216
2023-05-30 19:58:17,296 - DEBUG [node1_isolatedExecutor:1:PooledByteBufAllocator@167] - -Dio.netty.allocator.smallCacheSize: 256
2023-05-30 19:58:17,296 - DEBUG [node1_isolatedExecutor:1:PooledByteBufAllocator@168] - -Dio.netty.allocator.normalCacheSize: 64
2023-05-30 19:58:17,296 - DEBUG [node1_isolatedExecutor:1:PooledByteBufAllocator@169] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2023-05-30 19:58:17,296 - DEBUG [node1_isolatedExecutor:1:PooledByteBufAllocator@170] - -Dio.netty.allocator.cacheTrimInterval: 8192
2023-05-30 19:58:17,296 - DEBUG [node1_isolatedExecutor:1:PooledByteBufAllocator@171] - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2023-05-30 19:58:17,296 - DEBUG [node1_isolatedExecutor:1:PooledByteBufAllocator@172] - -Dio.netty.allocator.useCacheForAllThreads: true
2023-05-30 19:58:17,296 - DEBUG [node1_isolatedExecutor:1:PooledByteBufAllocator@173] - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2023-05-30 19:58:17,306 - DEBUG [node1_isolatedExecutor:1:ByteBufUtil@87] - -Dio.netty.allocator.type: pooled
2023-05-30 19:58:17,306 - DEBUG [node1_isolatedExecutor:1:ByteBufUtil@96] - -Dio.netty.threadLocalDirectBufferSize: 0
2023-05-30 19:58:17,306 - DEBUG [node1_isolatedExecutor:1:ByteBufUtil@99] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2023-05-30 19:58:17,323 - INFO  [node1_isolatedExecutor:1:StorageService@736] - Cassandra version: 4.0.5-SNAPSHOT
2023-05-30 19:58:17,324 - INFO  [node1_isolatedExecutor:1:StorageService@737] - CQL version: 3.4.5
2023-05-30 19:58:17,324 - INFO  [node1_isolatedExecutor:1:StorageService@738] - Native protocol supported versions: 3/v3, 4/v4, 5/v5, 6/v6-beta (default: 5/v5)
2023-05-30 19:58:17,440 - INFO  [node1_isolatedExecutor:1:IndexSummaryManager@84] - Initializing index summary manager with a memory pool size of 50 MB and a resize interval of 60 minutes
2023-05-30 19:58:17,440 - INFO  [node1_isolatedExecutor:1:StorageService@755] - Loading persisted ring state
2023-05-30 19:58:17,440 - INFO  [node1_isolatedExecutor:1:StorageService@838] - Populating token metadata from system tables
2023-05-30 19:58:17,446 - WARN  [node1_isolatedExecutor:1:SystemKeyspace@1130] - No host ID found, created 1b66b46a-f0cf-4ab8-a790-4a8d025fd5f0 (Note: This should happen exactly once per node).
2023-05-30 19:58:17,446 - WARN  [node1_isolatedExecutor:1:SystemKeyspace@1130] - No host ID found, created 1b66b46a-f0cf-4ab8-a790-4a8d025fd5f0 (Note: This should happen exactly once per node).
2023-05-30 19:58:17,447 - DEBUG [node1_isolatedExecutor:1:StorageService@649] - Starting shadow gossip round to check for endpoint collision
2023-05-30 19:58:17,448 - INFO  [node1_isolatedExecutor:1:StorageService@653] - Unable to gossip with any peers but continuing anyway since node is in its own seed list
2023-05-30 19:58:17,451 - INFO  [node1_isolatedExecutor:1:StorageService@960] - Starting up server gossip
2023-05-30 19:58:17,453 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of local: 2.338KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:17,510 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-local@1821220653(0.426KiB serialized bytes, 4 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:17,512 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-1-big-Data.db (0.218KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=653)
2023-05-30 19:58:17,580 - INFO  [node1_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb_txn_flush_d8ddbc30-ff45-11ed-bc52-8b144d1e6fed.log 
2023-05-30 19:58:17,582 - INFO  [node1_MemtableFlushWriter:1:CacheService@103] - Initializing key cache with capacity of 50 MBs.
2023-05-30 19:58:17,588 - INFO  [node1_MemtableFlushWriter:1:CacheService@125] - Initializing row cache with capacity of 0 MBs
2023-05-30 19:58:17,589 - INFO  [node1_MemtableFlushWriter:1:CacheService@154] - Initializing counter cache with capacity of 50 MBs
2023-05-30 19:58:17,590 - INFO  [node1_MemtableFlushWriter:1:CacheService@165] - Scheduling counter cache save to every 7200 seconds (going to save all keys).
2023-05-30 19:58:17,605 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-1-big-Data.db')] (1 sstables, 5.865KiB), biggest 5.865KiB, smallest 5.865KiB
2023-05-30 19:58:17,610 - DEBUG [node1_isolatedExecutor:1:StorageService@2399] - Ignoring application state INTERNAL_ADDRESS_AND_PORT from /127.0.0.1:7012 because it is not a member in token metadata
2023-05-30 19:58:17,610 - DEBUG [node1_isolatedExecutor:1:StorageService@2399] - Ignoring application state INTERNAL_IP from /127.0.0.1:7012 because it is not a member in token metadata
2023-05-30 19:58:17,611 - DEBUG [node1_isolatedExecutor:1:StorageService@2399] - Ignoring application state DC from /127.0.0.1:7012 because it is not a member in token metadata
2023-05-30 19:58:17,611 - DEBUG [node1_isolatedExecutor:1:StorageService@2399] - Ignoring application state RACK from /127.0.0.1:7012 because it is not a member in token metadata
2023-05-30 19:58:17,613 - DEBUG [node1_isolatedExecutor:1:StorageService@2399] - Ignoring application state SCHEMA from /127.0.0.1:7012 because it is not a member in token metadata
2023-05-30 19:58:17,643 - DEBUG [node1_isolatedExecutor:1:StorageService@1042] - Bootstrap variables: false false false true
2023-05-30 19:58:17,646 - INFO  [node1_isolatedExecutor:1:BootStrapper@194] - tokens manually specified as [-3074457345618258603]
2023-05-30 19:58:17,689 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of columns: 43.419KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:17,692 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-columns@2137911673(9.073KiB serialized bytes, 59 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:17,695 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-1-big-Data.db (4.347KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=11295)
2023-05-30 19:58:17,758 - INFO  [node1_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node1/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb_txn_flush_d900d490-ff45-11ed-bc52-8b144d1e6fed.log 
2023-05-30 19:58:17,759 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-1-big-Data.db')] (1 sstables, 6.835KiB), biggest 6.835KiB, smallest 6.835KiB
2023-05-30 19:58:17,760 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in dropped_columns
2023-05-30 19:58:17,761 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in triggers
2023-05-30 19:58:17,761 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in types
2023-05-30 19:58:17,761 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in functions
2023-05-30 19:58:17,761 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in aggregates
2023-05-30 19:58:17,761 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in indexes
2023-05-30 19:58:17,761 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of tables: 23.657KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:17,764 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-tables@456688298(7.291KiB serialized bytes, 10 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:17,765 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-1-big-Data.db (4.543KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=11295)
2023-05-30 19:58:17,831 - INFO  [node1_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node1/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb_txn_flush_d90bf820-ff45-11ed-bc52-8b144d1e6fed.log 
2023-05-30 19:58:17,831 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-1-big-Data.db')] (1 sstables, 7.638KiB), biggest 7.638KiB, smallest 7.638KiB
2023-05-30 19:58:17,832 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in views
2023-05-30 19:58:17,832 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of keyspaces: 1.931KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:17,834 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-keyspaces@1074029240(0.437KiB serialized bytes, 3 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:17,835 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-1-big-Data.db (0.363KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=11295)
2023-05-30 19:58:17,902 - INFO  [node1_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node1/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb_txn_flush_d916a680-ff45-11ed-bc52-8b144d1e6fed.log 
2023-05-30 19:58:17,903 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-1-big-Data.db')] (1 sstables, 5.267KiB), biggest 5.267KiB, smallest 5.267KiB
2023-05-30 19:58:17,952 - INFO  [node1_MigrationStage:1:Keyspace@386] - Creating replication strategy system_auth params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}
2023-05-30 19:58:17,953 - DEBUG [node1_MigrationStage:1:Keyspace@390] - New replication settings for keyspace system_auth - invalidating disk boundary caches
2023-05-30 19:58:17,954 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.network_permissions
2023-05-30 19:58:17,955 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.network_permissions
2023-05-30 19:58:17,955 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,955 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.network_permissions
2023-05-30 19:58:17,958 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.resource_role_permissons_index
2023-05-30 19:58:17,958 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.resource_role_permissons_index
2023-05-30 19:58:17,958 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,958 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.resource_role_permissons_index
2023-05-30 19:58:17,960 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.role_members
2023-05-30 19:58:17,961 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.role_members
2023-05-30 19:58:17,961 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,961 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.role_members
2023-05-30 19:58:17,963 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.role_permissions
2023-05-30 19:58:17,963 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.role_permissions
2023-05-30 19:58:17,963 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,964 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.role_permissions
2023-05-30 19:58:17,965 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.roles
2023-05-30 19:58:17,966 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.roles
2023-05-30 19:58:17,966 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,966 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.roles
2023-05-30 19:58:17,973 - INFO  [node1_MigrationStage:1:Keyspace@386] - Creating replication strategy system_distributed params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}
2023-05-30 19:58:17,973 - DEBUG [node1_MigrationStage:1:Keyspace@390] - New replication settings for keyspace system_distributed - invalidating disk boundary caches
2023-05-30 19:58:17,974 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_distributed.parent_repair_history
2023-05-30 19:58:17,975 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.parent_repair_history
2023-05-30 19:58:17,975 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,975 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_distributed.parent_repair_history
2023-05-30 19:58:17,976 - DEBUG [node1_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:17,976 - DEBUG [node1_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:17,976 - DEBUG [node1_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:17,976 - DEBUG [node1_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:17,976 - DEBUG [node1_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:17,976 - DEBUG [node1_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:17,978 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_distributed.repair_history
2023-05-30 19:58:17,979 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.repair_history
2023-05-30 19:58:17,979 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,979 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_distributed.repair_history
2023-05-30 19:58:17,979 - DEBUG [node1_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:17,979 - DEBUG [node1_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:17,979 - DEBUG [node1_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:17,979 - DEBUG [node1_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:17,979 - DEBUG [node1_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:17,979 - DEBUG [node1_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:17,981 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_distributed.view_build_status
2023-05-30 19:58:17,981 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.view_build_status
2023-05-30 19:58:17,982 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,982 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_distributed.view_build_status
2023-05-30 19:58:17,983 - INFO  [node1_MigrationStage:1:Keyspace@386] - Creating replication strategy system_traces params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=2}}
2023-05-30 19:58:17,983 - DEBUG [node1_MigrationStage:1:Keyspace@390] - New replication settings for keyspace system_traces - invalidating disk boundary caches
2023-05-30 19:58:17,984 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_traces.events
2023-05-30 19:58:17,985 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_traces.events
2023-05-30 19:58:17,985 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,985 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_traces.events
2023-05-30 19:58:17,987 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_traces.sessions
2023-05-30 19:58:17,987 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_traces.sessions
2023-05-30 19:58:17,987 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:17,987 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_traces.sessions
2023-05-30 19:58:18,002 - DEBUG [node1_MigrationStage:1:StorageService@2399] - Ignoring application state SCHEMA from /127.0.0.1:7012 because it is not a member in token metadata
2023-05-30 19:58:18,002 - INFO  [node1_isolatedExecutor:1:StorageService@1634] - JOINING: Finish joining ring
2023-05-30 19:58:18,005 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of local: 0.604KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:18,009 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-local@1192666713(0.084KiB serialized bytes, 3 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:18,009 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-2-big-Data.db (0.056KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=11467)
2023-05-30 19:58:18,075 - INFO  [node1_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb_txn_flush_d9310c50-ff45-11ed-bc52-8b144d1e6fed.log 
2023-05-30 19:58:18,076 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-2-big-Data.db')] (1 sstables, 4.954KiB), biggest 4.954KiB, smallest 4.954KiB
2023-05-30 19:58:18,079 - DEBUG [node1_isolatedExecutor:1:StorageService@307] - Setting tokens to [-3074457345618258603]
2023-05-30 19:58:18,085 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of local: 0.600KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:18,088 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-local@1465934331(0.075KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:18,088 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-3-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=11560)
2023-05-30 19:58:18,157 - INFO  [node1_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb_txn_flush_d93d6860-ff45-11ed-bc52-8b144d1e6fed.log 
2023-05-30 19:58:18,158 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-3-big-Data.db')] (1 sstables, 4.944KiB), biggest 4.944KiB, smallest 4.944KiB
2023-05-30 19:58:18,162 - DEBUG [node1_isolatedExecutor:1:StorageService@2399] - Ignoring application state TOKENS from /127.0.0.1:7012 because it is not a member in token metadata
2023-05-30 19:58:18,163 - DEBUG [node1_isolatedExecutor:1:StorageService@2782] - Node /127.0.0.1:7012 state NORMAL, token [-3074457345618258603]
2023-05-30 19:58:18,163 - DEBUG [node1_isolatedExecutor:1:StorageService@2697] - New node /127.0.0.1:7012 at token -3074457345618258603
2023-05-30 19:58:18,170 - DEBUG [node1_isolatedExecutor:1:StorageService@2782] - Node /127.0.0.1:7012 state NORMAL, token [-3074457345618258603]
2023-05-30 19:58:18,170 - INFO  [node1_isolatedExecutor:1:StorageService@2785] - Node /127.0.0.1:7012 state jump to NORMAL
2023-05-30 19:58:18,171 - DEBUG [node1_isolatedExecutor:1:StorageService@1636] - NORMAL
2023-05-30 19:58:18,171 - INFO  [node1_isolatedExecutor:1:Gossiper@2214] - Waiting for gossip to settle...
2023-05-30 19:58:24,172 - DEBUG [node1_isolatedExecutor:1:Gossiper@2226] - Gossip looks settled.
2023-05-30 19:58:25,173 - DEBUG [node1_isolatedExecutor:1:Gossiper@2226] - Gossip looks settled.
2023-05-30 19:58:26,173 - DEBUG [node1_isolatedExecutor:1:Gossiper@2226] - Gossip looks settled.
2023-05-30 19:58:26,173 - INFO  [node1_isolatedExecutor:1:Gossiper@2245] - No gossip backlog; proceeding
2023-05-30 19:58:26,173 - INFO  [node1_isolatedExecutor:1:StorageService@838] - Populating token metadata from system tables
2023-05-30 19:58:26,176 - INFO  [node1_isolatedExecutor:1:StorageService@832] - Token metadata: Normal Tokens:
/127.0.0.1:7012:[-3074457345618258603]
Pending Ranges:

2023-05-30 19:58:26,253 - DEBUG [node2_isolatedExecutor:2:DatabaseDescriptor@384] - Syncing log with batch mode
2023-05-30 19:58:26,253 - DEBUG [node3_isolatedExecutor:2:DatabaseDescriptor@384] - Syncing log with batch mode
2023-05-30 19:58:26,255 - INFO  [node2_isolatedExecutor:2:DatabaseDescriptor@422] - DiskAccessMode is standard, indexAccessMode is mmap
2023-05-30 19:58:26,256 - INFO  [node2_isolatedExecutor:2:DatabaseDescriptor@477] - Global memtable on-heap threshold is enabled at 10MB
2023-05-30 19:58:26,256 - INFO  [node2_isolatedExecutor:2:DatabaseDescriptor@481] - Global memtable off-heap threshold is enabled at 1762MB
2023-05-30 19:58:26,255 - INFO  [node3_isolatedExecutor:2:DatabaseDescriptor@422] - DiskAccessMode is standard, indexAccessMode is mmap
2023-05-30 19:58:26,257 - INFO  [node3_isolatedExecutor:2:DatabaseDescriptor@477] - Global memtable on-heap threshold is enabled at 10MB
2023-05-30 19:58:26,257 - INFO  [node3_isolatedExecutor:2:DatabaseDescriptor@481] - Global memtable off-heap threshold is enabled at 1762MB
2023-05-30 19:58:26,299 - DEBUG [node2_isolatedExecutor:2:SSLFactory@384] - Initializing hot reloading SSLContext
2023-05-30 19:58:26,299 - DEBUG [node3_isolatedExecutor:2:SSLFactory@384] - Initializing hot reloading SSLContext
2023-05-30 19:58:26,334 - DEBUG [node2_isolatedExecutor:2:InternalLoggerFactory@63] - Using SLF4J as the default logging framework
2023-05-30 19:58:26,334 - DEBUG [node3_isolatedExecutor:2:InternalLoggerFactory@63] - Using SLF4J as the default logging framework
2023-05-30 19:58:26,335 - DEBUG [node2_isolatedExecutor:2:InternalThreadLocalMap@83] - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2023-05-30 19:58:26,335 - DEBUG [node3_isolatedExecutor:2:InternalThreadLocalMap@83] - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2023-05-30 19:58:26,335 - DEBUG [node2_isolatedExecutor:2:InternalThreadLocalMap@86] - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2023-05-30 19:58:26,335 - DEBUG [node3_isolatedExecutor:2:InternalThreadLocalMap@86] - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2023-05-30 19:58:26,343 - INFO  [node2_isolatedExecutor:2:MonotonicClock$AbstractEpochSamplingClock@202] - Scheduling approximate time conversion task with an interval of 10000 milliseconds
2023-05-30 19:58:26,343 - INFO  [node3_isolatedExecutor:2:MonotonicClock$AbstractEpochSamplingClock@202] - Scheduling approximate time conversion task with an interval of 10000 milliseconds
2023-05-30 19:58:26,344 - INFO  [node3_isolatedExecutor:2:MonotonicClock$SampledClock@338] - Scheduling approximate time-check task with a precision of 2 milliseconds
2023-05-30 19:58:26,344 - INFO  [node2_isolatedExecutor:2:MonotonicClock$SampledClock@338] - Scheduling approximate time-check task with a precision of 2 milliseconds
2023-05-30 19:58:26,345 - WARN  [node3_isolatedExecutor:2:StartupChecks$1@143] - jemalloc shared library could not be preloaded to speed up memory allocations
2023-05-30 19:58:26,345 - WARN  [node3_isolatedExecutor:2:StartupChecks$1@143] - jemalloc shared library could not be preloaded to speed up memory allocations
2023-05-30 19:58:26,345 - WARN  [node2_isolatedExecutor:2:StartupChecks$1@143] - jemalloc shared library could not be preloaded to speed up memory allocations
2023-05-30 19:58:26,345 - WARN  [node2_isolatedExecutor:2:StartupChecks$1@143] - jemalloc shared library could not be preloaded to speed up memory allocations
2023-05-30 19:58:26,391 - INFO  [node2_ScheduledTasks:1:StorageService@159] - Overriding RING_DELAY to 15000ms
2023-05-30 19:58:26,391 - INFO  [node3_ScheduledTasks:1:StorageService@159] - Overriding RING_DELAY to 15000ms
2023-05-30 19:58:26,844 - WARN  [node2_isolatedExecutor:2:StartupChecks$3@187] - JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.
2023-05-30 19:58:26,844 - WARN  [node2_isolatedExecutor:2:StartupChecks$3@187] - JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.
2023-05-30 19:58:26,844 - WARN  [node3_isolatedExecutor:2:StartupChecks$3@187] - JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.
2023-05-30 19:58:26,844 - WARN  [node3_isolatedExecutor:2:StartupChecks$3@187] - JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.
2023-05-30 19:58:26,844 - ERROR [node2_isolatedExecutor:2:StartupChecks$3@190] - cassandra.jmx.local.port missing from cassandra-env.sh, unable to start local JMX service.
2023-05-30 19:58:26,844 - ERROR [node2_isolatedExecutor:2:StartupChecks$3@190] - cassandra.jmx.local.port missing from cassandra-env.sh, unable to start local JMX service.
2023-05-30 19:58:26,844 - ERROR [node3_isolatedExecutor:2:StartupChecks$3@190] - cassandra.jmx.local.port missing from cassandra-env.sh, unable to start local JMX service.
2023-05-30 19:58:26,844 - ERROR [node3_isolatedExecutor:2:StartupChecks$3@190] - cassandra.jmx.local.port missing from cassandra-env.sh, unable to start local JMX service.
2023-05-30 19:58:26,845 - WARN  [node3_isolatedExecutor:2:StartupChecks$5@238] - The JVM is not configured to stop on OutOfMemoryError which can cause data corruption. Use one of the following JVM options to configure the behavior on OutOfMemoryError:  -XX:+ExitOnOutOfMemoryError, -XX:+CrashOnOutOfMemoryError, or -XX:OnOutOfMemoryError="<cmd args>;<cmd args>"
2023-05-30 19:58:26,845 - WARN  [node2_isolatedExecutor:2:StartupChecks$5@238] - The JVM is not configured to stop on OutOfMemoryError which can cause data corruption. Use one of the following JVM options to configure the behavior on OutOfMemoryError:  -XX:+ExitOnOutOfMemoryError, -XX:+CrashOnOutOfMemoryError, or -XX:OnOutOfMemoryError="<cmd args>;<cmd args>"
2023-05-30 19:58:26,845 - WARN  [node3_isolatedExecutor:2:StartupChecks$5@238] - The JVM is not configured to stop on OutOfMemoryError which can cause data corruption. Use one of the following JVM options to configure the behavior on OutOfMemoryError:  -XX:+ExitOnOutOfMemoryError, -XX:+CrashOnOutOfMemoryError, or -XX:OnOutOfMemoryError="<cmd args>;<cmd args>"
2023-05-30 19:58:26,845 - WARN  [node2_isolatedExecutor:2:StartupChecks$5@238] - The JVM is not configured to stop on OutOfMemoryError which can cause data corruption. Use one of the following JVM options to configure the behavior on OutOfMemoryError:  -XX:+ExitOnOutOfMemoryError, -XX:+CrashOnOutOfMemoryError, or -XX:OnOutOfMemoryError="<cmd args>;<cmd args>"
2023-05-30 19:58:26,846 - INFO  [node3_isolatedExecutor:2:SigarLibrary@44] - Initializing SIGAR library
2023-05-30 19:58:26,846 - INFO  [node2_isolatedExecutor:2:SigarLibrary@44] - Initializing SIGAR library
2023-05-30 19:58:26,855 - DEBUG [node3_isolatedExecutor:2:SigarLog@60] - no libsigar-amd64-linux.so in java.library.path
org.hyperic.sigar.SigarException: no libsigar-amd64-linux.so in java.library.path
	at org.hyperic.sigar.Sigar.loadLibrary(Sigar.java:172)
	at org.hyperic.sigar.Sigar.<clinit>(Sigar.java:100)
	at org.apache.cassandra.utils.SigarLibrary.<init>(SigarLibrary.java:47)
	at org.apache.cassandra.utils.SigarLibrary.<clinit>(SigarLibrary.java:28)
	at org.apache.cassandra.service.StartupChecks$7.execute(StartupChecks.java:284)
	at org.apache.cassandra.service.StartupChecks.verify(StartupChecks.java:132)
	at org.apache.cassandra.service.CassandraDaemon.runStartupChecks(CassandraDaemon.java:489)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:486)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:26,855 - DEBUG [node2_isolatedExecutor:2:SigarLog@60] - no libsigar-amd64-linux.so in java.library.path
org.hyperic.sigar.SigarException: no libsigar-amd64-linux.so in java.library.path
	at org.hyperic.sigar.Sigar.loadLibrary(Sigar.java:172)
	at org.hyperic.sigar.Sigar.<clinit>(Sigar.java:100)
	at org.apache.cassandra.utils.SigarLibrary.<init>(SigarLibrary.java:47)
	at org.apache.cassandra.utils.SigarLibrary.<clinit>(SigarLibrary.java:28)
	at org.apache.cassandra.service.StartupChecks$7.execute(StartupChecks.java:284)
	at org.apache.cassandra.service.StartupChecks.verify(StartupChecks.java:132)
	at org.apache.cassandra.service.CassandraDaemon.runStartupChecks(CassandraDaemon.java:489)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:486)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:26,856 - INFO  [node3_isolatedExecutor:2:SigarLibrary@57] - Could not initialize SIGAR library org.hyperic.sigar.Sigar.getFileSystemListNative()[Lorg/hyperic/sigar/FileSystem; 
2023-05-30 19:58:26,856 - INFO  [node2_isolatedExecutor:2:SigarLibrary@57] - Could not initialize SIGAR library org.hyperic.sigar.Sigar.getFileSystemListNative()[Lorg/hyperic/sigar/FileSystem; 
2023-05-30 19:58:26,856 - INFO  [node3_isolatedExecutor:2:SigarLibrary@185] - Sigar could not be initialized, test for checking degraded mode omitted.
2023-05-30 19:58:26,856 - INFO  [node2_isolatedExecutor:2:SigarLibrary@185] - Sigar could not be initialized, test for checking degraded mode omitted.
2023-05-30 19:58:26,856 - WARN  [node2_isolatedExecutor:2:StartupChecks$8@329] - Maximum number of memory map areas per process (vm.max_map_count) 65530 is too low, recommended value: 1048575, you can change it with sysctl.
2023-05-30 19:58:26,856 - WARN  [node3_isolatedExecutor:2:StartupChecks$8@329] - Maximum number of memory map areas per process (vm.max_map_count) 65530 is too low, recommended value: 1048575, you can change it with sysctl.
2023-05-30 19:58:26,856 - WARN  [node2_isolatedExecutor:2:StartupChecks$8@329] - Maximum number of memory map areas per process (vm.max_map_count) 65530 is too low, recommended value: 1048575, you can change it with sysctl.
2023-05-30 19:58:26,856 - WARN  [node3_isolatedExecutor:2:StartupChecks$8@329] - Maximum number of memory map areas per process (vm.max_map_count) 65530 is too low, recommended value: 1048575, you can change it with sysctl.
2023-05-30 19:58:26,861 - DEBUG [node2_isolatedExecutor:2:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node2/data0
2023-05-30 19:58:26,861 - DEBUG [node3_isolatedExecutor:2:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node3/data0
2023-05-30 19:58:26,864 - DEBUG [node2_isolatedExecutor:2:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node2/data1
2023-05-30 19:58:26,864 - DEBUG [node3_isolatedExecutor:2:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node3/data1
2023-05-30 19:58:26,864 - DEBUG [node3_isolatedExecutor:2:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node3/data2
2023-05-30 19:58:26,864 - DEBUG [node2_isolatedExecutor:2:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node2/data2
2023-05-30 19:58:26,864 - DEBUG [node3_isolatedExecutor:2:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node3/commitlog
2023-05-30 19:58:26,864 - DEBUG [node2_isolatedExecutor:2:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node2/commitlog
2023-05-30 19:58:26,864 - DEBUG [node3_isolatedExecutor:2:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node3/saved_caches
2023-05-30 19:58:26,864 - DEBUG [node2_isolatedExecutor:2:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node2/saved_caches
2023-05-30 19:58:26,864 - DEBUG [node3_isolatedExecutor:2:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node3/hints
2023-05-30 19:58:26,864 - DEBUG [node2_isolatedExecutor:2:StartupChecks@345] - Checking directory /tmp/dtests293447409190997823/node2/hints
2023-05-30 19:58:27,179 - INFO  [node3_isolatedExecutor:2:Keyspace@386] - Creating replication strategy system params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.LocalStrategy}}
2023-05-30 19:58:27,187 - INFO  [node2_isolatedExecutor:2:Keyspace@386] - Creating replication strategy system params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.LocalStrategy}}
2023-05-30 19:58:27,191 - DEBUG [node3_isolatedExecutor:2:Keyspace@390] - New replication settings for keyspace system - invalidating disk boundary caches
2023-05-30 19:58:27,198 - DEBUG [node2_isolatedExecutor:2:Keyspace@390] - New replication settings for keyspace system - invalidating disk boundary caches
2023-05-30 19:58:27,202 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.IndexInfo
2023-05-30 19:58:27,209 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.IndexInfo
2023-05-30 19:58:28,085 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.IndexInfo
2023-05-30 19:58:28,093 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.IndexInfo
2023-05-30 19:58:28,093 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,094 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.IndexInfo
2023-05-30 19:58:28,100 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,101 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.IndexInfo
2023-05-30 19:58:28,118 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.batches
2023-05-30 19:58:28,120 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.paxos
2023-05-30 19:58:28,121 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.paxos
2023-05-30 19:58:28,121 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,121 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system.paxos
2023-05-30 19:58:28,125 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.batches
2023-05-30 19:58:28,125 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.local
2023-05-30 19:58:28,125 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.local
2023-05-30 19:58:28,126 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,126 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.local
2023-05-30 19:58:28,127 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.paxos
2023-05-30 19:58:28,127 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.peers_v2
2023-05-30 19:58:28,128 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peers_v2
2023-05-30 19:58:28,128 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.paxos
2023-05-30 19:58:28,128 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,128 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,128 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.peers_v2
2023-05-30 19:58:28,128 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system.paxos
2023-05-30 19:58:28,130 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.peers
2023-05-30 19:58:28,130 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peers
2023-05-30 19:58:28,130 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,130 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.peers
2023-05-30 19:58:28,132 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.peer_events_v2
2023-05-30 19:58:28,132 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peer_events_v2
2023-05-30 19:58:28,132 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.local
2023-05-30 19:58:28,132 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,132 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.peer_events_v2
2023-05-30 19:58:28,133 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.local
2023-05-30 19:58:28,133 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,133 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.local
2023-05-30 19:58:28,134 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.peer_events
2023-05-30 19:58:28,135 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peer_events
2023-05-30 19:58:28,135 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.peers_v2
2023-05-30 19:58:28,135 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,135 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.peer_events
2023-05-30 19:58:28,135 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peers_v2
2023-05-30 19:58:28,135 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,135 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.peers_v2
2023-05-30 19:58:28,137 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.compaction_history
2023-05-30 19:58:28,137 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.peers
2023-05-30 19:58:28,137 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.compaction_history
2023-05-30 19:58:28,137 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,137 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system.compaction_history
2023-05-30 19:58:28,137 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peers
2023-05-30 19:58:28,137 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,138 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.peers
2023-05-30 19:58:28,139 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.peer_events_v2
2023-05-30 19:58:28,139 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.sstable_activity
2023-05-30 19:58:28,140 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peer_events_v2
2023-05-30 19:58:28,140 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.sstable_activity
2023-05-30 19:58:28,140 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,140 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,140 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.peer_events_v2
2023-05-30 19:58:28,140 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.sstable_activity
2023-05-30 19:58:28,142 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.size_estimates
2023-05-30 19:58:28,142 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.size_estimates
2023-05-30 19:58:28,142 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.peer_events
2023-05-30 19:58:28,142 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,142 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.size_estimates
2023-05-30 19:58:28,142 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peer_events
2023-05-30 19:58:28,142 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,142 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.peer_events
2023-05-30 19:58:28,144 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.table_estimates
2023-05-30 19:58:28,144 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.table_estimates
2023-05-30 19:58:28,144 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,144 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.table_estimates
2023-05-30 19:58:28,144 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.compaction_history
2023-05-30 19:58:28,145 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.compaction_history
2023-05-30 19:58:28,145 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,145 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system.compaction_history
2023-05-30 19:58:28,146 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.available_ranges_v2
2023-05-30 19:58:28,146 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.available_ranges_v2
2023-05-30 19:58:28,146 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,146 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.available_ranges_v2
2023-05-30 19:58:28,147 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.sstable_activity
2023-05-30 19:58:28,147 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.sstable_activity
2023-05-30 19:58:28,147 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,147 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.sstable_activity
2023-05-30 19:58:28,148 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.available_ranges
2023-05-30 19:58:28,148 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.available_ranges
2023-05-30 19:58:28,148 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,148 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.available_ranges
2023-05-30 19:58:28,149 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.size_estimates
2023-05-30 19:58:28,149 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.size_estimates
2023-05-30 19:58:28,149 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,149 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.size_estimates
2023-05-30 19:58:28,150 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.transferred_ranges_v2
2023-05-30 19:58:28,150 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.transferred_ranges_v2
2023-05-30 19:58:28,150 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,150 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.transferred_ranges_v2
2023-05-30 19:58:28,151 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.table_estimates
2023-05-30 19:58:28,151 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.table_estimates
2023-05-30 19:58:28,151 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,151 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.table_estimates
2023-05-30 19:58:28,152 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.transferred_ranges
2023-05-30 19:58:28,152 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.transferred_ranges
2023-05-30 19:58:28,153 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,153 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.transferred_ranges
2023-05-30 19:58:28,153 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.available_ranges_v2
2023-05-30 19:58:28,153 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.available_ranges_v2
2023-05-30 19:58:28,153 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,154 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.available_ranges_v2
2023-05-30 19:58:28,154 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.view_builds_in_progress
2023-05-30 19:58:28,154 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.view_builds_in_progress
2023-05-30 19:58:28,155 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,155 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.view_builds_in_progress
2023-05-30 19:58:28,155 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.available_ranges
2023-05-30 19:58:28,155 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.available_ranges
2023-05-30 19:58:28,156 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,156 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.available_ranges
2023-05-30 19:58:28,156 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.built_views
2023-05-30 19:58:28,156 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.built_views
2023-05-30 19:58:28,156 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,157 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.built_views
2023-05-30 19:58:28,157 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.transferred_ranges_v2
2023-05-30 19:58:28,157 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.transferred_ranges_v2
2023-05-30 19:58:28,158 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,158 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.transferred_ranges_v2
2023-05-30 19:58:28,158 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.prepared_statements
2023-05-30 19:58:28,159 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.prepared_statements
2023-05-30 19:58:28,159 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,159 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system.prepared_statements
2023-05-30 19:58:28,159 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.transferred_ranges
2023-05-30 19:58:28,160 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.transferred_ranges
2023-05-30 19:58:28,160 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,160 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.transferred_ranges
2023-05-30 19:58:28,160 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.repairs
2023-05-30 19:58:28,161 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.repairs
2023-05-30 19:58:28,161 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,161 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system.repairs
2023-05-30 19:58:28,162 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.view_builds_in_progress
2023-05-30 19:58:28,162 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.view_builds_in_progress
2023-05-30 19:58:28,162 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,162 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.view_builds_in_progress
2023-05-30 19:58:28,164 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.built_views
2023-05-30 19:58:28,164 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.built_views
2023-05-30 19:58:28,164 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,164 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system.built_views
2023-05-30 19:58:28,166 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.prepared_statements
2023-05-30 19:58:28,166 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.prepared_statements
2023-05-30 19:58:28,166 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,166 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system.prepared_statements
2023-05-30 19:58:28,168 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system.repairs
2023-05-30 19:58:28,168 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.repairs
2023-05-30 19:58:28,168 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,169 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system.repairs
2023-05-30 19:58:28,319 - INFO  [node3_isolatedExecutor:2:QueryProcessor@115] - Initialized prepared statement caches with 27 MB
2023-05-30 19:58:28,321 - INFO  [node2_isolatedExecutor:2:QueryProcessor@115] - Initialized prepared statement caches with 27 MB
2023-05-30 19:58:28,384 - INFO  [node3_isolatedExecutor:2:Keyspace@386] - Creating replication strategy system_schema params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.LocalStrategy}}
2023-05-30 19:58:28,384 - DEBUG [node3_isolatedExecutor:2:Keyspace@390] - New replication settings for keyspace system_schema - invalidating disk boundary caches
2023-05-30 19:58:28,385 - INFO  [node2_isolatedExecutor:2:Keyspace@386] - Creating replication strategy system_schema params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.LocalStrategy}}
2023-05-30 19:58:28,385 - DEBUG [node2_isolatedExecutor:2:Keyspace@390] - New replication settings for keyspace system_schema - invalidating disk boundary caches
2023-05-30 19:58:28,385 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.keyspaces
2023-05-30 19:58:28,386 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.keyspaces
2023-05-30 19:58:28,386 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.keyspaces
2023-05-30 19:58:28,386 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,386 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.keyspaces
2023-05-30 19:58:28,386 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.keyspaces
2023-05-30 19:58:28,386 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,387 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.keyspaces
2023-05-30 19:58:28,388 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.tables
2023-05-30 19:58:28,388 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.tables
2023-05-30 19:58:28,388 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.tables
2023-05-30 19:58:28,388 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,388 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.tables
2023-05-30 19:58:28,389 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.tables
2023-05-30 19:58:28,389 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,389 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.tables
2023-05-30 19:58:28,390 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.columns
2023-05-30 19:58:28,390 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.columns
2023-05-30 19:58:28,390 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.columns
2023-05-30 19:58:28,390 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,391 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.columns
2023-05-30 19:58:28,391 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.columns
2023-05-30 19:58:28,391 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,391 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.columns
2023-05-30 19:58:28,392 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.triggers
2023-05-30 19:58:28,393 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.triggers
2023-05-30 19:58:28,393 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.triggers
2023-05-30 19:58:28,393 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,393 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.triggers
2023-05-30 19:58:28,393 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.triggers
2023-05-30 19:58:28,393 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,393 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.triggers
2023-05-30 19:58:28,395 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.dropped_columns
2023-05-30 19:58:28,395 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.dropped_columns
2023-05-30 19:58:28,395 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,395 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.dropped_columns
2023-05-30 19:58:28,395 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.dropped_columns
2023-05-30 19:58:28,396 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.dropped_columns
2023-05-30 19:58:28,396 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,396 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.dropped_columns
2023-05-30 19:58:28,397 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.views
2023-05-30 19:58:28,397 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.views
2023-05-30 19:58:28,398 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,398 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.views
2023-05-30 19:58:28,398 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.views
2023-05-30 19:58:28,399 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.views
2023-05-30 19:58:28,399 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,399 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.views
2023-05-30 19:58:28,399 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.types
2023-05-30 19:58:28,399 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.types
2023-05-30 19:58:28,400 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,400 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.types
2023-05-30 19:58:28,400 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.types
2023-05-30 19:58:28,401 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.types
2023-05-30 19:58:28,401 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,401 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.types
2023-05-30 19:58:28,401 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.functions
2023-05-30 19:58:28,401 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.functions
2023-05-30 19:58:28,402 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,402 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.functions
2023-05-30 19:58:28,402 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.functions
2023-05-30 19:58:28,403 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.functions
2023-05-30 19:58:28,403 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,403 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.functions
2023-05-30 19:58:28,403 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.aggregates
2023-05-30 19:58:28,403 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.aggregates
2023-05-30 19:58:28,404 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,404 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.aggregates
2023-05-30 19:58:28,405 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.aggregates
2023-05-30 19:58:28,405 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.aggregates
2023-05-30 19:58:28,405 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,405 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.indexes
2023-05-30 19:58:28,405 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.aggregates
2023-05-30 19:58:28,406 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.indexes
2023-05-30 19:58:28,406 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,406 - DEBUG [node3_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.indexes
2023-05-30 19:58:28,407 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@385] - Initializing system_schema.indexes
2023-05-30 19:58:28,407 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.indexes
2023-05-30 19:58:28,407 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:28,408 - DEBUG [node2_isolatedExecutor:2:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} for system_schema.indexes
2023-05-30 19:58:28,445 - INFO  [node3_isolatedExecutor:2:SystemKeyspaceMigrator40@76] - system.peers_v2 table was empty, migrating legacy system.peers, if this fails you should fix the issue and then truncate system.peers_v2 to have it try again.
2023-05-30 19:58:28,450 - INFO  [node3_isolatedExecutor:2:SystemKeyspaceMigrator40@100] - Migrating rows from legacy system.peers to system.peers_v2
2023-05-30 19:58:28,452 - INFO  [node3_isolatedExecutor:2:SystemKeyspaceMigrator40@119] - Migrated 0 rows from legacy system.peers to system.peers_v2
2023-05-30 19:58:28,452 - INFO  [node3_isolatedExecutor:2:SystemKeyspaceMigrator40@129] - system.peer_events_v2 table was empty, migrating legacy system.peer_events to system.peer_events_v2
2023-05-30 19:58:28,453 - INFO  [node3_isolatedExecutor:2:SystemKeyspaceMigrator40@152] - Migrated 0 rows from legacy system.peer_events to system.peer_events_v2
2023-05-30 19:58:28,453 - INFO  [node3_isolatedExecutor:2:SystemKeyspaceMigrator40@162] - system.transferred_ranges_v2 table was empty, migrating legacy system.transferred_ranges to system.transferred_ranges_v2
2023-05-30 19:58:28,453 - INFO  [node2_isolatedExecutor:2:SystemKeyspaceMigrator40@76] - system.peers_v2 table was empty, migrating legacy system.peers, if this fails you should fix the issue and then truncate system.peers_v2 to have it try again.
2023-05-30 19:58:28,454 - INFO  [node3_isolatedExecutor:2:SystemKeyspaceMigrator40@190] - Migrated 0 rows from legacy system.transferred_ranges to system.transferred_ranges_v2
2023-05-30 19:58:28,454 - INFO  [node3_isolatedExecutor:2:SystemKeyspaceMigrator40@200] - system.available_ranges_v2 table was empty, migrating legacy system.available_ranges to system.available_ranges_v2
2023-05-30 19:58:28,455 - INFO  [node3_isolatedExecutor:2:SystemKeyspaceMigrator40@226] - Migrated 0 rows from legacy system.available_ranges to system.available_ranges_v2
2023-05-30 19:58:28,455 - INFO  [node3_isolatedExecutor:2:StorageService@838] - Populating token metadata from system tables
2023-05-30 19:58:28,458 - INFO  [node2_isolatedExecutor:2:SystemKeyspaceMigrator40@100] - Migrating rows from legacy system.peers to system.peers_v2
2023-05-30 19:58:28,460 - INFO  [node2_isolatedExecutor:2:SystemKeyspaceMigrator40@119] - Migrated 0 rows from legacy system.peers to system.peers_v2
2023-05-30 19:58:28,460 - INFO  [node2_isolatedExecutor:2:SystemKeyspaceMigrator40@129] - system.peer_events_v2 table was empty, migrating legacy system.peer_events to system.peer_events_v2
2023-05-30 19:58:28,461 - INFO  [node2_isolatedExecutor:2:SystemKeyspaceMigrator40@152] - Migrated 0 rows from legacy system.peer_events to system.peer_events_v2
2023-05-30 19:58:28,461 - INFO  [node2_isolatedExecutor:2:SystemKeyspaceMigrator40@162] - system.transferred_ranges_v2 table was empty, migrating legacy system.transferred_ranges to system.transferred_ranges_v2
2023-05-30 19:58:28,462 - INFO  [node2_isolatedExecutor:2:SystemKeyspaceMigrator40@190] - Migrated 0 rows from legacy system.transferred_ranges to system.transferred_ranges_v2
2023-05-30 19:58:28,462 - INFO  [node2_isolatedExecutor:2:SystemKeyspaceMigrator40@200] - system.available_ranges_v2 table was empty, migrating legacy system.available_ranges to system.available_ranges_v2
2023-05-30 19:58:28,463 - INFO  [node2_isolatedExecutor:2:SystemKeyspaceMigrator40@226] - Migrated 0 rows from legacy system.available_ranges to system.available_ranges_v2
2023-05-30 19:58:28,463 - INFO  [node2_isolatedExecutor:2:StorageService@838] - Populating token metadata from system tables
2023-05-30 19:58:28,463 - INFO  [node3_isolatedExecutor:2:StorageService@832] - Token metadata: 
2023-05-30 19:58:28,471 - INFO  [node2_isolatedExecutor:2:StorageService@832] - Token metadata: 
2023-05-30 19:58:28,481 - INFO  [node3_isolatedExecutor:2:CommitLog@168] - No commitlog files found; skipping replay
2023-05-30 19:58:28,481 - INFO  [node3_isolatedExecutor:2:StorageService@838] - Populating token metadata from system tables
2023-05-30 19:58:28,482 - INFO  [node3_isolatedExecutor:2:StorageService@832] - Token metadata: 
2023-05-30 19:58:28,489 - INFO  [node2_isolatedExecutor:2:CommitLog@168] - No commitlog files found; skipping replay
2023-05-30 19:58:28,489 - INFO  [node2_isolatedExecutor:2:StorageService@838] - Populating token metadata from system tables
2023-05-30 19:58:28,490 - INFO  [node2_isolatedExecutor:2:StorageService@832] - Token metadata: 
2023-05-30 19:58:28,510 - WARN  [node3_isolatedExecutor:2:NativeTransportService@165] - epoll not available
java.lang.UnsupportedOperationException: Native transport was explicit disabled with -Dio.netty.transport.noNative=true
	at io.netty.channel.epoll.Epoll.<clinit>(Epoll.java:33)
	at org.apache.cassandra.service.NativeTransportService.useEpoll(NativeTransportService.java:164)
	at org.apache.cassandra.net.SocketFactory$Provider.optimalProvider(SocketFactory.java:164)
	at org.apache.cassandra.net.SocketFactory.<init>(SocketFactory.java:185)
	at org.apache.cassandra.net.MessagingService.<init>(MessagingService.java:234)
	at org.apache.cassandra.net.MessagingService$MSHandle.<clinit>(MessagingService.java:226)
	at org.apache.cassandra.net.MessagingService.instance(MessagingService.java:231)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:529)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:28,510 - WARN  [node3_isolatedExecutor:2:NativeTransportService@165] - epoll not available
java.lang.UnsupportedOperationException: Native transport was explicit disabled with -Dio.netty.transport.noNative=true
	at io.netty.channel.epoll.Epoll.<clinit>(Epoll.java:33)
	at org.apache.cassandra.service.NativeTransportService.useEpoll(NativeTransportService.java:164)
	at org.apache.cassandra.net.SocketFactory$Provider.optimalProvider(SocketFactory.java:164)
	at org.apache.cassandra.net.SocketFactory.<init>(SocketFactory.java:185)
	at org.apache.cassandra.net.MessagingService.<init>(MessagingService.java:234)
	at org.apache.cassandra.net.MessagingService$MSHandle.<clinit>(MessagingService.java:226)
	at org.apache.cassandra.net.MessagingService.instance(MessagingService.java:231)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:529)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:28,510 - DEBUG [node3_isolatedExecutor:2:SocketFactory$Provider@154] - using netty NIO event loop for pool prefix Messaging-AcceptLoop
2023-05-30 19:58:28,515 - DEBUG [node3_isolatedExecutor:2:MultithreadEventLoopGroup@44] - -Dio.netty.eventLoopThreads: 40
2023-05-30 19:58:28,520 - WARN  [node2_isolatedExecutor:2:NativeTransportService@165] - epoll not available
java.lang.UnsupportedOperationException: Native transport was explicit disabled with -Dio.netty.transport.noNative=true
	at io.netty.channel.epoll.Epoll.<clinit>(Epoll.java:33)
	at org.apache.cassandra.service.NativeTransportService.useEpoll(NativeTransportService.java:164)
	at org.apache.cassandra.net.SocketFactory$Provider.optimalProvider(SocketFactory.java:164)
	at org.apache.cassandra.net.SocketFactory.<init>(SocketFactory.java:185)
	at org.apache.cassandra.net.MessagingService.<init>(MessagingService.java:234)
	at org.apache.cassandra.net.MessagingService$MSHandle.<clinit>(MessagingService.java:226)
	at org.apache.cassandra.net.MessagingService.instance(MessagingService.java:231)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:529)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:28,520 - WARN  [node2_isolatedExecutor:2:NativeTransportService@165] - epoll not available
java.lang.UnsupportedOperationException: Native transport was explicit disabled with -Dio.netty.transport.noNative=true
	at io.netty.channel.epoll.Epoll.<clinit>(Epoll.java:33)
	at org.apache.cassandra.service.NativeTransportService.useEpoll(NativeTransportService.java:164)
	at org.apache.cassandra.net.SocketFactory$Provider.optimalProvider(SocketFactory.java:164)
	at org.apache.cassandra.net.SocketFactory.<init>(SocketFactory.java:185)
	at org.apache.cassandra.net.MessagingService.<init>(MessagingService.java:234)
	at org.apache.cassandra.net.MessagingService$MSHandle.<clinit>(MessagingService.java:226)
	at org.apache.cassandra.net.MessagingService.instance(MessagingService.java:231)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:529)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:28,520 - DEBUG [node2_isolatedExecutor:2:SocketFactory$Provider@154] - using netty NIO event loop for pool prefix Messaging-AcceptLoop
2023-05-30 19:58:28,525 - DEBUG [node2_isolatedExecutor:2:MultithreadEventLoopGroup@44] - -Dio.netty.eventLoopThreads: 40
2023-05-30 19:58:28,532 - DEBUG [node3_isolatedExecutor:2:NioEventLoop@106] - -Dio.netty.noKeySetOptimization: false
2023-05-30 19:58:28,532 - DEBUG [node3_isolatedExecutor:2:NioEventLoop@107] - -Dio.netty.selectorAutoRebuildThreshold: 512
2023-05-30 19:58:28,541 - DEBUG [node2_isolatedExecutor:2:NioEventLoop@106] - -Dio.netty.noKeySetOptimization: false
2023-05-30 19:58:28,541 - DEBUG [node2_isolatedExecutor:2:NioEventLoop@107] - -Dio.netty.selectorAutoRebuildThreshold: 512
2023-05-30 19:58:28,547 - DEBUG [node3_isolatedExecutor:2:PlatformDependent0@417] - -Dio.netty.noUnsafe: false
2023-05-30 19:58:28,547 - DEBUG [node3_isolatedExecutor:2:PlatformDependent0@897] - Java version: 8
2023-05-30 19:58:28,547 - DEBUG [node3_isolatedExecutor:2:PlatformDependent0@130] - sun.misc.Unsafe.theUnsafe: available
2023-05-30 19:58:28,548 - DEBUG [node3_isolatedExecutor:2:PlatformDependent0@154] - sun.misc.Unsafe.copyMemory: available
2023-05-30 19:58:28,548 - DEBUG [node3_isolatedExecutor:2:PlatformDependent0@192] - java.nio.Buffer.address: available
2023-05-30 19:58:28,549 - DEBUG [node3_isolatedExecutor:2:PlatformDependent0@257] - direct buffer constructor: available
2023-05-30 19:58:28,549 - DEBUG [node3_isolatedExecutor:2:PlatformDependent0@331] - java.nio.Bits.unaligned: available, true
2023-05-30 19:58:28,549 - DEBUG [node3_isolatedExecutor:2:PlatformDependent0@396] - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2023-05-30 19:58:28,549 - DEBUG [node3_isolatedExecutor:2:PlatformDependent0@403] - java.nio.DirectByteBuffer.<init>(long, int): available
2023-05-30 19:58:28,550 - DEBUG [node3_isolatedExecutor:2:PlatformDependent@1079] - sun.misc.Unsafe: available
2023-05-30 19:58:28,550 - DEBUG [node3_isolatedExecutor:2:PlatformDependent@1200] - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
2023-05-30 19:58:28,550 - DEBUG [node3_isolatedExecutor:2:PlatformDependent@1279] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2023-05-30 19:58:28,550 - DEBUG [node3_isolatedExecutor:2:PlatformDependent@177] - -Dio.netty.maxDirectMemory: 7393509376 bytes
2023-05-30 19:58:28,551 - DEBUG [node3_isolatedExecutor:2:PlatformDependent@184] - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2023-05-30 19:58:28,551 - DEBUG [node3_isolatedExecutor:2:CleanerJava6@92] - java.nio.ByteBuffer.cleaner(): available
2023-05-30 19:58:28,551 - DEBUG [node3_isolatedExecutor:2:PlatformDependent@204] - -Dio.netty.noPreferDirect: false
2023-05-30 19:58:28,554 - DEBUG [node3_isolatedExecutor:2:SocketFactory$Provider@154] - using netty NIO event loop for pool prefix node3_Messaging-EventLoop
2023-05-30 19:58:28,555 - DEBUG [node2_isolatedExecutor:2:PlatformDependent0@417] - -Dio.netty.noUnsafe: false
2023-05-30 19:58:28,556 - DEBUG [node2_isolatedExecutor:2:PlatformDependent0@897] - Java version: 8
2023-05-30 19:58:28,556 - DEBUG [node2_isolatedExecutor:2:PlatformDependent0@130] - sun.misc.Unsafe.theUnsafe: available
2023-05-30 19:58:28,557 - DEBUG [node2_isolatedExecutor:2:PlatformDependent0@154] - sun.misc.Unsafe.copyMemory: available
2023-05-30 19:58:28,557 - DEBUG [node2_isolatedExecutor:2:PlatformDependent0@192] - java.nio.Buffer.address: available
2023-05-30 19:58:28,557 - DEBUG [node2_isolatedExecutor:2:PlatformDependent0@257] - direct buffer constructor: available
2023-05-30 19:58:28,558 - DEBUG [node2_isolatedExecutor:2:PlatformDependent0@331] - java.nio.Bits.unaligned: available, true
2023-05-30 19:58:28,558 - DEBUG [node2_isolatedExecutor:2:PlatformDependent0@396] - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2023-05-30 19:58:28,558 - DEBUG [node2_isolatedExecutor:2:PlatformDependent0@403] - java.nio.DirectByteBuffer.<init>(long, int): available
2023-05-30 19:58:28,558 - DEBUG [node2_isolatedExecutor:2:PlatformDependent@1079] - sun.misc.Unsafe: available
2023-05-30 19:58:28,558 - DEBUG [node2_isolatedExecutor:2:PlatformDependent@1200] - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
2023-05-30 19:58:28,558 - DEBUG [node2_isolatedExecutor:2:PlatformDependent@1279] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2023-05-30 19:58:28,559 - DEBUG [node2_isolatedExecutor:2:PlatformDependent@177] - -Dio.netty.maxDirectMemory: 7393509376 bytes
2023-05-30 19:58:28,559 - DEBUG [node2_isolatedExecutor:2:PlatformDependent@184] - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2023-05-30 19:58:28,560 - DEBUG [node2_isolatedExecutor:2:CleanerJava6@92] - java.nio.ByteBuffer.cleaner(): available
2023-05-30 19:58:28,560 - DEBUG [node2_isolatedExecutor:2:PlatformDependent@204] - -Dio.netty.noPreferDirect: false
2023-05-30 19:58:28,578 - DEBUG [node3_isolatedExecutor:2:SocketFactory$Provider@154] - using netty NIO event loop for pool prefix Streaming-EventLoop
2023-05-30 19:58:28,579 - DEBUG [node2_isolatedExecutor:2:SocketFactory$Provider@154] - using netty NIO event loop for pool prefix node2_Messaging-EventLoop
2023-05-30 19:58:28,580 - DEBUG [node2_isolatedExecutor:2:SocketFactory$Provider@154] - using netty NIO event loop for pool prefix Streaming-EventLoop
2023-05-30 19:58:28,592 - INFO  [node3_isolatedExecutor:2:InboundConnectionInitiator@127] - Listening on address: (/127.0.0.3:7012), nic: null, encryption: unencrypted
2023-05-30 19:58:28,593 - INFO  [node2_isolatedExecutor:2:InboundConnectionInitiator@127] - Listening on address: (/127.0.0.2:7012), nic: null, encryption: unencrypted
2023-05-30 19:58:28,611 - DEBUG [node3_isolatedExecutor:2:ResourceLeakDetector@129] - -Dio.netty.leakDetection.level: simple
2023-05-30 19:58:28,611 - DEBUG [node3_isolatedExecutor:2:ResourceLeakDetector@130] - -Dio.netty.leakDetection.targetRecords: 4
2023-05-30 19:58:28,612 - DEBUG [node2_isolatedExecutor:2:ResourceLeakDetector@129] - -Dio.netty.leakDetection.level: simple
2023-05-30 19:58:28,612 - DEBUG [node2_isolatedExecutor:2:ResourceLeakDetector@130] - -Dio.netty.leakDetection.targetRecords: 4
2023-05-30 19:58:28,615 - INFO  [node3_isolatedExecutor:2:BufferPools@49] - Global buffer pool limit is 512.000MiB for chunk-cache and 128.000MiB for networking
2023-05-30 19:58:28,616 - INFO  [node2_isolatedExecutor:2:BufferPools@49] - Global buffer pool limit is 512.000MiB for chunk-cache and 128.000MiB for networking
2023-05-30 19:58:28,619 - DEBUG [node3_isolatedExecutor:2:DefaultChannelId@79] - -Dio.netty.processId: 23968 (auto-detected)
2023-05-30 19:58:28,620 - DEBUG [node2_isolatedExecutor:2:DefaultChannelId@79] - -Dio.netty.processId: 23968 (auto-detected)
2023-05-30 19:58:28,621 - DEBUG [node3_isolatedExecutor:2:NetUtil@135] - -Djava.net.preferIPv4Stack: false
2023-05-30 19:58:28,621 - DEBUG [node3_isolatedExecutor:2:NetUtil@136] - -Djava.net.preferIPv6Addresses: false
2023-05-30 19:58:28,622 - DEBUG [node2_isolatedExecutor:2:NetUtil@135] - -Djava.net.preferIPv4Stack: false
2023-05-30 19:58:28,622 - DEBUG [node2_isolatedExecutor:2:NetUtil@136] - -Djava.net.preferIPv6Addresses: false
2023-05-30 19:58:28,623 - DEBUG [node3_isolatedExecutor:2:NetUtilInitializations@129] - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2023-05-30 19:58:28,623 - DEBUG [node2_isolatedExecutor:2:NetUtilInitializations@129] - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2023-05-30 19:58:28,624 - DEBUG [node3_isolatedExecutor:2:NetUtil$1@169] - /proc/sys/net/core/somaxconn: 128
2023-05-30 19:58:28,624 - DEBUG [node2_isolatedExecutor:2:NetUtil$1@169] - /proc/sys/net/core/somaxconn: 128
2023-05-30 19:58:28,624 - DEBUG [node3_isolatedExecutor:2:DefaultChannelId@101] - -Dio.netty.machineId: f8:f2:1e:ff:fe:32:be:a1 (auto-detected)
2023-05-30 19:58:28,625 - DEBUG [node2_isolatedExecutor:2:DefaultChannelId@101] - -Dio.netty.machineId: f8:f2:1e:ff:fe:32:be:a1 (auto-detected)
2023-05-30 19:58:28,715 - DEBUG [node3_isolatedExecutor:2:PooledByteBufAllocator@154] - -Dio.netty.allocator.numHeapArenas: 40
2023-05-30 19:58:28,715 - DEBUG [node2_isolatedExecutor:2:PooledByteBufAllocator@154] - -Dio.netty.allocator.numHeapArenas: 40
2023-05-30 19:58:28,715 - DEBUG [node3_isolatedExecutor:2:PooledByteBufAllocator@155] - -Dio.netty.allocator.numDirectArenas: 40
2023-05-30 19:58:28,715 - DEBUG [node2_isolatedExecutor:2:PooledByteBufAllocator@155] - -Dio.netty.allocator.numDirectArenas: 40
2023-05-30 19:58:28,715 - DEBUG [node3_isolatedExecutor:2:PooledByteBufAllocator@157] - -Dio.netty.allocator.pageSize: 8192
2023-05-30 19:58:28,715 - DEBUG [node2_isolatedExecutor:2:PooledByteBufAllocator@157] - -Dio.netty.allocator.pageSize: 8192
2023-05-30 19:58:28,715 - DEBUG [node3_isolatedExecutor:2:PooledByteBufAllocator@162] - -Dio.netty.allocator.maxOrder: 11
2023-05-30 19:58:28,715 - DEBUG [node2_isolatedExecutor:2:PooledByteBufAllocator@162] - -Dio.netty.allocator.maxOrder: 11
2023-05-30 19:58:28,715 - DEBUG [node3_isolatedExecutor:2:PooledByteBufAllocator@166] - -Dio.netty.allocator.chunkSize: 16777216
2023-05-30 19:58:28,715 - DEBUG [node2_isolatedExecutor:2:PooledByteBufAllocator@166] - -Dio.netty.allocator.chunkSize: 16777216
2023-05-30 19:58:28,715 - DEBUG [node3_isolatedExecutor:2:PooledByteBufAllocator@167] - -Dio.netty.allocator.smallCacheSize: 256
2023-05-30 19:58:28,715 - DEBUG [node2_isolatedExecutor:2:PooledByteBufAllocator@167] - -Dio.netty.allocator.smallCacheSize: 256
2023-05-30 19:58:28,715 - DEBUG [node3_isolatedExecutor:2:PooledByteBufAllocator@168] - -Dio.netty.allocator.normalCacheSize: 64
2023-05-30 19:58:28,715 - DEBUG [node2_isolatedExecutor:2:PooledByteBufAllocator@168] - -Dio.netty.allocator.normalCacheSize: 64
2023-05-30 19:58:28,715 - DEBUG [node3_isolatedExecutor:2:PooledByteBufAllocator@169] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2023-05-30 19:58:28,716 - DEBUG [node2_isolatedExecutor:2:PooledByteBufAllocator@169] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2023-05-30 19:58:28,716 - DEBUG [node3_isolatedExecutor:2:PooledByteBufAllocator@170] - -Dio.netty.allocator.cacheTrimInterval: 8192
2023-05-30 19:58:28,716 - DEBUG [node2_isolatedExecutor:2:PooledByteBufAllocator@170] - -Dio.netty.allocator.cacheTrimInterval: 8192
2023-05-30 19:58:28,716 - DEBUG [node3_isolatedExecutor:2:PooledByteBufAllocator@171] - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2023-05-30 19:58:28,716 - DEBUG [node2_isolatedExecutor:2:PooledByteBufAllocator@171] - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2023-05-30 19:58:28,716 - DEBUG [node3_isolatedExecutor:2:PooledByteBufAllocator@172] - -Dio.netty.allocator.useCacheForAllThreads: true
2023-05-30 19:58:28,716 - DEBUG [node3_isolatedExecutor:2:PooledByteBufAllocator@173] - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2023-05-30 19:58:28,716 - DEBUG [node2_isolatedExecutor:2:PooledByteBufAllocator@172] - -Dio.netty.allocator.useCacheForAllThreads: true
2023-05-30 19:58:28,716 - DEBUG [node2_isolatedExecutor:2:PooledByteBufAllocator@173] - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2023-05-30 19:58:28,725 - DEBUG [node3_isolatedExecutor:2:ByteBufUtil@87] - -Dio.netty.allocator.type: pooled
2023-05-30 19:58:28,726 - DEBUG [node2_isolatedExecutor:2:ByteBufUtil@87] - -Dio.netty.allocator.type: pooled
2023-05-30 19:58:28,726 - DEBUG [node3_isolatedExecutor:2:ByteBufUtil@96] - -Dio.netty.threadLocalDirectBufferSize: 0
2023-05-30 19:58:28,726 - DEBUG [node2_isolatedExecutor:2:ByteBufUtil@96] - -Dio.netty.threadLocalDirectBufferSize: 0
2023-05-30 19:58:28,726 - DEBUG [node3_isolatedExecutor:2:ByteBufUtil@99] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2023-05-30 19:58:28,726 - DEBUG [node2_isolatedExecutor:2:ByteBufUtil@99] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2023-05-30 19:58:28,743 - INFO  [node2_isolatedExecutor:2:StorageService@736] - Cassandra version: 4.0.5-SNAPSHOT
2023-05-30 19:58:28,743 - INFO  [node2_isolatedExecutor:2:StorageService@737] - CQL version: 3.4.5
2023-05-30 19:58:28,744 - INFO  [node2_isolatedExecutor:2:StorageService@738] - Native protocol supported versions: 3/v3, 4/v4, 5/v5, 6/v6-beta (default: 5/v5)
2023-05-30 19:58:28,744 - INFO  [node3_isolatedExecutor:2:StorageService@736] - Cassandra version: 4.0.5-SNAPSHOT
2023-05-30 19:58:28,744 - INFO  [node3_isolatedExecutor:2:StorageService@737] - CQL version: 3.4.5
2023-05-30 19:58:28,744 - INFO  [node3_isolatedExecutor:2:StorageService@738] - Native protocol supported versions: 3/v3, 4/v4, 5/v5, 6/v6-beta (default: 5/v5)
2023-05-30 19:58:28,761 - INFO  [node2_isolatedExecutor:2:IndexSummaryManager@84] - Initializing index summary manager with a memory pool size of 50 MB and a resize interval of 60 minutes
2023-05-30 19:58:28,761 - INFO  [node3_isolatedExecutor:2:IndexSummaryManager@84] - Initializing index summary manager with a memory pool size of 50 MB and a resize interval of 60 minutes
2023-05-30 19:58:28,761 - INFO  [node2_isolatedExecutor:2:StorageService@755] - Loading persisted ring state
2023-05-30 19:58:28,761 - INFO  [node2_isolatedExecutor:2:StorageService@838] - Populating token metadata from system tables
2023-05-30 19:58:28,761 - INFO  [node3_isolatedExecutor:2:StorageService@755] - Loading persisted ring state
2023-05-30 19:58:28,762 - INFO  [node3_isolatedExecutor:2:StorageService@838] - Populating token metadata from system tables
2023-05-30 19:58:28,766 - WARN  [node2_isolatedExecutor:2:SystemKeyspace@1130] - No host ID found, created 24bdb6a7-c7b9-472a-b58e-276d1101e7b5 (Note: This should happen exactly once per node).
2023-05-30 19:58:28,766 - WARN  [node2_isolatedExecutor:2:SystemKeyspace@1130] - No host ID found, created 24bdb6a7-c7b9-472a-b58e-276d1101e7b5 (Note: This should happen exactly once per node).
2023-05-30 19:58:28,766 - WARN  [node3_isolatedExecutor:2:SystemKeyspace@1130] - No host ID found, created d11eaeba-b1ee-473f-b242-a881decebff8 (Note: This should happen exactly once per node).
2023-05-30 19:58:28,766 - WARN  [node3_isolatedExecutor:2:SystemKeyspace@1130] - No host ID found, created d11eaeba-b1ee-473f-b242-a881decebff8 (Note: This should happen exactly once per node).
2023-05-30 19:58:28,768 - DEBUG [node2_isolatedExecutor:2:StorageService@649] - Starting shadow gossip round to check for endpoint collision
2023-05-30 19:58:28,768 - DEBUG [node3_isolatedExecutor:2:StorageService@649] - Starting shadow gossip round to check for endpoint collision
2023-05-30 19:58:28,830 - DEBUG [node3_Messaging-EventLoop-3-3:AbstractByteBuf@63] - -Dio.netty.buffer.checkAccessible: true
2023-05-30 19:58:28,830 - DEBUG [node2_Messaging-EventLoop-3-3:AbstractByteBuf@63] - -Dio.netty.buffer.checkAccessible: true
2023-05-30 19:58:28,831 - DEBUG [node2_Messaging-EventLoop-3-3:AbstractByteBuf@64] - -Dio.netty.buffer.checkBounds: true
2023-05-30 19:58:28,831 - DEBUG [node3_Messaging-EventLoop-3-3:AbstractByteBuf@64] - -Dio.netty.buffer.checkBounds: true
2023-05-30 19:58:28,831 - DEBUG [node3_Messaging-EventLoop-3-3:ResourceLeakDetectorFactory$DefaultResourceLeakDetectorFactory@196] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@668e2942
2023-05-30 19:58:28,831 - DEBUG [node2_Messaging-EventLoop-3-3:ResourceLeakDetectorFactory$DefaultResourceLeakDetectorFactory@196] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@9b78292
2023-05-30 19:58:28,835 - DEBUG [node3_Messaging-EventLoop-3-3:Recycler@102] - -Dio.netty.recycler.maxCapacityPerThread: 4096
2023-05-30 19:58:28,835 - DEBUG [node2_Messaging-EventLoop-3-3:Recycler@102] - -Dio.netty.recycler.maxCapacityPerThread: 4096
2023-05-30 19:58:28,836 - DEBUG [node3_Messaging-EventLoop-3-3:Recycler@103] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
2023-05-30 19:58:28,836 - DEBUG [node2_Messaging-EventLoop-3-3:Recycler@103] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
2023-05-30 19:58:28,836 - DEBUG [node3_Messaging-EventLoop-3-3:Recycler@104] - -Dio.netty.recycler.linkCapacity: 16
2023-05-30 19:58:28,836 - DEBUG [node2_Messaging-EventLoop-3-3:Recycler@104] - -Dio.netty.recycler.linkCapacity: 16
2023-05-30 19:58:28,836 - DEBUG [node3_Messaging-EventLoop-3-3:Recycler@105] - -Dio.netty.recycler.ratio: 8
2023-05-30 19:58:28,836 - DEBUG [node2_Messaging-EventLoop-3-3:Recycler@105] - -Dio.netty.recycler.ratio: 8
2023-05-30 19:58:28,836 - DEBUG [node3_Messaging-EventLoop-3-3:Recycler@106] - -Dio.netty.recycler.delayedQueue.ratio: 8
2023-05-30 19:58:28,836 - DEBUG [node2_Messaging-EventLoop-3-3:Recycler@106] - -Dio.netty.recycler.delayedQueue.ratio: 8
2023-05-30 19:58:28,842 - DEBUG [node1_Messaging-EventLoop-3-2:AbstractByteBuf@63] - -Dio.netty.buffer.checkAccessible: true
2023-05-30 19:58:28,842 - DEBUG [node1_Messaging-EventLoop-3-2:AbstractByteBuf@64] - -Dio.netty.buffer.checkBounds: true
2023-05-30 19:58:28,843 - DEBUG [node1_Messaging-EventLoop-3-2:ResourceLeakDetectorFactory$DefaultResourceLeakDetectorFactory@196] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@111048d0
2023-05-30 19:58:28,864 - DEBUG [node1_Messaging-EventLoop-3-2:Recycler@102] - -Dio.netty.recycler.maxCapacityPerThread: 4096
2023-05-30 19:58:28,864 - DEBUG [node1_Messaging-EventLoop-3-2:Recycler@103] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
2023-05-30 19:58:28,864 - DEBUG [node1_Messaging-EventLoop-3-2:Recycler@104] - -Dio.netty.recycler.linkCapacity: 16
2023-05-30 19:58:28,865 - DEBUG [node1_Messaging-EventLoop-3-2:Recycler@105] - -Dio.netty.recycler.ratio: 8
2023-05-30 19:58:28,865 - DEBUG [node1_Messaging-EventLoop-3-2:Recycler@106] - -Dio.netty.recycler.delayedQueue.ratio: 8
2023-05-30 19:58:28,887 - INFO  [node1_Messaging-EventLoop-3-1:InboundConnectionInitiator$Handler@464] - /127.0.0.3:7012(/127.0.0.1:50918)->/127.0.0.1:7012-URGENT_MESSAGES-08fe66f7 messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:28,887 - INFO  [node1_Messaging-EventLoop-3-2:InboundConnectionInitiator$Handler@464] - /127.0.0.2:7012(/127.0.0.1:50916)->/127.0.0.1:7012-URGENT_MESSAGES-9196594b messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:28,888 - INFO  [node3_Messaging-EventLoop-3-3:OutboundConnection$1Initiate@1150] - /127.0.0.3:7012(/127.0.0.1:50918)->/127.0.0.1:7012-URGENT_MESSAGES-f7e5df55 successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:28,889 - INFO  [node2_Messaging-EventLoop-3-3:OutboundConnection$1Initiate@1150] - /127.0.0.2:7012(/127.0.0.1:50916)->/127.0.0.1:7012-URGENT_MESSAGES-e0ffdb45 successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:28,894 - DEBUG [node1_GossipStage:1:Gossiper@1627] - Shadow request received, adding all states
2023-05-30 19:58:28,910 - DEBUG [node1_GossipStage:1:Gossiper@1627] - Shadow request received, adding all states
2023-05-30 19:58:28,933 - INFO  [node1_Messaging-EventLoop-3-5:OutboundConnection$1Initiate@1150] - /127.0.0.1:7012(/127.0.0.1:50554)->/127.0.0.2:7012-URGENT_MESSAGES-d542daa3 successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:28,934 - INFO  [node1_Messaging-EventLoop-3-8:OutboundConnection$1Initiate@1150] - /127.0.0.1:7012(/127.0.0.1:39180)->/127.0.0.3:7012-URGENT_MESSAGES-6190461d successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:28,939 - INFO  [node2_Messaging-EventLoop-3-4:InboundConnectionInitiator$Handler@464] - /127.0.0.1:7012(/127.0.0.1:50554)->/127.0.0.2:7012-URGENT_MESSAGES-528f13d3 messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:28,941 - INFO  [node3_Messaging-EventLoop-3-4:InboundConnectionInitiator$Handler@464] - /127.0.0.1:7012(/127.0.0.1:39180)->/127.0.0.3:7012-URGENT_MESSAGES-2cbd81c7 messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:28,945 - DEBUG [node2_GossipStage:1:GossipDigestAckVerbHandler@59] - Received an ack from /127.0.0.1:7012, which may trigger exit from shadow round
2023-05-30 19:58:28,946 - DEBUG [node2_GossipStage:1:Gossiper@2067] - Received a regular ack from /127.0.0.1:7012, can now exit shadow round
2023-05-30 19:58:28,948 - DEBUG [node3_GossipStage:1:GossipDigestAckVerbHandler@59] - Received an ack from /127.0.0.1:7012, which may trigger exit from shadow round
2023-05-30 19:58:28,948 - DEBUG [node3_GossipStage:1:Gossiper@2067] - Received a regular ack from /127.0.0.1:7012, can now exit shadow round
2023-05-30 19:58:29,795 - INFO  [node3_isolatedExecutor:2:StorageService@960] - Starting up server gossip
2023-05-30 19:58:29,795 - INFO  [node2_isolatedExecutor:2:StorageService@960] - Starting up server gossip
2023-05-30 19:58:29,799 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@878] - Enqueuing flush of local: 2.337KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:29,799 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@878] - Enqueuing flush of local: 2.338KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:29,851 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-local@114989188(0.426KiB serialized bytes, 4 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:29,851 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-local@834049911(0.426KiB serialized bytes, 4 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:29,854 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-1-big-Data.db (0.218KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=653)
2023-05-30 19:58:29,854 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-1-big-Data.db (0.218KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=653)
2023-05-30 19:58:29,922 - INFO  [node2_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb_txn_flush_e03947b0-ff45-11ed-8fcf-679a97013a80.log 
2023-05-30 19:58:29,922 - INFO  [node3_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb_txn_flush_e03947b0-ff45-11ed-b37f-c54689fc3e92.log 
2023-05-30 19:58:29,925 - INFO  [node3_MemtableFlushWriter:1:CacheService@103] - Initializing key cache with capacity of 50 MBs.
2023-05-30 19:58:29,925 - INFO  [node2_MemtableFlushWriter:1:CacheService@103] - Initializing key cache with capacity of 50 MBs.
2023-05-30 19:58:29,932 - INFO  [node2_MemtableFlushWriter:1:CacheService@125] - Initializing row cache with capacity of 0 MBs
2023-05-30 19:58:29,932 - INFO  [node3_MemtableFlushWriter:1:CacheService@125] - Initializing row cache with capacity of 0 MBs
2023-05-30 19:58:29,933 - INFO  [node2_MemtableFlushWriter:1:CacheService@154] - Initializing counter cache with capacity of 50 MBs
2023-05-30 19:58:29,933 - INFO  [node3_MemtableFlushWriter:1:CacheService@154] - Initializing counter cache with capacity of 50 MBs
2023-05-30 19:58:29,933 - INFO  [node2_MemtableFlushWriter:1:CacheService@165] - Scheduling counter cache save to every 7200 seconds (going to save all keys).
2023-05-30 19:58:29,933 - INFO  [node3_MemtableFlushWriter:1:CacheService@165] - Scheduling counter cache save to every 7200 seconds (going to save all keys).
2023-05-30 19:58:29,947 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-1-big-Data.db')] (1 sstables, 5.865KiB), biggest 5.865KiB, smallest 5.865KiB
2023-05-30 19:58:29,947 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-1-big-Data.db')] (1 sstables, 5.865KiB), biggest 5.865KiB, smallest 5.865KiB
2023-05-30 19:58:29,950 - DEBUG [node2_isolatedExecutor:2:StorageService@2399] - Ignoring application state INTERNAL_ADDRESS_AND_PORT from /127.0.0.2:7012 because it is not a member in token metadata
2023-05-30 19:58:29,950 - DEBUG [node3_isolatedExecutor:2:StorageService@2399] - Ignoring application state INTERNAL_ADDRESS_AND_PORT from /127.0.0.3:7012 because it is not a member in token metadata
2023-05-30 19:58:29,950 - DEBUG [node3_isolatedExecutor:2:StorageService@2399] - Ignoring application state INTERNAL_IP from /127.0.0.3:7012 because it is not a member in token metadata
2023-05-30 19:58:29,950 - DEBUG [node2_isolatedExecutor:2:StorageService@2399] - Ignoring application state INTERNAL_IP from /127.0.0.2:7012 because it is not a member in token metadata
2023-05-30 19:58:29,951 - DEBUG [node3_isolatedExecutor:2:StorageService@2399] - Ignoring application state DC from /127.0.0.3:7012 because it is not a member in token metadata
2023-05-30 19:58:29,951 - DEBUG [node2_isolatedExecutor:2:StorageService@2399] - Ignoring application state DC from /127.0.0.2:7012 because it is not a member in token metadata
2023-05-30 19:58:29,951 - DEBUG [node3_isolatedExecutor:2:StorageService@2399] - Ignoring application state RACK from /127.0.0.3:7012 because it is not a member in token metadata
2023-05-30 19:58:29,951 - DEBUG [node2_isolatedExecutor:2:StorageService@2399] - Ignoring application state RACK from /127.0.0.2:7012 because it is not a member in token metadata
2023-05-30 19:58:29,954 - DEBUG [node3_isolatedExecutor:2:StorageService@2399] - Ignoring application state SCHEMA from /127.0.0.3:7012 because it is not a member in token metadata
2023-05-30 19:58:29,954 - DEBUG [node2_isolatedExecutor:2:StorageService@2399] - Ignoring application state SCHEMA from /127.0.0.2:7012 because it is not a member in token metadata
2023-05-30 19:58:29,983 - DEBUG [node3_isolatedExecutor:2:StorageService@1042] - Bootstrap variables: false false false false
2023-05-30 19:58:29,984 - DEBUG [node2_isolatedExecutor:2:StorageService@1042] - Bootstrap variables: false false false false
2023-05-30 19:58:29,986 - INFO  [node3_isolatedExecutor:2:BootStrapper@194] - tokens manually specified as [9223372036854775805]
2023-05-30 19:58:29,988 - INFO  [node2_isolatedExecutor:2:BootStrapper@194] - tokens manually specified as [3074457345618258601]
2023-05-30 19:58:30,027 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of columns: 43.419KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:30,031 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-columns@1203411346(9.073KiB serialized bytes, 59 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:30,035 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-1-big-Data.db (4.347KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=11295)
2023-05-30 19:58:30,048 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of columns: 43.416KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:30,068 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-columns@1409700293(9.073KiB serialized bytes, 59 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:30,071 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-1-big-Data.db (4.347KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=11295)
2023-05-30 19:58:30,110 - INFO  [node3_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node3/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb_txn_flush_e05b9cc0-ff45-11ed-b37f-c54689fc3e92.log 
2023-05-30 19:58:30,112 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-1-big-Data.db')] (1 sstables, 6.835KiB), biggest 6.835KiB, smallest 6.835KiB
2023-05-30 19:58:30,113 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in dropped_columns
2023-05-30 19:58:30,113 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in triggers
2023-05-30 19:58:30,114 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in types
2023-05-30 19:58:30,114 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in functions
2023-05-30 19:58:30,114 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in aggregates
2023-05-30 19:58:30,114 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in indexes
2023-05-30 19:58:30,114 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of tables: 23.657KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:30,133 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-tables@1233991888(7.291KiB serialized bytes, 10 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:30,134 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-1-big-Data.db (4.543KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=11295)
2023-05-30 19:58:30,149 - INFO  [node2_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node2/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb_txn_flush_e05ed110-ff45-11ed-8fcf-679a97013a80.log 
2023-05-30 19:58:30,151 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-1-big-Data.db')] (1 sstables, 6.835KiB), biggest 6.835KiB, smallest 6.835KiB
2023-05-30 19:58:30,152 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in dropped_columns
2023-05-30 19:58:30,152 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in triggers
2023-05-30 19:58:30,152 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in types
2023-05-30 19:58:30,152 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in functions
2023-05-30 19:58:30,152 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in aggregates
2023-05-30 19:58:30,153 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in indexes
2023-05-30 19:58:30,153 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of tables: 23.654KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:30,172 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-tables@869271783(7.291KiB serialized bytes, 10 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:30,173 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-1-big-Data.db (4.543KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=11295)
2023-05-30 19:58:30,206 - INFO  [node3_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node3/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb_txn_flush_e068e330-ff45-11ed-b37f-c54689fc3e92.log 
2023-05-30 19:58:30,207 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-1-big-Data.db')] (1 sstables, 7.638KiB), biggest 7.638KiB, smallest 7.638KiB
2023-05-30 19:58:30,208 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in views
2023-05-30 19:58:30,208 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of keyspaces: 1.931KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:30,227 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-keyspaces@413069419(0.437KiB serialized bytes, 3 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:30,227 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-1-big-Data.db (0.363KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=11295)
2023-05-30 19:58:30,243 - INFO  [node2_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node2/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb_txn_flush_e06eaf90-ff45-11ed-8fcf-679a97013a80.log 
2023-05-30 19:58:30,245 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-1-big-Data.db')] (1 sstables, 7.638KiB), biggest 7.638KiB, smallest 7.638KiB
2023-05-30 19:58:30,245 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in views
2023-05-30 19:58:30,245 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of keyspaces: 1.928KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:30,264 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-keyspaces@2021724149(0.437KiB serialized bytes, 3 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:30,265 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-1-big-Data.db (0.363KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=11295)
2023-05-30 19:58:30,298 - INFO  [node3_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node3/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb_txn_flush_e0771400-ff45-11ed-b37f-c54689fc3e92.log 
2023-05-30 19:58:30,299 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-1-big-Data.db')] (1 sstables, 5.267KiB), biggest 5.267KiB, smallest 5.267KiB
2023-05-30 19:58:30,323 - INFO  [node2_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node2/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb_txn_flush_e07ce060-ff45-11ed-8fcf-679a97013a80.log 
2023-05-30 19:58:30,325 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-1-big-Data.db')] (1 sstables, 5.267KiB), biggest 5.267KiB, smallest 5.267KiB
2023-05-30 19:58:30,351 - INFO  [node3_MigrationStage:1:Keyspace@386] - Creating replication strategy system_auth params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}
2023-05-30 19:58:30,351 - DEBUG [node3_MigrationStage:1:Keyspace@390] - New replication settings for keyspace system_auth - invalidating disk boundary caches
2023-05-30 19:58:30,352 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.network_permissions
2023-05-30 19:58:30,353 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.network_permissions
2023-05-30 19:58:30,354 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,354 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.network_permissions
2023-05-30 19:58:30,356 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.resource_role_permissons_index
2023-05-30 19:58:30,356 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.resource_role_permissons_index
2023-05-30 19:58:30,356 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,356 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.resource_role_permissons_index
2023-05-30 19:58:30,358 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.role_members
2023-05-30 19:58:30,359 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.role_members
2023-05-30 19:58:30,359 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,359 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.role_members
2023-05-30 19:58:30,361 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.role_permissions
2023-05-30 19:58:30,361 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.role_permissions
2023-05-30 19:58:30,361 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,361 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.role_permissions
2023-05-30 19:58:30,363 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.roles
2023-05-30 19:58:30,363 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.roles
2023-05-30 19:58:30,364 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,364 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.roles
2023-05-30 19:58:30,371 - INFO  [node3_MigrationStage:1:Keyspace@386] - Creating replication strategy system_distributed params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}
2023-05-30 19:58:30,371 - DEBUG [node3_MigrationStage:1:Keyspace@390] - New replication settings for keyspace system_distributed - invalidating disk boundary caches
2023-05-30 19:58:30,372 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_distributed.parent_repair_history
2023-05-30 19:58:30,373 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.parent_repair_history
2023-05-30 19:58:30,373 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,373 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_distributed.parent_repair_history
2023-05-30 19:58:30,374 - DEBUG [node3_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,374 - DEBUG [node3_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,374 - DEBUG [node3_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,374 - DEBUG [node3_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,374 - DEBUG [node3_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,374 - DEBUG [node3_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,376 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_distributed.repair_history
2023-05-30 19:58:30,376 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.repair_history
2023-05-30 19:58:30,377 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,377 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_distributed.repair_history
2023-05-30 19:58:30,377 - DEBUG [node3_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,377 - DEBUG [node3_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,377 - DEBUG [node3_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,377 - DEBUG [node3_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,377 - DEBUG [node3_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,377 - DEBUG [node3_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,379 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_distributed.view_build_status
2023-05-30 19:58:30,379 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.view_build_status
2023-05-30 19:58:30,379 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,380 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_distributed.view_build_status
2023-05-30 19:58:30,381 - INFO  [node3_MigrationStage:1:Keyspace@386] - Creating replication strategy system_traces params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=2}}
2023-05-30 19:58:30,381 - DEBUG [node3_MigrationStage:1:Keyspace@390] - New replication settings for keyspace system_traces - invalidating disk boundary caches
2023-05-30 19:58:30,382 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_traces.events
2023-05-30 19:58:30,383 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_traces.events
2023-05-30 19:58:30,383 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,383 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_traces.events
2023-05-30 19:58:30,385 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_traces.sessions
2023-05-30 19:58:30,385 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_traces.sessions
2023-05-30 19:58:30,386 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,386 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_traces.sessions
2023-05-30 19:58:30,387 - INFO  [node2_MigrationStage:1:Keyspace@386] - Creating replication strategy system_auth params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}
2023-05-30 19:58:30,388 - DEBUG [node2_MigrationStage:1:Keyspace@390] - New replication settings for keyspace system_auth - invalidating disk boundary caches
2023-05-30 19:58:30,389 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.network_permissions
2023-05-30 19:58:30,389 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.network_permissions
2023-05-30 19:58:30,390 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,390 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.network_permissions
2023-05-30 19:58:30,392 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.resource_role_permissons_index
2023-05-30 19:58:30,393 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.resource_role_permissons_index
2023-05-30 19:58:30,393 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,393 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.resource_role_permissons_index
2023-05-30 19:58:30,396 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.role_members
2023-05-30 19:58:30,397 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.role_members
2023-05-30 19:58:30,397 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,397 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.role_members
2023-05-30 19:58:30,400 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.role_permissions
2023-05-30 19:58:30,400 - DEBUG [node3_MigrationStage:1:StorageService@2399] - Ignoring application state SCHEMA from /127.0.0.3:7012 because it is not a member in token metadata
2023-05-30 19:58:30,400 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.role_permissions
2023-05-30 19:58:30,400 - INFO  [node3_isolatedExecutor:2:StorageService@1634] - JOINING: Finish joining ring
2023-05-30 19:58:30,400 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,401 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.role_permissions
2023-05-30 19:58:30,403 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_auth.roles
2023-05-30 19:58:30,403 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@878] - Enqueuing flush of local: 0.604KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:30,403 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.roles
2023-05-30 19:58:30,403 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,403 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_auth.roles
2023-05-30 19:58:30,407 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-local@439185567(0.084KiB serialized bytes, 3 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:30,407 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-2-big-Data.db (0.056KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=11467)
2023-05-30 19:58:30,411 - INFO  [node2_MigrationStage:1:Keyspace@386] - Creating replication strategy system_distributed params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}
2023-05-30 19:58:30,411 - DEBUG [node2_MigrationStage:1:Keyspace@390] - New replication settings for keyspace system_distributed - invalidating disk boundary caches
2023-05-30 19:58:30,412 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_distributed.parent_repair_history
2023-05-30 19:58:30,412 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.parent_repair_history
2023-05-30 19:58:30,413 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,413 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_distributed.parent_repair_history
2023-05-30 19:58:30,413 - DEBUG [node2_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,414 - DEBUG [node2_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,414 - DEBUG [node2_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,414 - DEBUG [node2_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,414 - DEBUG [node2_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,414 - DEBUG [node2_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,416 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_distributed.repair_history
2023-05-30 19:58:30,417 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.repair_history
2023-05-30 19:58:30,417 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,417 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_distributed.repair_history
2023-05-30 19:58:30,417 - DEBUG [node2_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,417 - DEBUG [node2_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,417 - DEBUG [node2_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,417 - DEBUG [node2_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,417 - DEBUG [node2_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,417 - DEBUG [node2_MigrationStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:30,420 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_distributed.view_build_status
2023-05-30 19:58:30,420 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.view_build_status
2023-05-30 19:58:30,420 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,420 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_distributed.view_build_status
2023-05-30 19:58:30,422 - INFO  [node2_MigrationStage:1:Keyspace@386] - Creating replication strategy system_traces params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=2}}
2023-05-30 19:58:30,422 - DEBUG [node2_MigrationStage:1:Keyspace@390] - New replication settings for keyspace system_traces - invalidating disk boundary caches
2023-05-30 19:58:30,424 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_traces.events
2023-05-30 19:58:30,424 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_traces.events
2023-05-30 19:58:30,424 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,424 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_traces.events
2023-05-30 19:58:30,426 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@385] - Initializing system_traces.sessions
2023-05-30 19:58:30,427 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_traces.sessions
2023-05-30 19:58:30,427 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [] (ringVersion = 0)
2023-05-30 19:58:30,427 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} for system_traces.sessions
2023-05-30 19:58:30,449 - DEBUG [node2_MigrationStage:1:StorageService@2399] - Ignoring application state SCHEMA from /127.0.0.2:7012 because it is not a member in token metadata
2023-05-30 19:58:30,449 - INFO  [node2_isolatedExecutor:2:StorageService@1634] - JOINING: Finish joining ring
2023-05-30 19:58:30,457 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@878] - Enqueuing flush of local: 0.604KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:30,469 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-local@759287541(0.084KiB serialized bytes, 3 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:30,469 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-2-big-Data.db (0.056KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=11467)
2023-05-30 19:58:30,485 - INFO  [node3_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb_txn_flush_e094d530-ff45-11ed-b37f-c54689fc3e92.log 
2023-05-30 19:58:30,487 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-2-big-Data.db')] (1 sstables, 4.954KiB), biggest 4.954KiB, smallest 4.954KiB
2023-05-30 19:58:30,489 - DEBUG [node3_isolatedExecutor:2:StorageService@307] - Setting tokens to [9223372036854775805]
2023-05-30 19:58:30,503 - INFO  [node3_isolatedExecutor:2:ColumnFamilyStore@878] - Enqueuing flush of local: 0.601KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:30,514 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-local@155716673(0.074KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:30,515 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-3-big-Data.db (0.047KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=11559)
2023-05-30 19:58:30,548 - INFO  [node2_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb_txn_flush_e09d39a0-ff45-11ed-8fcf-679a97013a80.log 
2023-05-30 19:58:30,557 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-2-big-Data.db')] (1 sstables, 4.954KiB), biggest 4.954KiB, smallest 4.954KiB
2023-05-30 19:58:30,561 - DEBUG [node2_isolatedExecutor:2:StorageService@307] - Setting tokens to [3074457345618258601]
2023-05-30 19:58:30,576 - INFO  [node2_isolatedExecutor:2:ColumnFamilyStore@878] - Enqueuing flush of local: 0.600KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:30,587 - INFO  [node3_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb_txn_flush_e0a41770-ff45-11ed-b37f-c54689fc3e92.log 
2023-05-30 19:58:30,588 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-local@1269770977(0.074KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (null, null]
2023-05-30 19:58:30,588 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-3-big-Data.db')] (1 sstables, 4.943KiB), biggest 4.943KiB, smallest 4.943KiB
2023-05-30 19:58:30,588 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-3-big-Data.db (0.047KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=11559)
2023-05-30 19:58:30,592 - DEBUG [node3_isolatedExecutor:2:StorageService@2399] - Ignoring application state TOKENS from /127.0.0.3:7012 because it is not a member in token metadata
2023-05-30 19:58:30,592 - DEBUG [node3_isolatedExecutor:2:StorageService@2782] - Node /127.0.0.3:7012 state NORMAL, token [9223372036854775805]
2023-05-30 19:58:30,593 - DEBUG [node3_isolatedExecutor:2:StorageService@2697] - New node /127.0.0.3:7012 at token 9223372036854775805
2023-05-30 19:58:30,597 - DEBUG [node3_isolatedExecutor:2:StorageService@2782] - Node /127.0.0.3:7012 state NORMAL, token [9223372036854775805]
2023-05-30 19:58:30,597 - INFO  [node3_isolatedExecutor:2:StorageService@2785] - Node /127.0.0.3:7012 state jump to NORMAL
2023-05-30 19:58:30,598 - DEBUG [node3_isolatedExecutor:2:StorageService@1636] - NORMAL
2023-05-30 19:58:30,598 - INFO  [node3_isolatedExecutor:2:Gossiper@2214] - Waiting for gossip to settle...
2023-05-30 19:58:30,656 - INFO  [node2_MemtableFlushWriter:1:LogTransaction@240] - Unfinished transaction log, deleting /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb_txn_flush_e0af6210-ff45-11ed-8fcf-679a97013a80.log 
2023-05-30 19:58:30,657 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-3-big-Data.db')] (1 sstables, 4.943KiB), biggest 4.943KiB, smallest 4.943KiB
2023-05-30 19:58:30,660 - DEBUG [node2_isolatedExecutor:2:StorageService@2399] - Ignoring application state TOKENS from /127.0.0.2:7012 because it is not a member in token metadata
2023-05-30 19:58:30,661 - DEBUG [node2_isolatedExecutor:2:StorageService@2782] - Node /127.0.0.2:7012 state NORMAL, token [3074457345618258601]
2023-05-30 19:58:30,661 - DEBUG [node2_isolatedExecutor:2:StorageService@2697] - New node /127.0.0.2:7012 at token 3074457345618258601
2023-05-30 19:58:30,665 - DEBUG [node2_isolatedExecutor:2:StorageService@2782] - Node /127.0.0.2:7012 state NORMAL, token [3074457345618258601]
2023-05-30 19:58:30,665 - INFO  [node2_isolatedExecutor:2:StorageService@2785] - Node /127.0.0.2:7012 state jump to NORMAL
2023-05-30 19:58:30,666 - DEBUG [node2_isolatedExecutor:2:StorageService@1636] - NORMAL
2023-05-30 19:58:30,667 - INFO  [node2_isolatedExecutor:2:Gossiper@2214] - Waiting for gossip to settle...
2023-05-30 19:58:30,957 - INFO  [node1_GossipStage:1:Gossiper@1364] - Node /127.0.0.2:7012 is now part of the cluster
2023-05-30 19:58:30,958 - DEBUG [node1_GossipStage:1:StorageService@2782] - Node /127.0.0.2:7012 state NORMAL, token [3074457345618258601]
2023-05-30 19:58:30,968 - DEBUG [node1_GossipStage:1:StorageService@2697] - New node /127.0.0.2:7012 at token 3074457345618258601
2023-05-30 19:58:30,971 - INFO  [node1_GossipStage:1:TokenMetadata@511] - Updating topology for /127.0.0.2:7012
2023-05-30 19:58:30,973 - INFO  [node1_GossipStage:1:TokenMetadata@511] - Updating topology for /127.0.0.2:7012
2023-05-30 19:58:30,979 - INFO  [node1_GossipStage:1:Gossiper@1364] - Node /127.0.0.3:7012 is now part of the cluster
2023-05-30 19:58:30,979 - DEBUG [node1_GossipStage:1:StorageService@2782] - Node /127.0.0.3:7012 state NORMAL, token [9223372036854775805]
2023-05-30 19:58:30,993 - DEBUG [node1_GossipStage:1:StorageService@2697] - New node /127.0.0.3:7012 at token 9223372036854775805
2023-05-30 19:58:30,995 - INFO  [node1_GossipStage:1:TokenMetadata@511] - Updating topology for /127.0.0.3:7012
2023-05-30 19:58:31,000 - INFO  [node1_GossipStage:1:TokenMetadata@511] - Updating topology for /127.0.0.3:7012
2023-05-30 19:58:31,002 - DEBUG [node1_GossipStage:1:Gossiper@1311] - removing expire time for endpoint : /127.0.0.2:7012
2023-05-30 19:58:31,002 - INFO  [node1_GossipStage:1:Gossiper@1312] - InetAddress /127.0.0.2:7012 is now UP
2023-05-30 19:58:31,003 - DEBUG [node1_GossipStage:1:Gossiper@1311] - removing expire time for endpoint : /127.0.0.3:7012
2023-05-30 19:58:31,003 - INFO  [node1_GossipStage:1:Gossiper@1312] - InetAddress /127.0.0.3:7012 is now UP
2023-05-30 19:58:31,625 - WARN  [node1_GossipTasks:1:FailureDetector@319] - Not marking nodes down due to local pause of 14622096769ns > 5000000000ns
2023-05-30 19:58:31,625 - WARN  [node1_GossipTasks:1:FailureDetector@319] - Not marking nodes down due to local pause of 14622096769ns > 5000000000ns
2023-05-30 19:58:31,625 - DEBUG [node1_GossipTasks:1:FailureDetector@325] - Still not marking nodes down due to local pause
2023-05-30 19:58:31,629 - INFO  [node2_GossipStage:1:Gossiper@1364] - Node /127.0.0.3:7012 is now part of the cluster
2023-05-30 19:58:31,631 - DEBUG [node2_GossipStage:1:StorageService@2782] - Node /127.0.0.3:7012 state NORMAL, token [9223372036854775805]
2023-05-30 19:58:31,634 - INFO  [node2_Messaging-EventLoop-3-7:OutboundConnection$1Initiate@1150] - /127.0.0.2:7012(/127.0.0.1:39184)->/127.0.0.3:7012-URGENT_MESSAGES-bbfb4efb successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:31,634 - INFO  [node3_Messaging-EventLoop-3-5:InboundConnectionInitiator$Handler@464] - /127.0.0.2:7012(/127.0.0.1:39184)->/127.0.0.3:7012-URGENT_MESSAGES-fadc910e messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:31,639 - INFO  [node3_Messaging-EventLoop-3-8:OutboundConnection$1Initiate@1150] - /127.0.0.3:7012(/127.0.0.1:50560)->/127.0.0.2:7012-URGENT_MESSAGES-153e1d43 successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:31,639 - INFO  [node2_Messaging-EventLoop-3-8:InboundConnectionInitiator$Handler@464] - /127.0.0.3:7012(/127.0.0.1:50560)->/127.0.0.2:7012-URGENT_MESSAGES-2d4151a0 messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:31,650 - DEBUG [node2_GossipStage:1:StorageService@2697] - New node /127.0.0.3:7012 at token 9223372036854775805
2023-05-30 19:58:31,654 - INFO  [node2_GossipStage:1:TokenMetadata@511] - Updating topology for /127.0.0.3:7012
2023-05-30 19:58:31,656 - INFO  [node2_GossipStage:1:TokenMetadata@511] - Updating topology for /127.0.0.3:7012
2023-05-30 19:58:31,661 - INFO  [node2_GossipStage:1:Gossiper@1364] - Node /127.0.0.1:7012 is now part of the cluster
2023-05-30 19:58:31,661 - DEBUG [node2_GossipStage:1:StorageService@2782] - Node /127.0.0.1:7012 state NORMAL, token [-3074457345618258603]
2023-05-30 19:58:31,667 - DEBUG [node2_GossipStage:1:StorageService@2697] - New node /127.0.0.1:7012 at token -3074457345618258603
2023-05-30 19:58:31,672 - INFO  [node2_GossipStage:1:TokenMetadata@511] - Updating topology for /127.0.0.1:7012
2023-05-30 19:58:31,674 - INFO  [node2_GossipStage:1:TokenMetadata@511] - Updating topology for /127.0.0.1:7012
2023-05-30 19:58:31,676 - DEBUG [node2_GossipStage:1:Gossiper@1311] - removing expire time for endpoint : /127.0.0.3:7012
2023-05-30 19:58:31,676 - INFO  [node2_GossipStage:1:Gossiper@1312] - InetAddress /127.0.0.3:7012 is now UP
2023-05-30 19:58:31,677 - DEBUG [node2_GossipStage:1:Gossiper@1311] - removing expire time for endpoint : /127.0.0.1:7012
2023-05-30 19:58:31,677 - INFO  [node2_GossipStage:1:Gossiper@1312] - InetAddress /127.0.0.1:7012 is now UP
2023-05-30 19:58:31,959 - INFO  [node3_GossipStage:1:Gossiper@1364] - Node /127.0.0.2:7012 is now part of the cluster
2023-05-30 19:58:31,960 - DEBUG [node3_GossipStage:1:StorageService@2782] - Node /127.0.0.2:7012 state NORMAL, token [3074457345618258601]
2023-05-30 19:58:31,977 - DEBUG [node3_GossipStage:1:StorageService@2697] - New node /127.0.0.2:7012 at token 3074457345618258601
2023-05-30 19:58:31,981 - INFO  [node3_GossipStage:1:TokenMetadata@511] - Updating topology for /127.0.0.2:7012
2023-05-30 19:58:31,982 - INFO  [node3_GossipStage:1:TokenMetadata@511] - Updating topology for /127.0.0.2:7012
2023-05-30 19:58:31,988 - INFO  [node3_GossipStage:1:Gossiper@1364] - Node /127.0.0.1:7012 is now part of the cluster
2023-05-30 19:58:31,989 - DEBUG [node3_GossipStage:1:StorageService@2782] - Node /127.0.0.1:7012 state NORMAL, token [-3074457345618258603]
2023-05-30 19:58:31,994 - DEBUG [node3_GossipStage:1:StorageService@2697] - New node /127.0.0.1:7012 at token -3074457345618258603
2023-05-30 19:58:31,997 - INFO  [node3_GossipStage:1:TokenMetadata@511] - Updating topology for /127.0.0.1:7012
2023-05-30 19:58:31,998 - INFO  [node3_GossipStage:1:TokenMetadata@511] - Updating topology for /127.0.0.1:7012
2023-05-30 19:58:32,003 - DEBUG [node3_GossipStage:1:Gossiper@1311] - removing expire time for endpoint : /127.0.0.2:7012
2023-05-30 19:58:32,003 - INFO  [node3_GossipStage:1:Gossiper@1312] - InetAddress /127.0.0.2:7012 is now UP
2023-05-30 19:58:32,004 - DEBUG [node3_GossipStage:1:Gossiper@1311] - removing expire time for endpoint : /127.0.0.1:7012
2023-05-30 19:58:32,004 - INFO  [node3_GossipStage:1:Gossiper@1312] - InetAddress /127.0.0.1:7012 is now UP
2023-05-30 19:58:32,615 - DEBUG [node1_BatchlogTasks:1:BatchlogManager@244] - Updating batchlog replay throttle to 1024 KB/s, 341 KB/s per endpoint
2023-05-30 19:58:32,626 - DEBUG [node1_GossipTasks:1:FailureDetector@325] - Still not marking nodes down due to local pause
2023-05-30 19:58:32,626 - DEBUG [node1_GossipTasks:1:FailureDetector@325] - Still not marking nodes down due to local pause
2023-05-30 19:58:33,627 - DEBUG [node1_GossipTasks:1:FailureDetector@325] - Still not marking nodes down due to local pause
2023-05-30 19:58:33,627 - DEBUG [node1_GossipTasks:1:FailureDetector@325] - Still not marking nodes down due to local pause
2023-05-30 19:58:34,627 - DEBUG [node1_GossipTasks:1:FailureDetector@325] - Still not marking nodes down due to local pause
2023-05-30 19:58:34,628 - DEBUG [node1_GossipTasks:1:FailureDetector@325] - Still not marking nodes down due to local pause
2023-05-30 19:58:35,628 - DEBUG [node1_GossipTasks:1:FailureDetector@325] - Still not marking nodes down due to local pause
2023-05-30 19:58:35,628 - DEBUG [node1_GossipTasks:1:FailureDetector@325] - Still not marking nodes down due to local pause
2023-05-30 19:58:36,255 - INFO  [node2_Messaging-EventLoop-3-9:InboundConnectionInitiator$Handler@464] - /127.0.0.1:7012(/127.0.0.1:50562)->/127.0.0.2:7012-SMALL_MESSAGES-fa14d004 messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:36,255 - INFO  [node1_Messaging-EventLoop-3-3:OutboundConnection$1Initiate@1150] - /127.0.0.1:7012(/127.0.0.1:50562)->/127.0.0.2:7012-SMALL_MESSAGES-7b311647 successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:36,266 - INFO  [node1_Messaging-EventLoop-3-9:InboundConnectionInitiator$Handler@464] - /127.0.0.2:7012(/127.0.0.1:50932)->/127.0.0.1:7012-SMALL_MESSAGES-f6192246 messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:36,266 - INFO  [node2_Messaging-EventLoop-3-1:OutboundConnection$1Initiate@1150] - /127.0.0.2:7012(/127.0.0.1:50932)->/127.0.0.1:7012-SMALL_MESSAGES-ace58f87 successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:36,290 - INFO  [node3_Messaging-EventLoop-3-9:InboundConnectionInitiator$Handler@464] - /127.0.0.1:7012(/127.0.0.1:39192)->/127.0.0.3:7012-SMALL_MESSAGES-0a27167e messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:36,291 - INFO  [node1_Messaging-EventLoop-3-6:OutboundConnection$1Initiate@1150] - /127.0.0.1:7012(/127.0.0.1:39192)->/127.0.0.3:7012-SMALL_MESSAGES-22ba8d2f successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:36,303 - INFO  [node1_Messaging-EventLoop-3-10:InboundConnectionInitiator$Handler@464] - /127.0.0.3:7012(/127.0.0.1:50936)->/127.0.0.1:7012-SMALL_MESSAGES-36bfca1e messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:36,303 - INFO  [node3_Messaging-EventLoop-3-1:OutboundConnection$1Initiate@1150] - /127.0.0.3:7012(/127.0.0.1:50936)->/127.0.0.1:7012-SMALL_MESSAGES-9181385c successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:36,405 - WARN  [node1_OptionalTasks:1:FBUtilities@379] - Trigger directory doesn't exist, please create it and try again.
2023-05-30 19:58:36,405 - WARN  [node1_OptionalTasks:1:FBUtilities@379] - Trigger directory doesn't exist, please create it and try again.
2023-05-30 19:58:36,417 - INFO  [node1_OptionalTasks:1:CassandraRoleManager@339] - Created default superuser role 'cassandra'
2023-05-30 19:58:36,599 - DEBUG [node3_isolatedExecutor:2:Gossiper@2226] - Gossip looks settled.
2023-05-30 19:58:36,667 - DEBUG [node2_isolatedExecutor:2:Gossiper@2226] - Gossip looks settled.
2023-05-30 19:58:37,599 - DEBUG [node3_isolatedExecutor:2:Gossiper@2226] - Gossip looks settled.
2023-05-30 19:58:37,668 - DEBUG [node2_isolatedExecutor:2:Gossiper@2226] - Gossip looks settled.
2023-05-30 19:58:38,600 - DEBUG [node3_isolatedExecutor:2:Gossiper@2226] - Gossip looks settled.
2023-05-30 19:58:38,600 - INFO  [node3_isolatedExecutor:2:Gossiper@2245] - No gossip backlog; proceeding
2023-05-30 19:58:38,600 - INFO  [node3_isolatedExecutor:2:StorageService@838] - Populating token metadata from system tables
2023-05-30 19:58:38,605 - INFO  [node3_isolatedExecutor:2:StorageService@832] - Token metadata: Normal Tokens:
/127.0.0.1:7012:[-3074457345618258603]
/127.0.0.2:7012:[3074457345618258601]
/127.0.0.3:7012:[9223372036854775805]
Pending Ranges:

2023-05-30 19:58:38,668 - DEBUG [node2_isolatedExecutor:2:Gossiper@2226] - Gossip looks settled.
2023-05-30 19:58:38,668 - INFO  [node2_isolatedExecutor:2:Gossiper@2245] - No gossip backlog; proceeding
2023-05-30 19:58:38,668 - INFO  [node2_isolatedExecutor:2:StorageService@838] - Populating token metadata from system tables
2023-05-30 19:58:38,672 - INFO  [node2_isolatedExecutor:2:StorageService@832] - Token metadata: Normal Tokens:
/127.0.0.1:7012:[-3074457345618258603]
/127.0.0.2:7012:[3074457345618258601]
/127.0.0.3:7012:[9223372036854775805]
Pending Ranges:

2023-05-30 19:58:38,740 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of columns: 156.707KiB (2%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:38,740 - DEBUG [node1_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.columns.
2023-05-30 19:58:38,740 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.columns
2023-05-30 19:58:38,741 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:38,742 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_schema.columns
2023-05-30 19:58:38,745 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-columns@143823983(32.921KiB serialized bytes, 218 ops, 2%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:38,748 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-2-big-Data.db (15.023KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=47152)
2023-05-30 19:58:38,813 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-2-big-Data.db')] (1 sstables, 10.168KiB), biggest 10.168KiB, smallest 10.168KiB
2023-05-30 19:58:38,814 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of dropped_columns: 1.081KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:38,815 - DEBUG [node1_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.dropped_columns.
2023-05-30 19:58:38,815 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.dropped_columns
2023-05-30 19:58:38,815 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:38,815 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_schema.dropped_columns
2023-05-30 19:58:38,818 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-dropped_columns@1809856103(0.120KiB serialized bytes, 3 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:38,819 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/dropped_columns-5e7583b5f3f43af19a39b7e1d6f5f11f/nb-1-big-Data.db (0.097KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=47152)
2023-05-30 19:58:38,886 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/dropped_columns-5e7583b5f3f43af19a39b7e1d6f5f11f/nb-1-big-Data.db')] (1 sstables, 5.209KiB), biggest 5.209KiB, smallest 5.209KiB
2023-05-30 19:58:38,887 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of triggers: 0.513KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:38,887 - DEBUG [node1_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.triggers.
2023-05-30 19:58:38,887 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.triggers
2023-05-30 19:58:38,888 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:38,888 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_schema.triggers
2023-05-30 19:58:38,890 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-triggers@431382828(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:38,891 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/triggers-4df70b666b05325195a132b54005fd48/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=47152)
2023-05-30 19:58:38,959 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/triggers-4df70b666b05325195a132b54005fd48/nb-1-big-Data.db')] (1 sstables, 4.971KiB), biggest 4.971KiB, smallest 4.971KiB
2023-05-30 19:58:38,960 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of types: 0.513KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:38,960 - DEBUG [node1_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.types.
2023-05-30 19:58:38,960 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.types
2023-05-30 19:58:38,960 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:38,960 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_schema.types
2023-05-30 19:58:38,964 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-types@1301128280(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:38,965 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/types-5a8b1ca866023f77a0459273d308917a/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=47152)
2023-05-30 19:58:39,032 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/types-5a8b1ca866023f77a0459273d308917a/nb-1-big-Data.db')] (1 sstables, 4.931KiB), biggest 4.931KiB, smallest 4.931KiB
2023-05-30 19:58:39,033 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of functions: 0.513KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,033 - DEBUG [node1_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.functions.
2023-05-30 19:58:39,033 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.functions
2023-05-30 19:58:39,034 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:39,034 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_schema.functions
2023-05-30 19:58:39,036 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-functions@1369464938(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,036 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/functions-96489b7980be3e14a70166a0b9159450/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=47152)
2023-05-30 19:58:39,104 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/functions-96489b7980be3e14a70166a0b9159450/nb-1-big-Data.db')] (1 sstables, 5.055KiB), biggest 5.055KiB, smallest 5.055KiB
2023-05-30 19:58:39,105 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of aggregates: 0.513KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,105 - DEBUG [node1_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.aggregates.
2023-05-30 19:58:39,105 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.aggregates
2023-05-30 19:58:39,106 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:39,106 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_schema.aggregates
2023-05-30 19:58:39,108 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-aggregates@991504183(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,108 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/aggregates-924c55872e3a345bb10c12f37c1ba895/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=47152)
2023-05-30 19:58:39,176 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/aggregates-924c55872e3a345bb10c12f37c1ba895/nb-1-big-Data.db')] (1 sstables, 5.055KiB), biggest 5.055KiB, smallest 5.055KiB
2023-05-30 19:58:39,177 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of indexes: 0.513KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,177 - DEBUG [node1_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.indexes.
2023-05-30 19:58:39,177 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.indexes
2023-05-30 19:58:39,178 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:39,178 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_schema.indexes
2023-05-30 19:58:39,180 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-indexes@294428281(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,180 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/indexes-0feb57ac311f382fba6d9024d305702f/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=47152)
2023-05-30 19:58:39,248 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/indexes-0feb57ac311f382fba6d9024d305702f/nb-1-big-Data.db')] (1 sstables, 4.971KiB), biggest 4.971KiB, smallest 4.971KiB
2023-05-30 19:58:39,248 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of tables: 69.004KiB (1%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,249 - DEBUG [node1_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.tables.
2023-05-30 19:58:39,249 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.tables
2023-05-30 19:58:39,249 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:39,249 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_schema.tables
2023-05-30 19:58:39,252 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-tables@830691188(21.567KiB serialized bytes, 32 ops, 1%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,253 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-2-big-Data.db (13.131KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=47152)
2023-05-30 19:58:39,319 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-2-big-Data.db')] (1 sstables, 8.646KiB), biggest 8.646KiB, smallest 8.646KiB
2023-05-30 19:58:39,320 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of views: 0.513KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,321 - DEBUG [node1_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.views.
2023-05-30 19:58:39,321 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.views
2023-05-30 19:58:39,321 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:39,322 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_schema.views
2023-05-30 19:58:39,324 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-views@1676857886(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,324 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/views-9786ac1cdd583201a7cdad556410c985/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=47152)
2023-05-30 19:58:39,392 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/views-9786ac1cdd583201a7cdad556410c985/nb-1-big-Data.db')] (1 sstables, 4.931KiB), biggest 4.931KiB, smallest 4.931KiB
2023-05-30 19:58:39,393 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of keyspaces: 1.972KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,393 - DEBUG [node1_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.keyspaces.
2023-05-30 19:58:39,393 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.keyspaces
2023-05-30 19:58:39,393 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:39,394 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_schema.keyspaces
2023-05-30 19:58:39,396 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-keyspaces@287334856(0.382KiB serialized bytes, 5 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,396 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-2-big-Data.db (0.313KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=47152)
2023-05-30 19:58:39,465 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-2-big-Data.db')] (1 sstables, 5.337KiB), biggest 5.337KiB, smallest 5.337KiB
2023-05-30 19:58:39,465 - INFO  [node1_MigrationStage:1:Keyspace@386] - Creating replication strategy distributed_test_keyspace params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}
2023-05-30 19:58:39,465 - DEBUG [node1_MigrationStage:1:Keyspace@390] - New replication settings for keyspace distributed_test_keyspace - invalidating disk boundary caches
2023-05-30 19:58:39,489 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of columns: 156.707KiB (2%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,489 - DEBUG [node3_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.columns.
2023-05-30 19:58:39,490 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.columns
2023-05-30 19:58:39,490 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of columns: 156.705KiB (2%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,490 - DEBUG [node2_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.columns.
2023-05-30 19:58:39,491 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.columns
2023-05-30 19:58:39,491 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,491 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,492 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.columns
2023-05-30 19:58:39,493 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.columns
2023-05-30 19:58:39,495 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-columns@698613248(32.921KiB serialized bytes, 218 ops, 2%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,496 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-columns@2022413379(32.921KiB serialized bytes, 218 ops, 2%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,499 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-2-big-Data.db (15.023KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47153)
2023-05-30 19:58:39,500 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-2-big-Data.db (15.023KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47158)
2023-05-30 19:58:39,564 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-2-big-Data.db')] (1 sstables, 10.167KiB), biggest 10.167KiB, smallest 10.167KiB
2023-05-30 19:58:39,565 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-2-big-Data.db')] (1 sstables, 10.168KiB), biggest 10.168KiB, smallest 10.168KiB
2023-05-30 19:58:39,565 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of dropped_columns: 1.081KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,565 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of dropped_columns: 1.079KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,565 - DEBUG [node3_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.dropped_columns.
2023-05-30 19:58:39,565 - DEBUG [node2_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.dropped_columns.
2023-05-30 19:58:39,566 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.dropped_columns
2023-05-30 19:58:39,566 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.dropped_columns
2023-05-30 19:58:39,566 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,566 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,566 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.dropped_columns
2023-05-30 19:58:39,566 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.dropped_columns
2023-05-30 19:58:39,569 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-dropped_columns@1188126455(0.120KiB serialized bytes, 3 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,569 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-dropped_columns@142983680(0.120KiB serialized bytes, 3 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,570 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/dropped_columns-5e7583b5f3f43af19a39b7e1d6f5f11f/nb-1-big-Data.db (0.097KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47153)
2023-05-30 19:58:39,570 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/dropped_columns-5e7583b5f3f43af19a39b7e1d6f5f11f/nb-1-big-Data.db (0.097KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47158)
2023-05-30 19:58:39,638 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/dropped_columns-5e7583b5f3f43af19a39b7e1d6f5f11f/nb-1-big-Data.db')] (1 sstables, 5.208KiB), biggest 5.208KiB, smallest 5.208KiB
2023-05-30 19:58:39,638 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/dropped_columns-5e7583b5f3f43af19a39b7e1d6f5f11f/nb-1-big-Data.db')] (1 sstables, 5.209KiB), biggest 5.209KiB, smallest 5.209KiB
2023-05-30 19:58:39,639 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of triggers: 0.513KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,639 - DEBUG [node3_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.triggers.
2023-05-30 19:58:39,640 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.triggers
2023-05-30 19:58:39,640 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,640 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.triggers
2023-05-30 19:58:39,643 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-triggers@923363130(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,643 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/triggers-4df70b666b05325195a132b54005fd48/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47153)
2023-05-30 19:58:39,651 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of triggers: 0.511KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,651 - DEBUG [node2_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.triggers.
2023-05-30 19:58:39,651 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.triggers
2023-05-30 19:58:39,652 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,652 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.triggers
2023-05-30 19:58:39,671 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-triggers@722502531(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,671 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/triggers-4df70b666b05325195a132b54005fd48/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47341)
2023-05-30 19:58:39,724 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/triggers-4df70b666b05325195a132b54005fd48/nb-1-big-Data.db')] (1 sstables, 4.971KiB), biggest 4.971KiB, smallest 4.971KiB
2023-05-30 19:58:39,725 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of types: 0.513KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,726 - DEBUG [node3_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.types.
2023-05-30 19:58:39,726 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.types
2023-05-30 19:58:39,726 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,726 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.types
2023-05-30 19:58:39,737 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/triggers-4df70b666b05325195a132b54005fd48/nb-1-big-Data.db')] (1 sstables, 4.971KiB), biggest 4.971KiB, smallest 4.971KiB
2023-05-30 19:58:39,738 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-types@2120900510(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,738 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of types: 0.511KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,739 - DEBUG [node2_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.types.
2023-05-30 19:58:39,739 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.types
2023-05-30 19:58:39,739 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/types-5a8b1ca866023f77a0459273d308917a/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47153)
2023-05-30 19:58:39,739 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,739 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.types
2023-05-30 19:58:39,758 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-types@425352226(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,759 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/types-5a8b1ca866023f77a0459273d308917a/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47341)
2023-05-30 19:58:39,819 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/types-5a8b1ca866023f77a0459273d308917a/nb-1-big-Data.db')] (1 sstables, 4.931KiB), biggest 4.931KiB, smallest 4.931KiB
2023-05-30 19:58:39,820 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of functions: 0.513KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,821 - DEBUG [node3_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.functions.
2023-05-30 19:58:39,821 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.functions
2023-05-30 19:58:39,821 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,821 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.functions
2023-05-30 19:58:39,832 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/types-5a8b1ca866023f77a0459273d308917a/nb-1-big-Data.db')] (1 sstables, 4.931KiB), biggest 4.931KiB, smallest 4.931KiB
2023-05-30 19:58:39,832 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-functions@1217392045(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,833 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of functions: 0.511KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,833 - DEBUG [node2_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.functions.
2023-05-30 19:58:39,833 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/functions-96489b7980be3e14a70166a0b9159450/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47153)
2023-05-30 19:58:39,833 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.functions
2023-05-30 19:58:39,834 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,834 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.functions
2023-05-30 19:58:39,852 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-functions@1029171910(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,853 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/functions-96489b7980be3e14a70166a0b9159450/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47341)
2023-05-30 19:58:39,889 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/functions-96489b7980be3e14a70166a0b9159450/nb-1-big-Data.db')] (1 sstables, 5.055KiB), biggest 5.055KiB, smallest 5.055KiB
2023-05-30 19:58:39,890 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of aggregates: 0.513KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,890 - DEBUG [node3_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.aggregates.
2023-05-30 19:58:39,890 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.aggregates
2023-05-30 19:58:39,890 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,890 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.aggregates
2023-05-30 19:58:39,909 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-aggregates@82125997(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,910 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/aggregates-924c55872e3a345bb10c12f37c1ba895/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47153)
2023-05-30 19:58:39,927 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/functions-96489b7980be3e14a70166a0b9159450/nb-1-big-Data.db')] (1 sstables, 5.055KiB), biggest 5.055KiB, smallest 5.055KiB
2023-05-30 19:58:39,928 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of aggregates: 0.511KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,928 - DEBUG [node2_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.aggregates.
2023-05-30 19:58:39,929 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.aggregates
2023-05-30 19:58:39,929 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,929 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.aggregates
2023-05-30 19:58:39,948 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-aggregates@459582126(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:39,948 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/aggregates-924c55872e3a345bb10c12f37c1ba895/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47341)
2023-05-30 19:58:39,983 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/aggregates-924c55872e3a345bb10c12f37c1ba895/nb-1-big-Data.db')] (1 sstables, 5.055KiB), biggest 5.055KiB, smallest 5.055KiB
2023-05-30 19:58:39,984 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of indexes: 0.513KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:39,984 - DEBUG [node3_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.indexes.
2023-05-30 19:58:39,984 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.indexes
2023-05-30 19:58:39,984 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:39,985 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.indexes
2023-05-30 19:58:40,003 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-indexes@2015994812(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,004 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/indexes-0feb57ac311f382fba6d9024d305702f/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47336)
2023-05-30 19:58:40,021 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/aggregates-924c55872e3a345bb10c12f37c1ba895/nb-1-big-Data.db')] (1 sstables, 5.055KiB), biggest 5.055KiB, smallest 5.055KiB
2023-05-30 19:58:40,022 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of indexes: 0.511KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,022 - DEBUG [node2_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.indexes.
2023-05-30 19:58:40,022 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.indexes
2023-05-30 19:58:40,023 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:40,023 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.indexes
2023-05-30 19:58:40,041 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-indexes@885472986(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,042 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/indexes-0feb57ac311f382fba6d9024d305702f/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47341)
2023-05-30 19:58:40,085 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/indexes-0feb57ac311f382fba6d9024d305702f/nb-1-big-Data.db')] (1 sstables, 4.971KiB), biggest 4.971KiB, smallest 4.971KiB
2023-05-30 19:58:40,086 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of tables: 69.004KiB (1%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,086 - DEBUG [node3_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.tables.
2023-05-30 19:58:40,086 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.tables
2023-05-30 19:58:40,086 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:40,087 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.tables
2023-05-30 19:58:40,105 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-tables@1410565512(21.567KiB serialized bytes, 32 ops, 1%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,106 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-2-big-Data.db (13.131KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47336)
2023-05-30 19:58:40,123 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/indexes-0feb57ac311f382fba6d9024d305702f/nb-1-big-Data.db')] (1 sstables, 4.971KiB), biggest 4.971KiB, smallest 4.971KiB
2023-05-30 19:58:40,124 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of tables: 69.002KiB (1%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,124 - DEBUG [node2_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.tables.
2023-05-30 19:58:40,125 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.tables
2023-05-30 19:58:40,125 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:40,125 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.tables
2023-05-30 19:58:40,144 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-tables@2134368044(21.567KiB serialized bytes, 32 ops, 1%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,145 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-2-big-Data.db (13.131KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47341)
2023-05-30 19:58:40,180 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-2-big-Data.db')] (1 sstables, 8.646KiB), biggest 8.646KiB, smallest 8.646KiB
2023-05-30 19:58:40,180 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of views: 0.513KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,181 - DEBUG [node3_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.views.
2023-05-30 19:58:40,181 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.views
2023-05-30 19:58:40,181 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:40,181 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.views
2023-05-30 19:58:40,200 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-views@1673979938(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,200 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/views-9786ac1cdd583201a7cdad556410c985/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47336)
2023-05-30 19:58:40,218 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-2-big-Data.db')] (1 sstables, 8.646KiB), biggest 8.646KiB, smallest 8.646KiB
2023-05-30 19:58:40,218 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of views: 0.511KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,219 - DEBUG [node2_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.views.
2023-05-30 19:58:40,219 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.views
2023-05-30 19:58:40,219 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:40,219 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.views
2023-05-30 19:58:40,238 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-views@2100566998(0.016KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,238 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/views-9786ac1cdd583201a7cdad556410c985/nb-1-big-Data.db (0.048KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47341)
2023-05-30 19:58:40,273 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/views-9786ac1cdd583201a7cdad556410c985/nb-1-big-Data.db')] (1 sstables, 4.931KiB), biggest 4.931KiB, smallest 4.931KiB
2023-05-30 19:58:40,274 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of keyspaces: 1.972KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,274 - DEBUG [node3_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.keyspaces.
2023-05-30 19:58:40,274 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.keyspaces
2023-05-30 19:58:40,275 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:40,275 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.keyspaces
2023-05-30 19:58:40,294 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-keyspaces@1311467707(0.382KiB serialized bytes, 5 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,294 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-2-big-Data.db (0.313KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47336)
2023-05-30 19:58:40,311 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/views-9786ac1cdd583201a7cdad556410c985/nb-1-big-Data.db')] (1 sstables, 4.931KiB), biggest 4.931KiB, smallest 4.931KiB
2023-05-30 19:58:40,312 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of keyspaces: 1.969KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,313 - DEBUG [node2_MigrationStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_schema.keyspaces.
2023-05-30 19:58:40,313 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_schema.keyspaces
2023-05-30 19:58:40,313 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:40,313 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_schema.keyspaces
2023-05-30 19:58:40,332 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-keyspaces@1128001284(0.382KiB serialized bytes, 5 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,333 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-2-big-Data.db (0.313KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=47341)
2023-05-30 19:58:40,367 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-2-big-Data.db')] (1 sstables, 5.334KiB), biggest 5.334KiB, smallest 5.334KiB
2023-05-30 19:58:40,370 - INFO  [node3_MigrationStage:1:Keyspace@386] - Creating replication strategy distributed_test_keyspace params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}
2023-05-30 19:58:40,370 - DEBUG [node3_MigrationStage:1:Keyspace@390] - New replication settings for keyspace distributed_test_keyspace - invalidating disk boundary caches
2023-05-30 19:58:40,394 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-2-big-Data.db')] (1 sstables, 5.335KiB), biggest 5.335KiB, smallest 5.335KiB
2023-05-30 19:58:40,397 - INFO  [node2_MigrationStage:1:Keyspace@386] - Creating replication strategy distributed_test_keyspace params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}
2023-05-30 19:58:40,397 - DEBUG [node2_MigrationStage:1:Keyspace@390] - New replication settings for keyspace distributed_test_keyspace - invalidating disk boundary caches
2023-05-30 19:58:40,421 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of columns: 1.660KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,423 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-columns@1680497347(0.258KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,424 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-3-big-Data.db (0.123KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=48388)
2023-05-30 19:58:40,492 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-3-big-Data.db')] (1 sstables, 5.336KiB), biggest 5.336KiB, smallest 5.336KiB
2023-05-30 19:58:40,492 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in dropped_columns
2023-05-30 19:58:40,492 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in triggers
2023-05-30 19:58:40,493 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in types
2023-05-30 19:58:40,493 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in functions
2023-05-30 19:58:40,493 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in aggregates
2023-05-30 19:58:40,493 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in indexes
2023-05-30 19:58:40,493 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of tables: 2.523KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,495 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-tables@1337559493(0.687KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,495 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-3-big-Data.db (0.434KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=48388)
2023-05-30 19:58:40,563 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-3-big-Data.db')] (1 sstables, 6.935KiB), biggest 6.935KiB, smallest 6.935KiB
2023-05-30 19:58:40,563 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in views
2023-05-30 19:58:40,563 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of keyspaces: 0.654KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,565 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-keyspaces@976142350(0.146KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,566 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-3-big-Data.db (0.132KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=48388)
2023-05-30 19:58:40,633 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-3-big-Data.db')] (1 sstables, 5.234KiB), biggest 5.234KiB, smallest 5.234KiB
2023-05-30 19:58:40,634 - INFO  [node1_MigrationStage:1:Keyspace@386] - Creating replication strategy distributed_test_keyspace params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}
2023-05-30 19:58:40,637 - INFO  [node1_MigrationStage:1:ColumnFamilyStore@385] - Initializing distributed_test_keyspace.tbl
2023-05-30 19:58:40,638 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for distributed_test_keyspace.tbl
2023-05-30 19:58:40,638 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.1:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.1:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 10)
2023-05-30 19:58:40,639 - DEBUG [node1_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for distributed_test_keyspace.tbl
2023-05-30 19:58:40,653 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of columns: 1.660KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,653 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of columns: 1.659KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,656 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-columns@2074744449(0.258KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,656 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-columns@1317480535(0.258KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,656 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-3-big-Data.db (0.123KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=48572)
2023-05-30 19:58:40,656 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-3-big-Data.db (0.123KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=48577)
2023-05-30 19:58:40,724 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-3-big-Data.db')] (1 sstables, 5.336KiB), biggest 5.336KiB, smallest 5.336KiB
2023-05-30 19:58:40,724 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/columns-24101c25a2ae3af787c1b40ee1aca33f/nb-3-big-Data.db')] (1 sstables, 5.336KiB), biggest 5.336KiB, smallest 5.336KiB
2023-05-30 19:58:40,725 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in dropped_columns
2023-05-30 19:58:40,725 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in dropped_columns
2023-05-30 19:58:40,725 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in triggers
2023-05-30 19:58:40,725 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in triggers
2023-05-30 19:58:40,725 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in types
2023-05-30 19:58:40,725 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in types
2023-05-30 19:58:40,725 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in functions
2023-05-30 19:58:40,725 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in functions
2023-05-30 19:58:40,725 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in aggregates
2023-05-30 19:58:40,725 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in aggregates
2023-05-30 19:58:40,725 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in indexes
2023-05-30 19:58:40,725 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in indexes
2023-05-30 19:58:40,726 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of tables: 2.477KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,726 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of tables: 2.476KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,728 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-tables@861795257(0.687KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,728 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-tables@252203028(0.687KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,729 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-3-big-Data.db (0.434KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=48572)
2023-05-30 19:58:40,729 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-3-big-Data.db (0.434KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=48577)
2023-05-30 19:58:40,797 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-3-big-Data.db')] (1 sstables, 6.935KiB), biggest 6.935KiB, smallest 6.935KiB
2023-05-30 19:58:40,797 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/nb-3-big-Data.db')] (1 sstables, 6.935KiB), biggest 6.935KiB, smallest 6.935KiB
2023-05-30 19:58:40,797 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in views
2023-05-30 19:58:40,798 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in views
2023-05-30 19:58:40,798 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of keyspaces: 0.654KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,798 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@878] - Enqueuing flush of keyspaces: 0.653KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,801 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-keyspaces@1737394696(0.146KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,801 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-keyspaces@1388253320(0.146KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:40,801 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-3-big-Data.db (0.132KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=48572)
2023-05-30 19:58:40,801 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-3-big-Data.db (0.132KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=48577)
2023-05-30 19:58:40,869 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-3-big-Data.db')] (1 sstables, 5.234KiB), biggest 5.234KiB, smallest 5.234KiB
2023-05-30 19:58:40,869 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system_schema/keyspaces-abac5682dea631c5b535b3d6cffd0fb6/nb-3-big-Data.db')] (1 sstables, 5.234KiB), biggest 5.234KiB, smallest 5.234KiB
2023-05-30 19:58:40,878 - INFO  [node3_MigrationStage:1:Keyspace@386] - Creating replication strategy distributed_test_keyspace params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}
2023-05-30 19:58:40,878 - INFO  [node2_MigrationStage:1:Keyspace@386] - Creating replication strategy distributed_test_keyspace params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}
2023-05-30 19:58:40,882 - INFO  [node3_MigrationStage:1:ColumnFamilyStore@385] - Initializing distributed_test_keyspace.tbl
2023-05-30 19:58:40,882 - INFO  [node2_MigrationStage:1:ColumnFamilyStore@385] - Initializing distributed_test_keyspace.tbl
2023-05-30 19:58:40,882 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for distributed_test_keyspace.tbl
2023-05-30 19:58:40,882 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for distributed_test_keyspace.tbl
2023-05-30 19:58:40,883 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.2:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.2:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:40,883 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.3:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.3:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:40,883 - DEBUG [node3_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for distributed_test_keyspace.tbl
2023-05-30 19:58:40,883 - DEBUG [node2_MigrationStage:1:DiskBoundaryManager@58] - Updating boundaries from null to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for distributed_test_keyspace.tbl
2023-05-30 19:58:40,903 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of tbl: 0.458KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:40,942 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-tbl@680712354(0.048KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(-3074457345618258603)]
2023-05-30 19:58:40,942 - INFO  [node1_PerDiskMemtableFlushWriter_1:1:Memtable$FlushRunnable@469] - Writing Memtable-tbl@680712354(0.048KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (max(-3074457345618258603), max(3074457345618258602)]
2023-05-30 19:58:40,942 - INFO  [node1_PerDiskMemtableFlushWriter_2:1:Memtable$FlushRunnable@469] - Writing Memtable-tbl@680712354(0.048KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (max(3074457345618258602), max(9223372036854775807)]
2023-05-30 19:58:40,943 - INFO  [node1_PerDiskMemtableFlushWriter_1:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data1/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-2-big-Data.db (0.000KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=48725)
2023-05-30 19:58:40,943 - INFO  [node1_PerDiskMemtableFlushWriter_2:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-3-big-Data.db (0.000KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=48725)
2023-05-30 19:58:40,943 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db (0.027KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=48725)
2023-05-30 19:58:41,011 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db')] (1 sstables, 4.857KiB), biggest 4.857KiB, smallest 4.857KiB
2023-05-30 19:58:41,021 - INFO  [node2_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of tbl: 0.457KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:41,060 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-tbl@300112092(0.048KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(-3074457345618258603)]
2023-05-30 19:58:41,060 - INFO  [node2_PerDiskMemtableFlushWriter_2:1:Memtable$FlushRunnable@469] - Writing Memtable-tbl@300112092(0.048KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (max(3074457345618258602), max(9223372036854775807)]
2023-05-30 19:58:41,060 - INFO  [node2_PerDiskMemtableFlushWriter_1:1:Memtable$FlushRunnable@469] - Writing Memtable-tbl@300112092(0.048KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (max(-3074457345618258603), max(3074457345618258602)]
2023-05-30 19:58:41,060 - INFO  [node2_PerDiskMemtableFlushWriter_2:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-3-big-Data.db (0.000KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=49097)
2023-05-30 19:58:41,060 - INFO  [node2_PerDiskMemtableFlushWriter_1:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data1/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-2-big-Data.db (0.000KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=49097)
2023-05-30 19:58:41,061 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db (0.027KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=49097)
2023-05-30 19:58:41,129 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db')] (1 sstables, 4.857KiB), biggest 4.857KiB, smallest 4.857KiB
2023-05-30 19:58:41,133 - INFO  [node3_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of tbl: 0.458KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:41,172 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-tbl@1928681714(0.048KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(-3074457345618258603)]
2023-05-30 19:58:41,172 - INFO  [node3_PerDiskMemtableFlushWriter_1:1:Memtable$FlushRunnable@469] - Writing Memtable-tbl@1928681714(0.048KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (max(-3074457345618258603), max(3074457345618258602)]
2023-05-30 19:58:41,172 - INFO  [node3_PerDiskMemtableFlushWriter_2:1:Memtable$FlushRunnable@469] - Writing Memtable-tbl@1928681714(0.048KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (max(3074457345618258602), max(9223372036854775807)]
2023-05-30 19:58:41,172 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db (0.000KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=48909)
2023-05-30 19:58:41,172 - INFO  [node3_PerDiskMemtableFlushWriter_1:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data1/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-2-big-Data.db (0.000KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=48909)
2023-05-30 19:58:41,172 - INFO  [node3_PerDiskMemtableFlushWriter_2:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-3-big-Data.db (0.027KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=48909)
2023-05-30 19:58:41,241 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-3-big-Data.db')] (1 sstables, 4.855KiB), biggest 4.855KiB, smallest 4.855KiB
2023-05-30 19:58:41,244 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in compaction_history
2023-05-30 19:58:41,244 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of peers_v2: 4.409KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:41,244 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in IndexInfo
2023-05-30 19:58:41,244 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in repairs
2023-05-30 19:58:41,244 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in size_estimates
2023-05-30 19:58:41,244 - DEBUG [node1_isolatedExecutor:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.peers_v2.
2023-05-30 19:58:41,244 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in table_estimates
2023-05-30 19:58:41,244 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in paxos
2023-05-30 19:58:41,244 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peers_v2
2023-05-30 19:58:41,244 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in built_views
2023-05-30 19:58:41,244 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in peer_events
2023-05-30 19:58:41,244 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:41,245 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.peers_v2
2023-05-30 19:58:41,245 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of peers: 3.917KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:41,245 - DEBUG [node1_isolatedExecutor:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.peers.
2023-05-30 19:58:41,245 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peers
2023-05-30 19:58:41,245 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:41,245 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.peers
2023-05-30 19:58:41,246 - INFO  [node1_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of local: 0.486KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:41,246 - DEBUG [node1_isolatedExecutor:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.local.
2023-05-30 19:58:41,246 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.local
2023-05-30 19:58:41,246 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:41,246 - DEBUG [node1_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.local
2023-05-30 19:58:41,247 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-peers_v2@517497649(0.512KiB serialized bytes, 30 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:41,247 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system/peers_v2-c4325fbb8e5e3bafbd070f9250ed818e/nb-1-big-Data.db (0.304KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=49091)
2023-05-30 19:58:41,315 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system/peers_v2-c4325fbb8e5e3bafbd070f9250ed818e/nb-1-big-Data.db')] (1 sstables, 5.577KiB), biggest 5.577KiB, smallest 5.577KiB
2023-05-30 19:58:41,317 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-peers@497821326(0.465KiB serialized bytes, 30 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:41,317 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system/peers-37f71aca7dc2383ba70672528af04d4f/nb-1-big-Data.db (0.280KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=49091)
2023-05-30 19:58:41,385 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system/peers-37f71aca7dc2383ba70672528af04d4f/nb-1-big-Data.db')] (1 sstables, 5.452KiB), biggest 5.452KiB, smallest 5.452KiB
2023-05-30 19:58:41,386 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in peer_events_v2
2023-05-30 19:58:41,386 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in batches
2023-05-30 19:58:41,386 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in transferred_ranges
2023-05-30 19:58:41,386 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in transferred_ranges_v2
2023-05-30 19:58:41,386 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in view_builds_in_progress
2023-05-30 19:58:41,387 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-local@1364114309(0.060KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:41,388 - INFO  [node1_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-4-big-Data.db (0.042KiB) for commitlog position CommitLogPosition(segmentId=1685491095340, position=49091)
2023-05-30 19:58:41,456 - DEBUG [node1_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-4-big-Data.db')] (1 sstables, 4.887KiB), biggest 4.887KiB, smallest 4.887KiB
2023-05-30 19:58:41,456 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in sstable_activity
2023-05-30 19:58:41,456 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in available_ranges_v2
2023-05-30 19:58:41,456 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in available_ranges
2023-05-30 19:58:41,456 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in prepared_statements
2023-05-30 19:58:41,457 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in compaction_history
2023-05-30 19:58:41,457 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in IndexInfo
2023-05-30 19:58:41,457 - INFO  [node2_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of peers_v2: 4.355KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:41,457 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in repairs
2023-05-30 19:58:41,457 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in size_estimates
2023-05-30 19:58:41,457 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in table_estimates
2023-05-30 19:58:41,457 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in paxos
2023-05-30 19:58:41,457 - DEBUG [node2_isolatedExecutor:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.peers_v2.
2023-05-30 19:58:41,457 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in built_views
2023-05-30 19:58:41,457 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in peer_events
2023-05-30 19:58:41,457 - DEBUG [node2_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peers_v2
2023-05-30 19:58:41,458 - DEBUG [node2_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:41,458 - DEBUG [node2_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.peers_v2
2023-05-30 19:58:41,458 - INFO  [node2_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of peers: 3.871KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:41,459 - DEBUG [node2_isolatedExecutor:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.peers.
2023-05-30 19:58:41,459 - DEBUG [node2_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peers
2023-05-30 19:58:41,459 - DEBUG [node2_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:41,460 - DEBUG [node2_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.peers
2023-05-30 19:58:41,460 - INFO  [node2_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of local: 0.485KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:41,460 - DEBUG [node2_isolatedExecutor:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.local.
2023-05-30 19:58:41,461 - DEBUG [node2_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.local
2023-05-30 19:58:41,461 - DEBUG [node2_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:41,461 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-peers_v2@1323341332(0.513KiB serialized bytes, 29 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:41,461 - DEBUG [node2_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.local
2023-05-30 19:58:41,461 - INFO  [node1_CompactionExecutor:1:CompactionTask@150] - Compacting (e72b8a10-ff45-11ed-bc52-8b144d1e6fed) [/tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-4-big-Data.db:level=0, /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-3-big-Data.db:level=0, /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-1-big-Data.db:level=0, /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-2-big-Data.db:level=0, ]
2023-05-30 19:58:41,462 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system/peers_v2-c4325fbb8e5e3bafbd070f9250ed818e/nb-1-big-Data.db (0.313KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=49097)
2023-05-30 19:58:41,523 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system/peers_v2-c4325fbb8e5e3bafbd070f9250ed818e/nb-1-big-Data.db')] (1 sstables, 5.598KiB), biggest 5.598KiB, smallest 5.598KiB
2023-05-30 19:58:41,525 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-peers@961726991(0.466KiB serialized bytes, 29 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:41,526 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system/peers-37f71aca7dc2383ba70672528af04d4f/nb-1-big-Data.db (0.286KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=49097)
2023-05-30 19:58:41,595 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system/peers-37f71aca7dc2383ba70672528af04d4f/nb-1-big-Data.db')] (1 sstables, 5.471KiB), biggest 5.471KiB, smallest 5.471KiB
2023-05-30 19:58:41,595 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in peer_events_v2
2023-05-30 19:58:41,595 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in batches
2023-05-30 19:58:41,595 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in transferred_ranges
2023-05-30 19:58:41,595 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in transferred_ranges_v2
2023-05-30 19:58:41,595 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in view_builds_in_progress
2023-05-30 19:58:41,597 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-local@1956099521(0.060KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:41,597 - INFO  [node2_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-4-big-Data.db (0.042KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=49097)
2023-05-30 19:58:41,623 - INFO  [node1_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-4-big
2023-05-30 19:58:41,631 - INFO  [node1_CompactionExecutor:1:CompactionTask@241] - Compacted (e72b8a10-ff45-11ed-bc52-8b144d1e6fed) 4 sstables to [/tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-5-big,] to level=0.  0.371KiB to 0.246KiB (~66% of original) in 153ms.  Read Throughput = 2.411KiB/s, Write Throughput = 1.599KiB/s, Row Throughput = ~2/s.  4 total partitions merged to 1.  Partition merge counts were {4:1, }
2023-05-30 19:58:41,639 - INFO  [node1_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-3-big
2023-05-30 19:58:41,649 - INFO  [node1_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-1-big
2023-05-30 19:58:41,657 - INFO  [node1_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-2-big
2023-05-30 19:58:41,668 - DEBUG [node2_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-4-big-Data.db')] (1 sstables, 4.888KiB), biggest 4.888KiB, smallest 4.888KiB
2023-05-30 19:58:41,668 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in sstable_activity
2023-05-30 19:58:41,668 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in available_ranges_v2
2023-05-30 19:58:41,669 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in available_ranges
2023-05-30 19:58:41,669 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in prepared_statements
2023-05-30 19:58:41,669 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in compaction_history
2023-05-30 19:58:41,669 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in IndexInfo
2023-05-30 19:58:41,669 - INFO  [node3_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of peers_v2: 4.343KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:41,669 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in repairs
2023-05-30 19:58:41,669 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in size_estimates
2023-05-30 19:58:41,669 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in table_estimates
2023-05-30 19:58:41,669 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in paxos
2023-05-30 19:58:41,669 - DEBUG [node3_isolatedExecutor:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.peers_v2.
2023-05-30 19:58:41,669 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in built_views
2023-05-30 19:58:41,669 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in peer_events
2023-05-30 19:58:41,670 - DEBUG [node3_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peers_v2
2023-05-30 19:58:41,670 - DEBUG [node3_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:41,670 - DEBUG [node3_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.peers_v2
2023-05-30 19:58:41,671 - INFO  [node3_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of peers: 3.858KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:41,671 - DEBUG [node3_isolatedExecutor:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.peers.
2023-05-30 19:58:41,671 - DEBUG [node3_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peers
2023-05-30 19:58:41,671 - DEBUG [node3_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:41,671 - DEBUG [node3_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.peers
2023-05-30 19:58:41,672 - INFO  [node3_isolatedExecutor:1:ColumnFamilyStore@878] - Enqueuing flush of local: 0.486KiB (0%) on-heap, 0.000KiB (0%) off-heap
2023-05-30 19:58:41,672 - DEBUG [node3_isolatedExecutor:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.local.
2023-05-30 19:58:41,672 - DEBUG [node3_isolatedExecutor:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.local
2023-05-30 19:58:41,673 - DEBUG [node3_isolatedExecutor:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:41,673 - DEBUG [node3_isolatedExecutor:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.local
2023-05-30 19:58:41,673 - INFO  [node2_CompactionExecutor:1:CompactionTask@150] - Compacting (e74be350-ff45-11ed-8fcf-679a97013a80) [/tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-2-big-Data.db:level=0, /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-1-big-Data.db:level=0, /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-3-big-Data.db:level=0, /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-4-big-Data.db:level=0, ]
2023-05-30 19:58:41,673 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-peers_v2@1497388595(0.513KiB serialized bytes, 29 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:41,674 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system/peers_v2-c4325fbb8e5e3bafbd070f9250ed818e/nb-1-big-Data.db (0.310KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=48909)
2023-05-30 19:58:41,734 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system/peers_v2-c4325fbb8e5e3bafbd070f9250ed818e/nb-1-big-Data.db')] (1 sstables, 5.583KiB), biggest 5.583KiB, smallest 5.583KiB
2023-05-30 19:58:41,737 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-peers@89962137(0.466KiB serialized bytes, 29 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:41,737 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system/peers-37f71aca7dc2383ba70672528af04d4f/nb-1-big-Data.db (0.285KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=48909)
2023-05-30 19:58:41,805 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system/peers-37f71aca7dc2383ba70672528af04d4f/nb-1-big-Data.db')] (1 sstables, 5.459KiB), biggest 5.459KiB, smallest 5.459KiB
2023-05-30 19:58:41,806 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in peer_events_v2
2023-05-30 19:58:41,806 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in batches
2023-05-30 19:58:41,806 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in transferred_ranges
2023-05-30 19:58:41,806 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in transferred_ranges_v2
2023-05-30 19:58:41,806 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in view_builds_in_progress
2023-05-30 19:58:41,808 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@469] - Writing Memtable-local@378643184(0.060KiB serialized bytes, 2 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
2023-05-30 19:58:41,808 - INFO  [node3_PerDiskMemtableFlushWriter_0:1:Memtable$FlushRunnable@498] - Completed flushing /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-4-big-Data.db (0.042KiB) for commitlog position CommitLogPosition(segmentId=1685491106338, position=48909)
2023-05-30 19:58:41,833 - INFO  [node2_CompactionExecutor:1:CompactionTask@241] - Compacted (e74be350-ff45-11ed-8fcf-679a97013a80) 4 sstables to [/tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-5-big,] to level=0.  0.370KiB to 0.246KiB (~66% of original) in 153ms.  Read Throughput = 2.413KiB/s, Write Throughput = 1.604KiB/s, Row Throughput = ~2/s.  4 total partitions merged to 1.  Partition merge counts were {4:1, }
2023-05-30 19:58:41,841 - INFO  [node2_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-2-big
2023-05-30 19:58:41,850 - INFO  [node2_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-1-big
2023-05-30 19:58:41,859 - INFO  [node2_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-3-big
2023-05-30 19:58:41,868 - INFO  [node2_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node2/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-4-big
2023-05-30 19:58:41,879 - DEBUG [node3_MemtableFlushWriter:1:ColumnFamilyStore$Flush@1197] - Flushed to [BigTableReader(path='/tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-4-big-Data.db')] (1 sstables, 4.887KiB), biggest 4.887KiB, smallest 4.887KiB
2023-05-30 19:58:41,879 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in sstable_activity
2023-05-30 19:58:41,879 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in available_ranges_v2
2023-05-30 19:58:41,879 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in available_ranges
2023-05-30 19:58:41,879 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in prepared_statements
2023-05-30 19:58:41,883 - INFO  [node3_CompactionExecutor:1:CompactionTask@150] - Compacting (e76c1580-ff45-11ed-b37f-c54689fc3e92) [/tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-4-big-Data.db:level=0, /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-3-big-Data.db:level=0, /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-2-big-Data.db:level=0, /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-1-big-Data.db:level=0, ]
2023-05-30 19:58:42,017 - INFO  [node3_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-4-big
2023-05-30 19:58:42,025 - INFO  [node3_CompactionExecutor:1:CompactionTask@241] - Compacted (e76c1580-ff45-11ed-b37f-c54689fc3e92) 4 sstables to [/tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-5-big,] to level=0.  0.370KiB to 0.245KiB (~66% of original) in 127ms.  Read Throughput = 2.911KiB/s, Write Throughput = 1.928KiB/s, Row Throughput = ~2/s.  4 total partitions merged to 1.  Partition merge counts were {4:1, }
2023-05-30 19:58:42,025 - INFO  [node3_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-3-big
2023-05-30 19:58:42,026 - INFO  [node3_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-2-big
2023-05-30 19:58:42,028 - INFO  [node3_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node3/data0/system/local-7ad54392bcdd35a684174e047860b377/nb-1-big
2023-05-30 19:58:42,069 - INFO  [node1_Repair-Task:1:RepairRunnable@310] - Starting repair command #1 (e7885010-ff45-11ed-bc52-8b144d1e6fed), repairing keyspace distributed_test_keyspace with repair options (parallelism: parallel, primary range: false, incremental: true, job threads: 1, ColumnFamilies: [], dataCenters: [], hosts: [], previewKind: NONE, # of ranges: 3, pull repair: false, force repair: false, optimise streams: false, ignore unreplicated keyspaces: false)
2023-05-30 19:58:42,082 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.compaction_history.
2023-05-30 19:58:42,083 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.compaction_history
2023-05-30 19:58:42,083 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,083 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.compaction_history
2023-05-30 19:58:42,084 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.IndexInfo.
2023-05-30 19:58:42,084 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.IndexInfo
2023-05-30 19:58:42,084 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,084 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.IndexInfo
2023-05-30 19:58:42,084 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.repairs.
2023-05-30 19:58:42,084 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.repairs
2023-05-30 19:58:42,085 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,085 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.repairs
2023-05-30 19:58:42,085 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.size_estimates.
2023-05-30 19:58:42,085 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.size_estimates
2023-05-30 19:58:42,085 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,085 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.size_estimates
2023-05-30 19:58:42,086 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.table_estimates.
2023-05-30 19:58:42,086 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.table_estimates
2023-05-30 19:58:42,086 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,086 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.table_estimates
2023-05-30 19:58:42,086 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.paxos.
2023-05-30 19:58:42,087 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.paxos
2023-05-30 19:58:42,087 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,087 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.paxos
2023-05-30 19:58:42,087 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.built_views.
2023-05-30 19:58:42,088 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.built_views
2023-05-30 19:58:42,088 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,088 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.built_views
2023-05-30 19:58:42,088 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.peer_events.
2023-05-30 19:58:42,088 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peer_events
2023-05-30 19:58:42,088 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,089 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.peer_events
2023-05-30 19:58:42,089 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.peer_events_v2.
2023-05-30 19:58:42,089 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peer_events_v2
2023-05-30 19:58:42,089 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,089 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.peer_events_v2
2023-05-30 19:58:42,089 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.transferred_ranges.
2023-05-30 19:58:42,090 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.transferred_ranges
2023-05-30 19:58:42,090 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,090 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.transferred_ranges
2023-05-30 19:58:42,090 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.transferred_ranges_v2.
2023-05-30 19:58:42,091 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.transferred_ranges_v2
2023-05-30 19:58:42,091 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,091 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.transferred_ranges_v2
2023-05-30 19:58:42,091 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.view_builds_in_progress.
2023-05-30 19:58:42,091 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.view_builds_in_progress
2023-05-30 19:58:42,092 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,092 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.view_builds_in_progress
2023-05-30 19:58:42,092 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.sstable_activity.
2023-05-30 19:58:42,092 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.sstable_activity
2023-05-30 19:58:42,092 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,092 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.sstable_activity
2023-05-30 19:58:42,092 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.available_ranges_v2.
2023-05-30 19:58:42,092 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.available_ranges_v2
2023-05-30 19:58:42,092 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,093 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.available_ranges_v2
2023-05-30 19:58:42,093 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.available_ranges.
2023-05-30 19:58:42,093 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.available_ranges
2023-05-30 19:58:42,093 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,093 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}], positions=[max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.available_ranges
2023-05-30 19:58:42,093 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.prepared_statements.
2023-05-30 19:58:42,093 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.prepared_statements
2023-05-30 19:58:42,093 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 10)
2023-05-30 19:58:42,093 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system.prepared_statements
2023-05-30 19:58:42,094 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.roles.
2023-05-30 19:58:42,094 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.roles
2023-05-30 19:58:42,094 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(9223372036854775805,-3074457345618258603])] (ringVersion = 10)
2023-05-30 19:58:42,094 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-7173733806442603406), max(-5124095576030431004), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_auth.roles
2023-05-30 19:58:42,094 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.role_members.
2023-05-30 19:58:42,094 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.role_members
2023-05-30 19:58:42,095 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(9223372036854775805,-3074457345618258603])] (ringVersion = 10)
2023-05-30 19:58:42,095 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-7173733806442603406), max(-5124095576030431004), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_auth.role_members
2023-05-30 19:58:42,095 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.resource_role_permissons_index.
2023-05-30 19:58:42,095 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.resource_role_permissons_index
2023-05-30 19:58:42,095 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(9223372036854775805,-3074457345618258603])] (ringVersion = 10)
2023-05-30 19:58:42,095 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-7173733806442603406), max(-5124095576030431004), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_auth.resource_role_permissons_index
2023-05-30 19:58:42,096 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.network_permissions.
2023-05-30 19:58:42,096 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.network_permissions
2023-05-30 19:58:42,096 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(9223372036854775805,-3074457345618258603])] (ringVersion = 10)
2023-05-30 19:58:42,096 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-7173733806442603406), max(-5124095576030431004), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_auth.network_permissions
2023-05-30 19:58:42,096 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.role_permissions.
2023-05-30 19:58:42,097 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.role_permissions
2023-05-30 19:58:42,097 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(9223372036854775805,-3074457345618258603])] (ringVersion = 10)
2023-05-30 19:58:42,097 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-7173733806442603406), max(-5124095576030431004), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_auth.role_permissions
2023-05-30 19:58:42,097 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_distributed.parent_repair_history.
2023-05-30 19:58:42,097 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.parent_repair_history
2023-05-30 19:58:42,097 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.1:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.1:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 10)
2023-05-30 19:58:42,098 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_distributed.parent_repair_history
2023-05-30 19:58:42,098 - DEBUG [node1_Repair-Task:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,098 - DEBUG [node1_Repair-Task:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,098 - DEBUG [node1_Repair-Task:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,098 - DEBUG [node1_Repair-Task:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,098 - DEBUG [node1_Repair-Task:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,098 - DEBUG [node1_Repair-Task:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,099 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_distributed.repair_history.
2023-05-30 19:58:42,099 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.repair_history
2023-05-30 19:58:42,099 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.1:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.1:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 10)
2023-05-30 19:58:42,099 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_distributed.repair_history
2023-05-30 19:58:42,099 - DEBUG [node1_Repair-Task:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,099 - DEBUG [node1_Repair-Task:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,100 - DEBUG [node1_Repair-Task:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,100 - DEBUG [node1_Repair-Task:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,100 - DEBUG [node1_Repair-Task:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,100 - DEBUG [node1_Repair-Task:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,100 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_distributed.view_build_status.
2023-05-30 19:58:42,100 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.view_build_status
2023-05-30 19:58:42,100 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.1:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.1:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 10)
2023-05-30 19:58:42,100 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_distributed.view_build_status
2023-05-30 19:58:42,101 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_traces.sessions.
2023-05-30 19:58:42,101 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_traces.sessions
2023-05-30 19:58:42,101 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.1:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 10)
2023-05-30 19:58:42,101 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-5124095576030431005), max(5124095576030431002), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_traces.sessions
2023-05-30 19:58:42,101 - DEBUG [node1_Repair-Task:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_traces.events.
2023-05-30 19:58:42,101 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_traces.events
2023-05-30 19:58:42,102 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.1:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.1:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 10)
2023-05-30 19:58:42,102 - DEBUG [node1_Repair-Task:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node1/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node1/data2}], positions=[max(-5124095576030431005), max(5124095576030431002), max(9223372036854775807)], ringVersion=10, directoriesVersion=0} for system_traces.events
2023-05-30 19:58:42,110 - DEBUG [node3_AntiEntropyStage:1:RepairMessageVerbHandler@69] - Preparing, PrepareMessage{tableIds='[e68c8af0-ff45-11ed-bc52-8b144d1e6fed]', ranges=[(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]], parentRepairSession=e7885010-ff45-11ed-bc52-8b144d1e6fed, isIncremental=true, timestamp=1685491122103, isGlobal=true}
2023-05-30 19:58:42,110 - DEBUG [node2_AntiEntropyStage:1:RepairMessageVerbHandler@69] - Preparing, PrepareMessage{tableIds='[e68c8af0-ff45-11ed-bc52-8b144d1e6fed]', ranges=[(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]], parentRepairSession=e7885010-ff45-11ed-bc52-8b144d1e6fed, isIncremental=true, timestamp=1685491122103, isGlobal=true}
2023-05-30 19:58:42,110 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.compaction_history.
2023-05-30 19:58:42,110 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.compaction_history.
2023-05-30 19:58:42,111 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.compaction_history
2023-05-30 19:58:42,111 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.compaction_history
2023-05-30 19:58:42,111 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,111 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,111 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.compaction_history
2023-05-30 19:58:42,112 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.IndexInfo.
2023-05-30 19:58:42,112 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.compaction_history
2023-05-30 19:58:42,112 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.IndexInfo
2023-05-30 19:58:42,112 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,112 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.IndexInfo.
2023-05-30 19:58:42,112 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.IndexInfo
2023-05-30 19:58:42,112 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.IndexInfo
2023-05-30 19:58:42,113 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.repairs.
2023-05-30 19:58:42,113 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.repairs
2023-05-30 19:58:42,113 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,113 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,113 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.IndexInfo
2023-05-30 19:58:42,113 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.repairs.
2023-05-30 19:58:42,113 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.repairs
2023-05-30 19:58:42,114 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.repairs
2023-05-30 19:58:42,114 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.size_estimates.
2023-05-30 19:58:42,114 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.size_estimates
2023-05-30 19:58:42,114 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,114 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,114 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.size_estimates
2023-05-30 19:58:42,114 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.table_estimates.
2023-05-30 19:58:42,114 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.repairs
2023-05-30 19:58:42,115 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.table_estimates
2023-05-30 19:58:42,115 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.size_estimates.
2023-05-30 19:58:42,115 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.size_estimates
2023-05-30 19:58:42,115 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,115 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.table_estimates
2023-05-30 19:58:42,115 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.paxos.
2023-05-30 19:58:42,115 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,115 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.paxos
2023-05-30 19:58:42,116 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.size_estimates
2023-05-30 19:58:42,116 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,116 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.table_estimates.
2023-05-30 19:58:42,116 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.table_estimates
2023-05-30 19:58:42,116 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.paxos
2023-05-30 19:58:42,116 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,116 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.table_estimates
2023-05-30 19:58:42,116 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.built_views.
2023-05-30 19:58:42,116 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.paxos.
2023-05-30 19:58:42,118 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.built_views
2023-05-30 19:58:42,118 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.paxos
2023-05-30 19:58:42,118 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,118 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,118 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.built_views
2023-05-30 19:58:42,118 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.peer_events.
2023-05-30 19:58:42,118 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peer_events
2023-05-30 19:58:42,118 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.paxos
2023-05-30 19:58:42,118 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,118 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.peer_events
2023-05-30 19:58:42,118 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.peer_events_v2.
2023-05-30 19:58:42,119 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peer_events_v2
2023-05-30 19:58:42,119 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.built_views.
2023-05-30 19:58:42,120 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.built_views
2023-05-30 19:58:42,120 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,120 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,120 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.peer_events_v2
2023-05-30 19:58:42,120 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.built_views
2023-05-30 19:58:42,120 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.peer_events.
2023-05-30 19:58:42,120 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.transferred_ranges.
2023-05-30 19:58:42,120 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.transferred_ranges
2023-05-30 19:58:42,120 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peer_events
2023-05-30 19:58:42,120 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,120 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,121 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.transferred_ranges
2023-05-30 19:58:42,121 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.peer_events
2023-05-30 19:58:42,121 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.transferred_ranges_v2.
2023-05-30 19:58:42,121 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.transferred_ranges_v2
2023-05-30 19:58:42,121 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.peer_events_v2.
2023-05-30 19:58:42,121 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.peer_events_v2
2023-05-30 19:58:42,121 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,121 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.transferred_ranges_v2
2023-05-30 19:58:42,121 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.view_builds_in_progress.
2023-05-30 19:58:42,121 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,121 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.view_builds_in_progress
2023-05-30 19:58:42,121 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.peer_events_v2
2023-05-30 19:58:42,121 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,122 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.transferred_ranges.
2023-05-30 19:58:42,122 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.view_builds_in_progress
2023-05-30 19:58:42,122 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.transferred_ranges
2023-05-30 19:58:42,122 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.sstable_activity.
2023-05-30 19:58:42,122 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.sstable_activity
2023-05-30 19:58:42,122 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,122 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.transferred_ranges
2023-05-30 19:58:42,122 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,122 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.transferred_ranges_v2.
2023-05-30 19:58:42,122 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.sstable_activity
2023-05-30 19:58:42,122 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.transferred_ranges_v2
2023-05-30 19:58:42,123 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.available_ranges_v2.
2023-05-30 19:58:42,123 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.available_ranges_v2
2023-05-30 19:58:42,123 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,123 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,123 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.transferred_ranges_v2
2023-05-30 19:58:42,123 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.available_ranges_v2
2023-05-30 19:58:42,123 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.available_ranges.
2023-05-30 19:58:42,123 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.available_ranges
2023-05-30 19:58:42,123 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.view_builds_in_progress.
2023-05-30 19:58:42,123 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.view_builds_in_progress
2023-05-30 19:58:42,123 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,123 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.available_ranges
2023-05-30 19:58:42,123 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,124 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.prepared_statements.
2023-05-30 19:58:42,124 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.prepared_statements
2023-05-30 19:58:42,124 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.view_builds_in_progress
2023-05-30 19:58:42,124 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,124 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.sstable_activity.
2023-05-30 19:58:42,124 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.sstable_activity
2023-05-30 19:58:42,124 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.prepared_statements
2023-05-30 19:58:42,124 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.roles.
2023-05-30 19:58:42,124 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.roles
2023-05-30 19:58:42,124 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,124 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.sstable_activity
2023-05-30 19:58:42,124 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,124 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.available_ranges_v2.
2023-05-30 19:58:42,125 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.available_ranges_v2
2023-05-30 19:58:42,125 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(5124095576030431002), max(7173733806442603403), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_auth.roles
2023-05-30 19:58:42,125 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.role_members.
2023-05-30 19:58:42,125 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.role_members
2023-05-30 19:58:42,125 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,125 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.available_ranges_v2
2023-05-30 19:58:42,125 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.available_ranges.
2023-05-30 19:58:42,125 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,125 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.available_ranges
2023-05-30 19:58:42,125 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(5124095576030431002), max(7173733806442603403), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_auth.role_members
2023-05-30 19:58:42,125 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.resource_role_permissons_index.
2023-05-30 19:58:42,125 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,126 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.resource_role_permissons_index
2023-05-30 19:58:42,126 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}], positions=[max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.available_ranges
2023-05-30 19:58:42,126 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,126 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system.prepared_statements.
2023-05-30 19:58:42,126 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(5124095576030431002), max(7173733806442603403), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_auth.resource_role_permissons_index
2023-05-30 19:58:42,126 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system.prepared_statements
2023-05-30 19:58:42,126 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.network_permissions.
2023-05-30 19:58:42,126 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-9223372036854775808,-9223372036854775808])] (ringVersion = 12)
2023-05-30 19:58:42,126 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.network_permissions
2023-05-30 19:58:42,126 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system.prepared_statements
2023-05-30 19:58:42,126 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,127 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.roles.
2023-05-30 19:58:42,127 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(5124095576030431002), max(7173733806442603403), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_auth.network_permissions
2023-05-30 19:58:42,127 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.roles
2023-05-30 19:58:42,127 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.role_permissions.
2023-05-30 19:58:42,127 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.role_permissions
2023-05-30 19:58:42,127 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-3074457345618258603,3074457345618258601])] (ringVersion = 12)
2023-05-30 19:58:42,127 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,127 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-1024819115206086202), max(1024819115206086199), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_auth.roles
2023-05-30 19:58:42,127 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(5124095576030431002), max(7173733806442603403), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_auth.role_permissions
2023-05-30 19:58:42,127 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_distributed.parent_repair_history.
2023-05-30 19:58:42,127 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.parent_repair_history
2023-05-30 19:58:42,128 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.role_members.
2023-05-30 19:58:42,128 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.role_members
2023-05-30 19:58:42,128 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.3:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.3:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,128 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-3074457345618258603,3074457345618258601])] (ringVersion = 12)
2023-05-30 19:58:42,128 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_distributed.parent_repair_history
2023-05-30 19:58:42,128 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-1024819115206086202), max(1024819115206086199), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_auth.role_members
2023-05-30 19:58:42,128 - DEBUG [node3_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,128 - DEBUG [node3_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,128 - DEBUG [node3_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,128 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.resource_role_permissons_index.
2023-05-30 19:58:42,128 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.resource_role_permissons_index
2023-05-30 19:58:42,129 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-3074457345618258603,3074457345618258601])] (ringVersion = 12)
2023-05-30 19:58:42,129 - DEBUG [node3_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,129 - DEBUG [node3_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,129 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-1024819115206086202), max(1024819115206086199), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_auth.resource_role_permissons_index
2023-05-30 19:58:42,129 - DEBUG [node3_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,129 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.network_permissions.
2023-05-30 19:58:42,129 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_distributed.repair_history.
2023-05-30 19:58:42,129 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.network_permissions
2023-05-30 19:58:42,129 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.repair_history
2023-05-30 19:58:42,129 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.3:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.3:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,129 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-3074457345618258603,3074457345618258601])] (ringVersion = 12)
2023-05-30 19:58:42,129 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-1024819115206086202), max(1024819115206086199), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_auth.network_permissions
2023-05-30 19:58:42,129 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_distributed.repair_history
2023-05-30 19:58:42,130 - DEBUG [node3_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,130 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_auth.role_permissions.
2023-05-30 19:58:42,130 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_auth.role_permissions
2023-05-30 19:58:42,130 - DEBUG [node3_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,130 - DEBUG [node3_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,130 - DEBUG [node3_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,130 - DEBUG [node3_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,130 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(-3074457345618258603,3074457345618258601])] (ringVersion = 12)
2023-05-30 19:58:42,130 - DEBUG [node3_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,130 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_distributed.view_build_status.
2023-05-30 19:58:42,130 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.view_build_status
2023-05-30 19:58:42,130 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-1024819115206086202), max(1024819115206086199), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_auth.role_permissions
2023-05-30 19:58:42,130 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_distributed.parent_repair_history.
2023-05-30 19:58:42,130 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.3:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.3:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,131 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.parent_repair_history
2023-05-30 19:58:42,131 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_distributed.view_build_status
2023-05-30 19:58:42,131 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_traces.sessions.
2023-05-30 19:58:42,131 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_traces.sessions
2023-05-30 19:58:42,131 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.2:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.2:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,131 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.3:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,131 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_distributed.parent_repair_history
2023-05-30 19:58:42,131 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(1024819115206086199), max(5124095576030431001), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_traces.sessions
2023-05-30 19:58:42,131 - DEBUG [node2_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,132 - DEBUG [node2_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,132 - DEBUG [node2_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,132 - DEBUG [node3_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_traces.events.
2023-05-30 19:58:42,132 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_traces.events
2023-05-30 19:58:42,132 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.3:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.3:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,132 - DEBUG [node2_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,132 - DEBUG [node2_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,132 - DEBUG [node3_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node3/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node3/data2}], positions=[max(1024819115206086199), max(5124095576030431001), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_traces.events
2023-05-30 19:58:42,132 - DEBUG [node2_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,132 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_distributed.repair_history.
2023-05-30 19:58:42,133 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.repair_history
2023-05-30 19:58:42,133 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.2:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.2:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,133 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_distributed.repair_history
2023-05-30 19:58:42,133 - DEBUG [node2_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,133 - DEBUG [node2_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,134 - DEBUG [node2_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,134 - DEBUG [node2_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,134 - DEBUG [node2_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,134 - DEBUG [node2_AntiEntropyStage:1:TimeWindowCompactionStrategy@71] - Disabling tombstone compactions for TWCS
2023-05-30 19:58:42,134 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_distributed.view_build_status.
2023-05-30 19:58:42,134 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_distributed.view_build_status
2023-05-30 19:58:42,134 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.2:7012,(-3074457345618258603,3074457345618258601]), Full(/127.0.0.2:7012,(3074457345618258601,9223372036854775805])] (ringVersion = 12)
2023-05-30 19:58:42,135 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-3074457345618258603), max(3074457345618258602), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_distributed.view_build_status
2023-05-30 19:58:42,135 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_traces.sessions.
2023-05-30 19:58:42,135 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_traces.sessions
2023-05-30 19:58:42,135 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.2:7012,(-3074457345618258603,3074457345618258601])] (ringVersion = 12)
2023-05-30 19:58:42,136 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-5124095576030431005), max(-1024819115206086202), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_traces.sessions
2023-05-30 19:58:42,136 - DEBUG [node2_AntiEntropyStage:1:CompactionStrategyManager@519] - Recreating compaction strategy - disk boundaries are out of date for system_traces.events.
2023-05-30 19:58:42,136 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@55] - Refreshing disk boundary cache for system_traces.events
2023-05-30 19:58:42,136 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@94] - Got local ranges [Full(/127.0.0.2:7012,(9223372036854775805,-3074457345618258603]), Full(/127.0.0.2:7012,(-3074457345618258603,3074457345618258601])] (ringVersion = 12)
2023-05-30 19:58:42,136 - DEBUG [node2_AntiEntropyStage:1:DiskBoundaryManager@58] - Updating boundaries from DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=null, ringVersion=0, directoriesVersion=0} to DiskBoundaries{directories=[DataDirectory{location=/tmp/dtests293447409190997823/node2/data0}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data1}, DataDirectory{location=/tmp/dtests293447409190997823/node2/data2}], positions=[max(-5124095576030431005), max(-1024819115206086202), max(9223372036854775807)], ringVersion=12, directoriesVersion=0} for system_traces.events
2023-05-30 19:58:42,144 - INFO  [node1_Repair-Task:1:CoordinatorSession@290] - Beginning coordination of incremental repair session e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:42,144 - INFO  [node1_Repair-Task:1:CoordinatorSession@153] - Beginning prepare phase of incremental repair session e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:42,150 - INFO  [node1_Messaging-EventLoop-3-11:OutboundConnection$1Initiate@1150] - /127.0.0.1:7012(/127.0.0.1:50938)->/127.0.0.1:7012-SMALL_MESSAGES-fbade54a successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:42,150 - INFO  [node1_Messaging-EventLoop-3-14:InboundConnectionInitiator$Handler@464] - /127.0.0.1:7012(/127.0.0.1:50938)->/127.0.0.1:7012-SMALL_MESSAGES-83bb197b messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:42,154 - INFO  [node3_AntiEntropyStage:1:LocalSessions@815] - Beginning local incremental repair session LocalSession{sessionID=e7885010-ff45-11ed-bc52-8b144d1e6fed, state=PREPARING, coordinator=/127.0.0.1:7012, tableIds=[e68c8af0-ff45-11ed-bc52-8b144d1e6fed], repairedAt=1685491122103, ranges=[(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]], participants=[/127.0.0.3:7012, /127.0.0.2:7012, /127.0.0.1:7012], startedAt=1685491122, lastUpdate=1685491122}
2023-05-30 19:58:42,154 - INFO  [node2_AntiEntropyStage:1:LocalSessions@815] - Beginning local incremental repair session LocalSession{sessionID=e7885010-ff45-11ed-bc52-8b144d1e6fed, state=PREPARING, coordinator=/127.0.0.1:7012, tableIds=[e68c8af0-ff45-11ed-bc52-8b144d1e6fed], repairedAt=1685491122103, ranges=[(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]], participants=[/127.0.0.3:7012, /127.0.0.2:7012, /127.0.0.1:7012], startedAt=1685491122, lastUpdate=1685491122}
2023-05-30 19:58:42,157 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in tbl
2023-05-30 19:58:42,157 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in tbl
2023-05-30 19:58:42,158 - INFO  [node1_AntiEntropyStage:1:LocalSessions@815] - Beginning local incremental repair session LocalSession{sessionID=e7885010-ff45-11ed-bc52-8b144d1e6fed, state=PREPARING, coordinator=/127.0.0.1:7012, tableIds=[e68c8af0-ff45-11ed-bc52-8b144d1e6fed], repairedAt=1685491122103, ranges=[(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]], participants=[/127.0.0.3:7012, /127.0.0.2:7012, /127.0.0.1:7012], startedAt=1685491122, lastUpdate=1685491122}
2023-05-30 19:58:42,159 - DEBUG [pool-11-thread-1:PendingAntiCompaction$AcquisitionCallable@218] - acquiring sstables for pending anti compaction on session e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:42,159 - DEBUG [pool-12-thread-1:PendingAntiCompaction$AcquisitionCallable@218] - acquiring sstables for pending anti compaction on session e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:42,159 - DEBUG [node1_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in tbl
2023-05-30 19:58:42,161 - DEBUG [pool-13-thread-1:PendingAntiCompaction$AcquisitionCallable@218] - acquiring sstables for pending anti compaction on session e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:42,170 - INFO  [node1_CompactionExecutor:1:CompactionManager@777] - [repair #e7885010-ff45-11ed-bc52-8b144d1e6fed] Starting anticompaction for distributed_test_keyspace.tbl on 1/1 sstables
2023-05-30 19:58:42,170 - INFO  [node2_CompactionExecutor:1:CompactionManager@777] - [repair #e7885010-ff45-11ed-bc52-8b144d1e6fed] Starting anticompaction for distributed_test_keyspace.tbl on 1/1 sstables
2023-05-30 19:58:42,171 - INFO  [node1_CompactionExecutor:1:CompactionManager@836] - [repair #e7885010-ff45-11ed-bc52-8b144d1e6fed] SSTable BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db') fully contained in range (-9223372036854775808,-9223372036854775808], mutating repairedAt instead of anticompacting
2023-05-30 19:58:42,171 - INFO  [node3_CompactionExecutor:1:CompactionManager@777] - [repair #e7885010-ff45-11ed-bc52-8b144d1e6fed] Starting anticompaction for distributed_test_keyspace.tbl on 1/1 sstables
2023-05-30 19:58:42,171 - INFO  [node2_CompactionExecutor:1:CompactionManager@836] - [repair #e7885010-ff45-11ed-bc52-8b144d1e6fed] SSTable BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db') fully contained in range (-9223372036854775808,-9223372036854775808], mutating repairedAt instead of anticompacting
2023-05-30 19:58:42,172 - INFO  [node3_CompactionExecutor:1:CompactionManager@836] - [repair #e7885010-ff45-11ed-bc52-8b144d1e6fed] SSTable BigTableReader(path='/tmp/dtests293447409190997823/node3/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-3-big-Data.db') fully contained in range (-9223372036854775808,-9223372036854775808], mutating repairedAt instead of anticompacting
2023-05-30 19:58:42,177 - DEBUG [node2_CompactionExecutor:1:PendingRepairManager@118] - Creating distributed_test_keyspace.tbl compaction strategy for pending repair: e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:42,177 - DEBUG [node3_CompactionExecutor:1:PendingRepairManager@118] - Creating distributed_test_keyspace.tbl compaction strategy for pending repair: e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:42,177 - DEBUG [node1_CompactionExecutor:1:PendingRepairManager@118] - Creating distributed_test_keyspace.tbl compaction strategy for pending repair: e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:42,177 - INFO  [node2_CompactionExecutor:1:CompactionManager@797] - [repair #e7885010-ff45-11ed-bc52-8b144d1e6fed] Completed anticompaction successfully
2023-05-30 19:58:42,178 - INFO  [node2_CompactionExecutor:1:LocalSessions$1@830] - Prepare phase for incremental repair session e7885010-ff45-11ed-bc52-8b144d1e6fed completed
2023-05-30 19:58:42,178 - INFO  [node1_CompactionExecutor:1:CompactionManager@797] - [repair #e7885010-ff45-11ed-bc52-8b144d1e6fed] Completed anticompaction successfully
2023-05-30 19:58:42,178 - INFO  [node3_CompactionExecutor:1:CompactionManager@797] - [repair #e7885010-ff45-11ed-bc52-8b144d1e6fed] Completed anticompaction successfully
2023-05-30 19:58:42,179 - INFO  [node3_CompactionExecutor:1:LocalSessions$1@830] - Prepare phase for incremental repair session e7885010-ff45-11ed-bc52-8b144d1e6fed completed
2023-05-30 19:58:42,179 - INFO  [node1_CompactionExecutor:1:LocalSessions$1@830] - Prepare phase for incremental repair session e7885010-ff45-11ed-bc52-8b144d1e6fed completed
2023-05-30 19:58:42,183 - INFO  [node1_AntiEntropyStage:1:CoordinatorSession@188] - Incremental repair session e7885010-ff45-11ed-bc52-8b144d1e6fed successfully prepared.
2023-05-30 19:58:42,186 - DEBUG [node1_AntiEntropyStage:1:CoordinatorSession$1@305] - Incremental repair e7885010-ff45-11ed-bc52-8b144d1e6fed prepare phase completed in 0 seconds
2023-05-30 19:58:42,187 - INFO  [node1_AntiEntropyStage:1:RepairRunnable@645] - Starting RepairSession for CommonRange{endpoints=[/127.0.0.2:7012, /127.0.0.3:7012], transEndpoints=[], ranges=[(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]], hasSkippedReplicas=false}
2023-05-30 19:58:42,188 - INFO  [node1_AntiEntropyStage:1:RepairSession@258] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] parentSessionId = e7885010-ff45-11ed-bc52-8b144d1e6fed: new session: will sync /127.0.0.1:7012, /127.0.0.2:7012, /127.0.0.3:7012 on range CommonRange{endpoints=[/127.0.0.2:7012, /127.0.0.3:7012], transEndpoints=[], ranges=[(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]], hasSkippedReplicas=false} for distributed_test_keyspace.[tbl]
2023-05-30 19:58:42,200 - INFO  [node1_Repair#1:1:RepairJob@380] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Requesting merkle trees for tbl (to [/127.0.0.2:7012, /127.0.0.3:7012, /127.0.0.1:7012])
2023-05-30 19:58:42,203 - DEBUG [node1_AntiEntropyStage:1:RepairMessageVerbHandler@128] - Validating ValidationRequest{nowInSec=1685491122} org.apache.cassandra.repair.messages.ValidationRequest@64768db2
2023-05-30 19:58:42,203 - INFO  [node1_AntiEntropyStage:1:LocalSessions@887] - Setting local incremental repair session LocalSession{sessionID=e7885010-ff45-11ed-bc52-8b144d1e6fed, state=PREPARED, coordinator=/127.0.0.1:7012, tableIds=[e68c8af0-ff45-11ed-bc52-8b144d1e6fed], repairedAt=1685491122103, ranges=[(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]], participants=[/127.0.0.3:7012, /127.0.0.2:7012, /127.0.0.1:7012], startedAt=1685491122, lastUpdate=1685491122} to REPAIRING
2023-05-30 19:58:42,204 - DEBUG [node2_AntiEntropyStage:1:RepairMessageVerbHandler@128] - Validating ValidationRequest{nowInSec=1685491122} org.apache.cassandra.repair.messages.ValidationRequest@64768db2
2023-05-30 19:58:42,205 - INFO  [node2_AntiEntropyStage:1:LocalSessions@887] - Setting local incremental repair session LocalSession{sessionID=e7885010-ff45-11ed-bc52-8b144d1e6fed, state=PREPARED, coordinator=/127.0.0.1:7012, tableIds=[e68c8af0-ff45-11ed-bc52-8b144d1e6fed], repairedAt=1685491122103, ranges=[(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]], participants=[/127.0.0.3:7012, /127.0.0.2:7012, /127.0.0.1:7012], startedAt=1685491122, lastUpdate=1685491122} to REPAIRING
2023-05-30 19:58:42,205 - DEBUG [node3_AntiEntropyStage:1:RepairMessageVerbHandler@128] - Validating ValidationRequest{nowInSec=1685491122} org.apache.cassandra.repair.messages.ValidationRequest@64768db2
2023-05-30 19:58:42,205 - INFO  [node3_AntiEntropyStage:1:LocalSessions@887] - Setting local incremental repair session LocalSession{sessionID=e7885010-ff45-11ed-bc52-8b144d1e6fed, state=PREPARED, coordinator=/127.0.0.1:7012, tableIds=[e68c8af0-ff45-11ed-bc52-8b144d1e6fed], repairedAt=1685491122103, ranges=[(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]], participants=[/127.0.0.3:7012, /127.0.0.2:7012, /127.0.0.1:7012], startedAt=1685491122, lastUpdate=1685491122} to REPAIRING
2023-05-30 19:58:42,210 - INFO  [node1_ValidationExecutor:1:CassandraValidationIterator@210] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed], parentSessionId=e7885010-ff45-11ed-bc52-8b144d1e6fed: Performing validation compaction on 1 sstables in distributed_test_keyspace.tbl
2023-05-30 19:58:42,211 - INFO  [node3_ValidationExecutor:1:CassandraValidationIterator@210] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed], parentSessionId=e7885010-ff45-11ed-bc52-8b144d1e6fed: Performing validation compaction on 1 sstables in distributed_test_keyspace.tbl
2023-05-30 19:58:42,211 - INFO  [node2_ValidationExecutor:1:CassandraValidationIterator@210] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed], parentSessionId=e7885010-ff45-11ed-bc52-8b144d1e6fed: Performing validation compaction on 1 sstables in distributed_test_keyspace.tbl
2023-05-30 19:58:42,225 - DEBUG [node2_ValidationExecutor:1:ValidationManager@80] - Created 3 merkle trees with merkle trees size 3, 130 partitions, 268 bytes
2023-05-30 19:58:42,225 - DEBUG [node3_ValidationExecutor:1:ValidationManager@80] - Created 3 merkle trees with merkle trees size 3, 130 partitions, 268 bytes
2023-05-30 19:58:42,226 - DEBUG [node1_ValidationExecutor:1:ValidationManager@80] - Created 3 merkle trees with merkle trees size 3, 130 partitions, 268 bytes
2023-05-30 19:58:42,226 - DEBUG [node3_ValidationExecutor:1:Validator@152] - Prepared AEService trees of size 130 for [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed on distributed_test_keyspace/tbl, [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]]]
2023-05-30 19:58:42,226 - DEBUG [node2_ValidationExecutor:1:Validator@152] - Prepared AEService trees of size 130 for [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed on distributed_test_keyspace/tbl, [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]]]
2023-05-30 19:58:42,226 - DEBUG [node1_ValidationExecutor:1:Validator@152] - Prepared AEService trees of size 130 for [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed on distributed_test_keyspace/tbl, [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]]]
2023-05-30 19:58:42,234 - DEBUG [node1_ValidationExecutor:1:Validator@221] - Validated 1 partitions for e79aedb0-ff45-11ed-bc52-8b144d1e6fed.  Partitions per leaf are:
2023-05-30 19:58:42,234 - DEBUG [node2_ValidationExecutor:1:Validator@221] - Validated 1 partitions for e79aedb0-ff45-11ed-bc52-8b144d1e6fed.  Partitions per leaf are:
2023-05-30 19:58:42,234 - DEBUG [node3_ValidationExecutor:1:Validator@221] - Validated 1 partitions for e79aedb0-ff45-11ed-bc52-8b144d1e6fed.  Partitions per leaf are:
2023-05-30 19:58:42,235 - DEBUG [node3_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 1
2023-05-30 19:58:42,235 - DEBUG [node3_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 1
2023-05-30 19:58:42,235 - DEBUG [node2_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 128
2023-05-30 19:58:42,235 - DEBUG [node2_ValidationExecutor:1:EstimatedHistogram@334] -     [1..1]: 1
2023-05-30 19:58:42,235 - DEBUG [node1_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 128
2023-05-30 19:58:42,235 - DEBUG [node1_ValidationExecutor:1:EstimatedHistogram@334] -     [1..1]: 1
2023-05-30 19:58:42,235 - DEBUG [node2_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 1
2023-05-30 19:58:42,235 - DEBUG [node3_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 127
2023-05-30 19:58:42,235 - DEBUG [node2_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 1
2023-05-30 19:58:42,235 - DEBUG [node1_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 1
2023-05-30 19:58:42,235 - DEBUG [node3_ValidationExecutor:1:EstimatedHistogram@334] -     [1..1]: 1
2023-05-30 19:58:42,235 - DEBUG [node2_ValidationExecutor:1:Validator@223] - Validated 1 partitions for e79aedb0-ff45-11ed-bc52-8b144d1e6fed.  Partition sizes are:
2023-05-30 19:58:42,235 - DEBUG [node3_ValidationExecutor:1:Validator@223] - Validated 1 partitions for e79aedb0-ff45-11ed-bc52-8b144d1e6fed.  Partition sizes are:
2023-05-30 19:58:42,235 - DEBUG [node1_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 1
2023-05-30 19:58:42,235 - DEBUG [node3_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 1
2023-05-30 19:58:42,235 - DEBUG [node1_ValidationExecutor:1:Validator@223] - Validated 1 partitions for e79aedb0-ff45-11ed-bc52-8b144d1e6fed.  Partition sizes are:
2023-05-30 19:58:42,235 - DEBUG [node3_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 1
2023-05-30 19:58:42,235 - DEBUG [node2_ValidationExecutor:1:EstimatedHistogram@334] -     [0..1]: 128
2023-05-30 19:58:42,236 - DEBUG [node2_ValidationExecutor:1:EstimatedHistogram@334] -     [2..6]: 0
2023-05-30 19:58:42,236 - DEBUG [node2_ValidationExecutor:1:EstimatedHistogram@334] -    [7..11]: 0
2023-05-30 19:58:42,236 - DEBUG [node3_ValidationExecutor:1:EstimatedHistogram@334] -     [0..1]: 127
2023-05-30 19:58:42,236 - DEBUG [node2_ValidationExecutor:1:EstimatedHistogram@334] -   [12..16]: 0
2023-05-30 19:58:42,236 - DEBUG [node3_ValidationExecutor:1:EstimatedHistogram@334] -     [2..7]: 0
2023-05-30 19:58:42,236 - DEBUG [node2_ValidationExecutor:1:EstimatedHistogram@334] -   [17..69]: 1
2023-05-30 19:58:42,236 - DEBUG [node3_ValidationExecutor:1:EstimatedHistogram@334] -    [8..13]: 0
2023-05-30 19:58:42,236 - DEBUG [node2_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 1
2023-05-30 19:58:42,236 - DEBUG [node3_ValidationExecutor:1:EstimatedHistogram@334] -   [14..19]: 0
2023-05-30 19:58:42,236 - DEBUG [node2_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 1
2023-05-30 19:58:42,236 - DEBUG [node3_ValidationExecutor:1:EstimatedHistogram@334] -   [20..69]: 1
2023-05-30 19:58:42,236 - DEBUG [node1_ValidationExecutor:1:EstimatedHistogram@334] -     [0..1]: 128
2023-05-30 19:58:42,236 - DEBUG [node1_ValidationExecutor:1:EstimatedHistogram@334] -     [2..6]: 0
2023-05-30 19:58:42,236 - INFO  [node2_AntiEntropyStage:1:Validator@248] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Sending completed merkle tree to /127.0.0.1:7012 for distributed_test_keyspace.tbl
2023-05-30 19:58:42,236 - INFO  [node3_AntiEntropyStage:1:Validator@248] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Sending completed merkle tree to /127.0.0.1:7012 for distributed_test_keyspace.tbl
2023-05-30 19:58:42,236 - DEBUG [node1_ValidationExecutor:1:EstimatedHistogram@334] -    [7..11]: 0
2023-05-30 19:58:42,236 - DEBUG [node3_ValidationExecutor:1:ValidationManager@143] - Validation of 130 partitions (~0.027KiB) finished in 27 msec, for [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed on distributed_test_keyspace/tbl, [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]]]
2023-05-30 19:58:42,236 - DEBUG [node2_ValidationExecutor:1:ValidationManager@143] - Validation of 130 partitions (~0.027KiB) finished in 27 msec, for [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed on distributed_test_keyspace/tbl, [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]]]
2023-05-30 19:58:42,236 - DEBUG [node1_ValidationExecutor:1:EstimatedHistogram@334] -   [12..16]: 0
2023-05-30 19:58:42,236 - DEBUG [node1_ValidationExecutor:1:EstimatedHistogram@334] -   [17..69]: 1
2023-05-30 19:58:42,236 - DEBUG [node1_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 1
2023-05-30 19:58:42,236 - DEBUG [node1_ValidationExecutor:1:EstimatedHistogram@334] -     [0..0]: 1
2023-05-30 19:58:42,237 - INFO  [node1_AntiEntropyStage:1:Validator@253] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Local completed merkle tree for /127.0.0.1:7012 for distributed_test_keyspace.tbl
2023-05-30 19:58:42,237 - DEBUG [node1_ValidationExecutor:1:ValidationManager@143] - Validation of 130 partitions (~0.027KiB) finished in 29 msec, for [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed on distributed_test_keyspace/tbl, [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]]]
2023-05-30 19:58:42,238 - DEBUG [node1_AntiEntropyStage:1:MerkleTree@741] - Allocating direct buffer of size 10528 for an off-heap merkle tree
2023-05-30 19:58:42,239 - DEBUG [node1_Messaging-EventLoop-3-9:MerkleTree@741] - Allocating direct buffer of size 10528 for an off-heap merkle tree
2023-05-30 19:58:42,239 - DEBUG [node1_Messaging-EventLoop-3-10:MerkleTree@741] - Allocating direct buffer of size 114 for an off-heap merkle tree
2023-05-30 19:58:42,239 - DEBUG [node1_Messaging-EventLoop-3-10:MerkleTree@741] - Allocating direct buffer of size 114 for an off-heap merkle tree
2023-05-30 19:58:42,239 - DEBUG [node1_Messaging-EventLoop-3-10:MerkleTree@741] - Allocating direct buffer of size 10528 for an off-heap merkle tree
2023-05-30 19:58:42,240 - DEBUG [node1_AntiEntropyStage:1:MerkleTree@741] - Allocating direct buffer of size 114 for an off-heap merkle tree
2023-05-30 19:58:42,240 - DEBUG [node1_AntiEntropyStage:1:MerkleTree@741] - Allocating direct buffer of size 114 for an off-heap merkle tree
2023-05-30 19:58:42,240 - DEBUG [node1_Messaging-EventLoop-3-9:MerkleTree@741] - Allocating direct buffer of size 114 for an off-heap merkle tree
2023-05-30 19:58:42,240 - DEBUG [node1_Messaging-EventLoop-3-9:MerkleTree@741] - Allocating direct buffer of size 114 for an off-heap merkle tree
2023-05-30 19:58:42,240 - INFO  [node1_AntiEntropyStage:1:RepairSession@202] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Received merkle tree for tbl from /127.0.0.1:7012
2023-05-30 19:58:42,242 - INFO  [node1_AntiEntropyStage:1:RepairSession@202] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Received merkle tree for tbl from /127.0.0.3:7012
2023-05-30 19:58:42,243 - INFO  [node1_AntiEntropyStage:1:RepairSession@202] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Received merkle tree for tbl from /127.0.0.2:7012
2023-05-30 19:58:42,246 - INFO  [node1_RepairJobTask:2:RepairJob@265] - Created 3 sync tasks based on 3 merkle tree responses for e7885010-ff45-11ed-bc52-8b144d1e6fed (took: 2ms)
2023-05-30 19:58:42,247 - INFO  [node1_RepairJobTask:1:SyncTask@87] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Endpoints /127.0.0.1:7012 and /127.0.0.2:7012 have 2 range(s) out of sync for tbl
2023-05-30 19:58:42,247 - INFO  [node1_RepairJobTask:3:SyncTask@87] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Endpoints /127.0.0.2:7012 and /127.0.0.3:7012 have 2 range(s) out of sync for tbl
2023-05-30 19:58:42,247 - INFO  [node1_RepairJobTask:4:SyncTask@87] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Endpoints /127.0.0.1:7012 and /127.0.0.3:7012 have 2 range(s) out of sync for tbl
2023-05-30 19:58:42,247 - INFO  [node1_RepairJobTask:1:LocalSyncTask@117] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Performing streaming repair of 2 ranges with /127.0.0.2:7012
2023-05-30 19:58:42,247 - INFO  [node1_RepairJobTask:4:LocalSyncTask@117] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Performing streaming repair of 2 ranges with /127.0.0.3:7012
2023-05-30 19:58:42,248 - INFO  [node1_RepairJobTask:3:SymmetricRemoteSyncTask@69] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Forwarding streaming repair of 2 ranges to /127.0.0.2:7012 (to be streamed with /127.0.0.3:7012)
2023-05-30 19:58:42,250 - DEBUG [node2_AntiEntropyStage:1:RepairMessageVerbHandler@148] - Syncing SyncRequest{initiator=/127.0.0.1:7012, src=/127.0.0.2:7012, dst=/127.0.0.3:7012, ranges=[(9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]], previewKind=NONE, asymmetric=false} org.apache.cassandra.repair.messages.SyncRequest@30138d86
2023-05-30 19:58:42,252 - INFO  [node2_AntiEntropyStage:1:StreamingRepairTask@75] - [streaming task #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Performing streaming repair of 2 ranges with /127.0.0.3:7012
2023-05-30 19:58:42,261 - DEBUG [node2_AntiEntropyStage:1:StreamSession@243] - Creating stream session to peer: (/127.0.0.3:7012, null), framing: null, encryption: unencrypted as initiator
2023-05-30 19:58:42,262 - DEBUG [node1_RepairJobTask:1:StreamSession@243] - Creating stream session to peer: (/127.0.0.2:7012, null), framing: null, encryption: unencrypted as initiator
2023-05-30 19:58:42,262 - DEBUG [node1_RepairJobTask:4:StreamSession@243] - Creating stream session to peer: (/127.0.0.3:7012, null), framing: null, encryption: unencrypted as initiator
2023-05-30 19:58:42,265 - DEBUG [node2_AntiEntropyStage:1:CassandraStreamManager@125] - ViewFilter for 1/1 sstables
2023-05-30 19:58:42,265 - DEBUG [node1_RepairJobTask:4:CassandraStreamManager@125] - ViewFilter for 1/1 sstables
2023-05-30 19:58:42,265 - DEBUG [node1_RepairJobTask:1:CassandraStreamManager@125] - ViewFilter for 1/1 sstables
2023-05-30 19:58:42,280 - INFO  [node2_AntiEntropyStage:1:StreamResultFuture@90] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Executing streaming plan for Repair
2023-05-30 19:58:42,280 - INFO  [node1_RepairJobTask:4:StreamResultFuture@90] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Executing streaming plan for Repair
2023-05-30 19:58:42,280 - INFO  [node1_RepairJobTask:1:StreamResultFuture@90] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Executing streaming plan for Repair
2023-05-30 19:58:42,280 - INFO  [node2_AntiEntropyStage:1:StreamSession@360] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Starting streaming to /127.0.0.3:7012
2023-05-30 19:58:42,280 - INFO  [node1_RepairJobTask:1:StreamSession@360] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Starting streaming to /127.0.0.2:7012
2023-05-30 19:58:42,280 - INFO  [node1_RepairJobTask:4:StreamSession@360] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Starting streaming to /127.0.0.3:7012
2023-05-30 19:58:42,289 - DEBUG [node2_AntiEntropyStage:1:NettyStreamingMessageSender@208] - Creating channel id 72d81333 local /127.0.0.1:39198 remote /127.0.0.3:7012
2023-05-30 19:58:42,289 - DEBUG [node1_RepairJobTask:4:NettyStreamingMessageSender@208] - Creating channel id 03197f6e local /127.0.0.1:39202 remote /127.0.0.3:7012
2023-05-30 19:58:42,289 - DEBUG [node1_RepairJobTask:1:NettyStreamingMessageSender@208] - Creating channel id eb9c209e local /127.0.0.1:50574 remote /127.0.0.2:7012
2023-05-30 19:58:42,289 - DEBUG [node2_AntiEntropyStage:1:NettyStreamingMessageSender@189] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 72d81333] Scheduling keep-alive task with 300s period.
2023-05-30 19:58:42,289 - INFO  [node3_Messaging-EventLoop-3-10:InboundConnectionInitiator$Handler@400] - /127.0.0.2:7012(/127.0.0.1:39198)->/127.0.0.3:7012-STREAMING-790fcdcd streaming connection established, version = 12, framing = UNPROTECTED, encryption = unencrypted
2023-05-30 19:58:42,289 - INFO  [node3_Messaging-EventLoop-3-11:InboundConnectionInitiator$Handler@400] - /127.0.0.1:7012(/127.0.0.1:39202)->/127.0.0.3:7012-STREAMING-2910f6c7 streaming connection established, version = 12, framing = UNPROTECTED, encryption = unencrypted
2023-05-30 19:58:42,290 - DEBUG [node1_RepairJobTask:4:NettyStreamingMessageSender@189] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 03197f6e] Scheduling keep-alive task with 300s period.
2023-05-30 19:58:42,290 - DEBUG [node1_RepairJobTask:1:NettyStreamingMessageSender@189] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: eb9c209e] Scheduling keep-alive task with 300s period.
2023-05-30 19:58:42,290 - INFO  [node2_Messaging-EventLoop-3-10:InboundConnectionInitiator$Handler@400] - /127.0.0.1:7012(/127.0.0.1:50574)->/127.0.0.2:7012-STREAMING-7ee83ec9 streaming connection established, version = 12, framing = UNPROTECTED, encryption = unencrypted
2023-05-30 19:58:42,290 - DEBUG [Streaming-EventLoop-4-1:NettyStreamingMessageSender@261] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 72d81333] Sending keep-alive
2023-05-30 19:58:42,290 - DEBUG [node2_AntiEntropyStage:1:NettyStreamingMessageSender@261] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 72d81333] Sending StreamInitMessage: from = /127.0.0.2:7012, planId = e7a4ffd0-ff45-11ed-8fcf-679a97013a80, session index = 0
2023-05-30 19:58:42,290 - DEBUG [node1_RepairJobTask:1:NettyStreamingMessageSender@261] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: eb9c209e] Sending StreamInitMessage: from = /127.0.0.1:7012, planId = e7a43c80-ff45-11ed-bc52-8b144d1e6fed, session index = 0
2023-05-30 19:58:42,290 - DEBUG [node1_RepairJobTask:4:NettyStreamingMessageSender@261] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 03197f6e] Sending StreamInitMessage: from = /127.0.0.1:7012, planId = e7a43c81-ff45-11ed-bc52-8b144d1e6fed, session index = 0
2023-05-30 19:58:42,291 - DEBUG [Streaming-EventLoop-4-1:NettyStreamingMessageSender@261] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 03197f6e] Sending keep-alive
2023-05-30 19:58:42,291 - DEBUG [Streaming-EventLoop-4-2:NettyStreamingMessageSender@261] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: eb9c209e] Sending keep-alive
2023-05-30 19:58:42,295 - DEBUG [node2_AntiEntropyStage:1:NettyStreamingMessageSender@261] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 72d81333] Sending Prepare SYN (1 requests,  7 files}
2023-05-30 19:58:42,295 - DEBUG [node1_RepairJobTask:4:NettyStreamingMessageSender@261] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 03197f6e] Sending Prepare SYN (1 requests,  7 files}
2023-05-30 19:58:42,295 - DEBUG [node1_RepairJobTask:1:NettyStreamingMessageSender@261] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: eb9c209e] Sending Prepare SYN (1 requests,  7 files}
2023-05-30 19:58:42,295 - INFO  [node1_RepairJobTask:4:StreamCoordinator@264] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed, ID#0] Beginning stream session with /127.0.0.3:7012
2023-05-30 19:58:42,295 - INFO  [node1_RepairJobTask:1:StreamCoordinator@264] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed, ID#0] Beginning stream session with /127.0.0.2:7012
2023-05-30 19:58:42,295 - INFO  [node2_AntiEntropyStage:1:StreamCoordinator@264] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80, ID#0] Beginning stream session with /127.0.0.3:7012
2023-05-30 19:58:42,693 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:StreamingInboundHandler$StreamDeserializingTask@179] - [Stream channel: 7ee83ec9] Received keep-alive
2023-05-30 19:58:42,699 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-790fcdcd:StreamingInboundHandler$StreamDeserializingTask@179] - [Stream channel: 790fcdcd] Received keep-alive
2023-05-30 19:58:42,699 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-2910f6c7:StreamingInboundHandler$StreamDeserializingTask@179] - [Stream channel: 2910f6c7] Received keep-alive
2023-05-30 19:58:43,093 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:StreamResultFuture@114] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed ID#0] Creating new streaming plan for Repair from /127.0.0.1:7012 channel.remote /127.0.0.1:50574 channel.local /127.0.0.2:7012 channel.id 7ee83ec9
2023-05-30 19:58:43,095 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:StreamSession@243] - Creating stream session to peer: (/127.0.0.1:7012, null), framing: null, encryption: unencrypted as follower
2023-05-30 19:58:43,095 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:StreamResultFuture@123] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed, ID#0] Received streaming plan for Repair from /127.0.0.1:7012 channel.remote /127.0.0.1:50574 channel.local /127.0.0.2:7012 channel.id 7ee83ec9
2023-05-30 19:58:43,095 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:NettyStreamingMessageSender@189] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: 7ee83ec9] Scheduling keep-alive task with 300s period.
2023-05-30 19:58:43,095 - DEBUG [node2_Messaging-EventLoop-3-10:NettyStreamingMessageSender@261] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: 7ee83ec9] Sending keep-alive
2023-05-30 19:58:43,096 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: 7ee83ec9] Received StreamInitMessage: from = /127.0.0.1:7012, planId = e7a43c80-ff45-11ed-bc52-8b144d1e6fed, session index = 0
2023-05-30 19:58:43,096 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: 7ee83ec9] Received Prepare SYN (1 requests,  7 files}
2023-05-30 19:58:43,097 - DEBUG [node2_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in tbl
2023-05-30 19:58:43,097 - DEBUG [node2_NonPeriodicTasks:1:CassandraStreamManager@125] - ViewFilter for 1/1 sstables
2023-05-30 19:58:43,100 - DEBUG [node2_NonPeriodicTasks:1:NettyStreamingMessageSender@261] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: 7ee83ec9] Sending Prepare SYNACK ( 7 files}
2023-05-30 19:58:43,100 - INFO  [node2_NonPeriodicTasks:1:StreamResultFuture@179] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed ID#0] Prepare completed. Receiving 7 files(4.783KiB), sending 7 files(4.783KiB)
2023-05-30 19:58:43,102 - INFO  [Stream-Deserializer-/127.0.0.1:7012-2910f6c7:StreamResultFuture@114] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed ID#0] Creating new streaming plan for Repair from /127.0.0.1:7012 channel.remote /127.0.0.1:39202 channel.local /127.0.0.3:7012 channel.id 2910f6c7
2023-05-30 19:58:43,107 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-2910f6c7:StreamSession@243] - Creating stream session to peer: (/127.0.0.1:7012, null), framing: null, encryption: unencrypted as follower
2023-05-30 19:58:43,107 - INFO  [Stream-Deserializer-/127.0.0.1:7012-2910f6c7:StreamResultFuture@123] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed, ID#0] Received streaming plan for Repair from /127.0.0.1:7012 channel.remote /127.0.0.1:39202 channel.local /127.0.0.3:7012 channel.id 2910f6c7
2023-05-30 19:58:43,108 - INFO  [Stream-Deserializer-/127.0.0.2:7012-790fcdcd:StreamResultFuture@114] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 ID#0] Creating new streaming plan for Repair from /127.0.0.2:7012 channel.remote /127.0.0.1:39198 channel.local /127.0.0.3:7012 channel.id 790fcdcd
2023-05-30 19:58:43,108 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-2910f6c7:NettyStreamingMessageSender@189] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 2910f6c7] Scheduling keep-alive task with 300s period.
2023-05-30 19:58:43,108 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-790fcdcd:StreamSession@243] - Creating stream session to peer: (/127.0.0.2:7012, null), framing: null, encryption: unencrypted as follower
2023-05-30 19:58:43,108 - INFO  [Stream-Deserializer-/127.0.0.2:7012-790fcdcd:StreamResultFuture@123] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80, ID#0] Received streaming plan for Repair from /127.0.0.2:7012 channel.remote /127.0.0.1:39198 channel.local /127.0.0.3:7012 channel.id 790fcdcd
2023-05-30 19:58:43,109 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-790fcdcd:NettyStreamingMessageSender@189] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 790fcdcd] Scheduling keep-alive task with 300s period.
2023-05-30 19:58:43,109 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-2910f6c7:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 2910f6c7] Received StreamInitMessage: from = /127.0.0.1:7012, planId = e7a43c81-ff45-11ed-bc52-8b144d1e6fed, session index = 0
2023-05-30 19:58:43,109 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-790fcdcd:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 790fcdcd] Received StreamInitMessage: from = /127.0.0.2:7012, planId = e7a4ffd0-ff45-11ed-8fcf-679a97013a80, session index = 0
2023-05-30 19:58:43,109 - DEBUG [node3_Messaging-EventLoop-3-10:NettyStreamingMessageSender@261] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 790fcdcd] Sending keep-alive
2023-05-30 19:58:43,109 - DEBUG [node3_Messaging-EventLoop-3-11:NettyStreamingMessageSender@261] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 2910f6c7] Sending keep-alive
2023-05-30 19:58:43,111 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-790fcdcd:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 790fcdcd] Received Prepare SYN (1 requests,  7 files}
2023-05-30 19:58:43,111 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-2910f6c7:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 2910f6c7] Received Prepare SYN (1 requests,  7 files}
2023-05-30 19:58:43,112 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in tbl
2023-05-30 19:58:43,112 - DEBUG [node3_NonPeriodicTasks:1:CassandraStreamManager@125] - ViewFilter for 1/1 sstables
2023-05-30 19:58:43,121 - DEBUG [node3_NonPeriodicTasks:1:NettyStreamingMessageSender@261] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 790fcdcd] Sending Prepare SYNACK ( 7 files}
2023-05-30 19:58:43,123 - INFO  [node3_NonPeriodicTasks:1:StreamResultFuture@179] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 ID#0] Prepare completed. Receiving 7 files(4.783KiB), sending 7 files(4.781KiB)
2023-05-30 19:58:43,127 - DEBUG [node3_MemtablePostFlush:1:ColumnFamilyStore@933] - forceFlush requested but everything is clean in tbl
2023-05-30 19:58:43,127 - DEBUG [node3_NonPeriodicTasks:1:CassandraStreamManager@125] - ViewFilter for 1/1 sstables
2023-05-30 19:58:43,127 - DEBUG [node3_NonPeriodicTasks:1:NettyStreamingMessageSender@261] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 2910f6c7] Sending Prepare SYNACK ( 7 files}
2023-05-30 19:58:43,128 - INFO  [node3_NonPeriodicTasks:1:StreamResultFuture@179] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed ID#0] Prepare completed. Receiving 7 files(4.783KiB), sending 7 files(4.781KiB)
2023-05-30 19:58:43,493 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-72d81333:StreamingInboundHandler$StreamDeserializingTask@179] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 72d81333] Received keep-alive
2023-05-30 19:58:43,494 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-eb9c209e:StreamingInboundHandler$StreamDeserializingTask@179] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: eb9c209e] Received keep-alive
2023-05-30 19:58:43,494 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-03197f6e:StreamingInboundHandler$StreamDeserializingTask@179] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 03197f6e] Received keep-alive
2023-05-30 19:58:43,894 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-72d81333:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 72d81333] Received Prepare SYNACK ( 7 files}
2023-05-30 19:58:43,894 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-03197f6e:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 03197f6e] Received Prepare SYNACK ( 7 files}
2023-05-30 19:58:43,894 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-eb9c209e:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: eb9c209e] Received Prepare SYNACK ( 7 files}
2023-05-30 19:58:43,895 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-72d81333:NettyStreamingMessageSender@261] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 72d81333] Sending Prepare ACK
2023-05-30 19:58:43,895 - INFO  [Stream-Deserializer-/127.0.0.3:7012-72d81333:StreamResultFuture@179] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 ID#0] Prepare completed. Receiving 7 files(4.781KiB), sending 7 files(4.783KiB)
2023-05-30 19:58:43,896 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-72d81333:NettyStreamingMessageSender@238] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Sending OutgoingStreamMessage{header=Header (tableId: e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0, repairedAt: 0, pendingRepair: e7885010-ff45-11ed-bc52-8b144d1e6fed, sendByFollower: false), stream=CassandraOutgoingFile{/tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db}}
2023-05-30 19:58:43,897 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-03197f6e:NettyStreamingMessageSender@261] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 03197f6e] Sending Prepare ACK
2023-05-30 19:58:43,897 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-eb9c209e:NettyStreamingMessageSender@261] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: eb9c209e] Sending Prepare ACK
2023-05-30 19:58:43,898 - INFO  [Stream-Deserializer-/127.0.0.3:7012-03197f6e:StreamResultFuture@179] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed ID#0] Prepare completed. Receiving 7 files(4.781KiB), sending 7 files(4.783KiB)
2023-05-30 19:58:43,898 - INFO  [Stream-Deserializer-/127.0.0.2:7012-eb9c209e:StreamResultFuture@179] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed ID#0] Prepare completed. Receiving 7 files(4.783KiB), sending 7 files(4.783KiB)
2023-05-30 19:58:43,903 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-03197f6e:NettyStreamingMessageSender@238] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Sending OutgoingStreamMessage{header=Header (tableId: e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0, repairedAt: 0, pendingRepair: e7885010-ff45-11ed-bc52-8b144d1e6fed, sendByFollower: false), stream=CassandraOutgoingFile{/tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db}}
2023-05-30 19:58:43,903 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-eb9c209e:NettyStreamingMessageSender@238] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Sending OutgoingStreamMessage{header=Header (tableId: e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0, repairedAt: 0, pendingRepair: e7885010-ff45-11ed-bc52-8b144d1e6fed, sendByFollower: false), stream=CassandraOutgoingFile{/tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db}}
2023-05-30 19:58:43,903 - INFO  [node3_Messaging-EventLoop-3-12:InboundConnectionInitiator$Handler@400] - /127.0.0.2:7012(/127.0.0.1:39204)->/127.0.0.3:7012-STREAMING-b142c5d2 streaming connection established, version = 12, framing = UNPROTECTED, encryption = unencrypted
2023-05-30 19:58:43,903 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:NettyStreamingMessageSender@208] - Creating channel id bae64572 local /127.0.0.1:39204 remote /127.0.0.3:7012
2023-05-30 19:58:43,909 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:NettyStreamingMessageSender@208] - Creating channel id 7be9c090 local /127.0.0.1:50580 remote /127.0.0.2:7012
2023-05-30 19:58:43,909 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:NettyStreamingMessageSender@208] - Creating channel id 5882c103 local /127.0.0.1:39206 remote /127.0.0.3:7012
2023-05-30 19:58:43,910 - INFO  [node3_Messaging-EventLoop-3-13:InboundConnectionInitiator$Handler@400] - /127.0.0.1:7012(/127.0.0.1:39206)->/127.0.0.3:7012-STREAMING-313f83d7 streaming connection established, version = 12, framing = UNPROTECTED, encryption = unencrypted
2023-05-30 19:58:43,910 - INFO  [node2_Messaging-EventLoop-3-11:InboundConnectionInitiator$Handler@400] - /127.0.0.1:7012(/127.0.0.1:50580)->/127.0.0.2:7012-STREAMING-7b13a7bc streaming connection established, version = 12, framing = UNPROTECTED, encryption = unencrypted
2023-05-30 19:58:43,911 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@69] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Start streaming sstable /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db to /127.0.0.3:7012, repairedAt = 0, totalSize = 4.783KiB
2023-05-30 19:58:43,911 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 1 component Data.db size 0.033KiB
2023-05-30 19:58:43,912 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-2910f6c7:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 2910f6c7] Received Prepare ACK
2023-05-30 19:58:43,912 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-790fcdcd:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 790fcdcd] Received Prepare ACK
2023-05-30 19:58:43,912 - INFO  [Stream-Deserializer-/127.0.0.1:7012-2910f6c7:StreamResultFuture@179] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed ID#0] Prepare completed. Receiving 7 files(4.783KiB), sending 7 files(4.781KiB)
2023-05-30 19:58:43,912 - INFO  [Stream-Deserializer-/127.0.0.2:7012-790fcdcd:StreamResultFuture@179] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 ID#0] Prepare completed. Receiving 7 files(4.783KiB), sending 7 files(4.781KiB)
2023-05-30 19:58:43,913 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-790fcdcd:NettyStreamingMessageSender@238] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Sending OutgoingStreamMessage{header=Header (tableId: e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0, repairedAt: 0, pendingRepair: e7885010-ff45-11ed-bc52-8b144d1e6fed, sendByFollower: true), stream=CassandraOutgoingFile{/tmp/dtests293447409190997823/node3/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-3-big-Data.db}}
2023-05-30 19:58:43,913 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-2910f6c7:NettyStreamingMessageSender@238] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Sending OutgoingStreamMessage{header=Header (tableId: e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0, repairedAt: 0, pendingRepair: e7885010-ff45-11ed-bc52-8b144d1e6fed, sendByFollower: true), stream=CassandraOutgoingFile{/tmp/dtests293447409190997823/node3/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-3-big-Data.db}}
2023-05-30 19:58:43,915 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@69] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Start streaming sstable /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db to /127.0.0.2:7012, repairedAt = 0, totalSize = 4.783KiB
2023-05-30 19:58:43,915 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@69] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Start streaming sstable /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db to /127.0.0.3:7012, repairedAt = 0, totalSize = 4.783KiB
2023-05-30 19:58:43,916 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Data.db size 0.033KiB
2023-05-30 19:58:43,916 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Data.db size 0.033KiB
2023-05-30 19:58:43,919 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 1 component Data.db to /127.0.0.3:7012, xfered = 0.033KiB, length = 0.033KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,919 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 1 component Index.db size 0.008KiB
2023-05-30 19:58:43,920 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 1 component Index.db to /127.0.0.3:7012, xfered = 0.008KiB, length = 0.008KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,921 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 1 component Statistics.db size 4.616KiB
2023-05-30 19:58:43,922 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 1 component Statistics.db to /127.0.0.3:7012, xfered = 4.616KiB, length = 4.616KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,922 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 1 component CompressionInfo.db size 0.046KiB
2023-05-30 19:58:43,924 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 1 component CompressionInfo.db to /127.0.0.3:7012, xfered = 0.046KiB, length = 0.046KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,923 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Data.db to /127.0.0.3:7012, xfered = 0.033KiB, length = 0.033KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,923 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Data.db to /127.0.0.2:7012, xfered = 0.033KiB, length = 0.033KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,924 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 1 component Filter.db size 0.016KiB
2023-05-30 19:58:43,924 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Index.db size 0.008KiB
2023-05-30 19:58:43,924 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Index.db size 0.008KiB
2023-05-30 19:58:43,924 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 1 component Filter.db to /127.0.0.3:7012, xfered = 0.016KiB, length = 0.016KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,925 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 1 component Summary.db size 0.055KiB
2023-05-30 19:58:43,925 - INFO  [node1_Messaging-EventLoop-3-15:InboundConnectionInitiator$Handler@400] - /127.0.0.3:7012(/127.0.0.1:50952)->/127.0.0.1:7012-STREAMING-ca05ba6b streaming connection established, version = 12, framing = UNPROTECTED, encryption = unencrypted
2023-05-30 19:58:43,925 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Index.db to /127.0.0.3:7012, xfered = 0.008KiB, length = 0.008KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,925 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Index.db to /127.0.0.2:7012, xfered = 0.008KiB, length = 0.008KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,925 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 1 component Summary.db to /127.0.0.3:7012, xfered = 0.055KiB, length = 0.055KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,926 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Statistics.db size 4.616KiB
2023-05-30 19:58:43,926 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Statistics.db size 4.616KiB
2023-05-30 19:58:43,926 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 1 component Digest.crc32 size 0.010KiB
2023-05-30 19:58:43,926 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:NettyStreamingMessageSender@208] - Creating channel id d35f00b7 local /127.0.0.1:50952 remote /127.0.0.1:7012
2023-05-30 19:58:43,926 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:NettyStreamingMessageSender@208] - Creating channel id ef8137da local /127.0.0.1:50586 remote /127.0.0.2:7012
2023-05-30 19:58:43,926 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 1 component Digest.crc32 to /127.0.0.3:7012, xfered = 0.010KiB, length = 0.010KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,926 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Statistics.db to /127.0.0.2:7012, xfered = 4.616KiB, length = 4.616KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,926 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Statistics.db to /127.0.0.3:7012, xfered = 4.616KiB, length = 4.616KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,926 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component CompressionInfo.db size 0.046KiB
2023-05-30 19:58:43,926 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component CompressionInfo.db size 0.046KiB
2023-05-30 19:58:43,926 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component CompressionInfo.db to /127.0.0.3:7012, xfered = 0.046KiB, length = 0.046KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,926 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component CompressionInfo.db to /127.0.0.2:7012, xfered = 0.046KiB, length = 0.046KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,926 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Filter.db size 0.016KiB
2023-05-30 19:58:43,926 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Filter.db size 0.016KiB
2023-05-30 19:58:43,927 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Filter.db to /127.0.0.2:7012, xfered = 0.016KiB, length = 0.016KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,927 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Filter.db to /127.0.0.3:7012, xfered = 0.016KiB, length = 0.016KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,927 - INFO  [node2_Messaging-EventLoop-3-12:InboundConnectionInitiator$Handler@400] - /127.0.0.3:7012(/127.0.0.1:50586)->/127.0.0.2:7012-STREAMING-1486e1d3 streaming connection established, version = 12, framing = UNPROTECTED, encryption = unencrypted
2023-05-30 19:58:43,927 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Summary.db size 0.055KiB
2023-05-30 19:58:43,927 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Summary.db size 0.055KiB
2023-05-30 19:58:43,928 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@112] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming sstable /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db to /127.0.0.3:7012, xfered = 4.783KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,931 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Summary.db to /127.0.0.3:7012, xfered = 0.055KiB, length = 0.055KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,932 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Summary.db to /127.0.0.2:7012, xfered = 0.055KiB, length = 0.055KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,932 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Digest.crc32 size 0.010KiB
2023-05-30 19:58:43,932 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Digest.crc32 size 0.010KiB
2023-05-30 19:58:43,933 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Digest.crc32 to /127.0.0.3:7012, xfered = 0.010KiB, length = 0.010KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,933 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Digest.crc32 to /127.0.0.2:7012, xfered = 0.010KiB, length = 0.010KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,934 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.3.7012:1:CassandraEntireSSTableStreamWriter@112] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming sstable /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db to /127.0.0.3:7012, xfered = 4.783KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,934 - DEBUG [node1_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@112] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming sstable /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db to /127.0.0.2:7012, xfered = 4.783KiB, totalSize = 4.783KiB
2023-05-30 19:58:43,936 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@69] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Start streaming sstable /tmp/dtests293447409190997823/node3/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-3-big-Data.db to /127.0.0.1:7012, repairedAt = 0, totalSize = 4.781KiB
2023-05-30 19:58:43,936 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@69] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Start streaming sstable /tmp/dtests293447409190997823/node3/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-3-big-Data.db to /127.0.0.2:7012, repairedAt = 0, totalSize = 4.781KiB
2023-05-30 19:58:43,937 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 3 component Data.db size 0.033KiB
2023-05-30 19:58:43,937 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 3 component Data.db size 0.033KiB
2023-05-30 19:58:43,940 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 3 component Data.db to /127.0.0.1:7012, xfered = 0.033KiB, length = 0.033KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,940 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 3 component Data.db to /127.0.0.2:7012, xfered = 0.033KiB, length = 0.033KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,941 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 3 component Index.db size 0.008KiB
2023-05-30 19:58:43,941 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 3 component Index.db size 0.008KiB
2023-05-30 19:58:43,941 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 3 component Index.db to /127.0.0.1:7012, xfered = 0.008KiB, length = 0.008KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,941 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 3 component Statistics.db size 4.616KiB
2023-05-30 19:58:43,941 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 3 component Index.db to /127.0.0.2:7012, xfered = 0.008KiB, length = 0.008KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,941 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 3 component Statistics.db to /127.0.0.1:7012, xfered = 4.616KiB, length = 4.616KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,941 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 3 component Statistics.db size 4.616KiB
2023-05-30 19:58:43,942 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 3 component CompressionInfo.db size 0.046KiB
2023-05-30 19:58:43,942 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 3 component CompressionInfo.db to /127.0.0.1:7012, xfered = 0.046KiB, length = 0.046KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,943 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 3 component Filter.db size 0.016KiB
2023-05-30 19:58:43,943 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 3 component Statistics.db to /127.0.0.2:7012, xfered = 4.616KiB, length = 4.616KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,943 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 3 component Filter.db to /127.0.0.1:7012, xfered = 0.016KiB, length = 0.016KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,943 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 3 component Summary.db size 0.055KiB
2023-05-30 19:58:43,943 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 3 component CompressionInfo.db size 0.046KiB
2023-05-30 19:58:43,944 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 3 component Summary.db to /127.0.0.1:7012, xfered = 0.055KiB, length = 0.055KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,944 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 3 component Digest.crc32 size 0.008KiB
2023-05-30 19:58:43,944 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 3 component CompressionInfo.db to /127.0.0.2:7012, xfered = 0.046KiB, length = 0.046KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,945 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 3 component Digest.crc32 to /127.0.0.1:7012, xfered = 0.008KiB, length = 0.008KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,945 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 3 component Filter.db size 0.016KiB
2023-05-30 19:58:43,945 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@112] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished streaming sstable /tmp/dtests293447409190997823/node3/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-3-big-Data.db to /127.0.0.1:7012, xfered = 4.781KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,945 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 3 component Filter.db to /127.0.0.2:7012, xfered = 0.016KiB, length = 0.016KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,945 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 3 component Summary.db size 0.055KiB
2023-05-30 19:58:43,946 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 3 component Summary.db to /127.0.0.2:7012, xfered = 0.055KiB, length = 0.055KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,946 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming distributed_test_keyspace.tbl gen 3 component Digest.crc32 size 0.008KiB
2023-05-30 19:58:43,946 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming distributed_test_keyspace.tbl gen 3 component Digest.crc32 to /127.0.0.2:7012, xfered = 0.008KiB, length = 0.008KiB, totalSize = 4.781KiB
2023-05-30 19:58:43,947 - DEBUG [node3_NettyStreaming-Outbound-/127.0.0.2.7012:1:CassandraEntireSSTableStreamWriter@112] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished streaming sstable /tmp/dtests293447409190997823/node3/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-3-big-Data.db to /127.0.0.2:7012, xfered = 4.781KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,297 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: 7ee83ec9] Received Prepare ACK
2023-05-30 19:58:44,298 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:StreamResultFuture@179] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed ID#0] Prepare completed. Receiving 7 files(4.783KiB), sending 7 files(4.783KiB)
2023-05-30 19:58:44,298 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:NettyStreamingMessageSender@238] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Sending OutgoingStreamMessage{header=Header (tableId: e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0, repairedAt: 0, pendingRepair: e7885010-ff45-11ed-bc52-8b144d1e6fed, sendByFollower: true), stream=CassandraOutgoingFile{/tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db}}
2023-05-30 19:58:44,303 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:NettyStreamingMessageSender@208] - Creating channel id d87b18e3 local /127.0.0.1:50956 remote /127.0.0.1:7012
2023-05-30 19:58:44,303 - INFO  [node1_Messaging-EventLoop-3-16:InboundConnectionInitiator$Handler@400] - /127.0.0.2:7012(/127.0.0.1:50956)->/127.0.0.1:7012-STREAMING-9c970f1a streaming connection established, version = 12, framing = UNPROTECTED, encryption = unencrypted
2023-05-30 19:58:44,303 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@69] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Start streaming sstable /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db to /127.0.0.1:7012, repairedAt = 0, totalSize = 4.783KiB
2023-05-30 19:58:44,304 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Data.db size 0.033KiB
2023-05-30 19:58:44,304 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Data.db to /127.0.0.1:7012, xfered = 0.033KiB, length = 0.033KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,304 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Index.db size 0.008KiB
2023-05-30 19:58:44,305 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Index.db to /127.0.0.1:7012, xfered = 0.008KiB, length = 0.008KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,305 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Statistics.db size 4.616KiB
2023-05-30 19:58:44,305 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Statistics.db to /127.0.0.1:7012, xfered = 4.616KiB, length = 4.616KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,305 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component CompressionInfo.db size 0.046KiB
2023-05-30 19:58:44,306 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component CompressionInfo.db to /127.0.0.1:7012, xfered = 0.046KiB, length = 0.046KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,306 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Filter.db size 0.016KiB
2023-05-30 19:58:44,307 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Filter.db to /127.0.0.1:7012, xfered = 0.016KiB, length = 0.016KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,307 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Summary.db size 0.055KiB
2023-05-30 19:58:44,307 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Summary.db to /127.0.0.1:7012, xfered = 0.055KiB, length = 0.055KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,307 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@84] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming distributed_test_keyspace.tbl gen 1 component Digest.crc32 size 0.010KiB
2023-05-30 19:58:44,307 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@98] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming distributed_test_keyspace.tbl gen 1 component Digest.crc32 to /127.0.0.1:7012, xfered = 0.010KiB, length = 0.010KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,307 - DEBUG [node2_NettyStreaming-Outbound-/127.0.0.1.7012:1:CassandraEntireSSTableStreamWriter@112] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished streaming sstable /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db to /127.0.0.1:7012, xfered = 4.783KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,309 - ERROR [Stream-Deserializer-/127.0.0.2:7012-b142c5d2:StreamSession@675] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming error occurred on session with peer 127.0.0.2:7012
org.apache.cassandra.streaming.StreamReceiveException: java.io.IOException: Failing incoming file read from test!
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:60)
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:38)
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:53)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.run(StreamingInboundHandler.java:172)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failing incoming file read from test!
	at org.apache.cassandra.distributed.test.RepairErrorsTest$ByteBuddyHelperStreamFailure.read(RepairErrorsTest.java:252)
	at org.apache.cassandra.db.streaming.CassandraIncomingFile.read(CassandraIncomingFile.java)
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:53)
	... 5 common frames omitted
2023-05-30 19:58:44,309 - ERROR [Stream-Deserializer-/127.0.0.2:7012-b142c5d2:StreamSession@675] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Streaming error occurred on session with peer 127.0.0.2:7012
org.apache.cassandra.streaming.StreamReceiveException: java.io.IOException: Failing incoming file read from test!
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:60)
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:38)
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:53)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.run(StreamingInboundHandler.java:172)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failing incoming file read from test!
	at org.apache.cassandra.distributed.test.RepairErrorsTest$ByteBuddyHelperStreamFailure.read(RepairErrorsTest.java:252)
	at org.apache.cassandra.db.streaming.CassandraIncomingFile.read(CassandraIncomingFile.java)
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:53)
	... 5 common frames omitted
2023-05-30 19:58:44,309 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-b142c5d2:NettyStreamingMessageSender@261] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 790fcdcd] Sending Session Failed
2023-05-30 19:58:44,310 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-b142c5d2:StreamSession@502] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Will close attached channels {ef8137da=[id: 0xef8137da, L:/127.0.0.1:50586 - R:/127.0.0.2:7012], 790fcdcd=[id: 0x790fcdcd, L:/127.0.0.3:7012 - R:/127.0.0.1:39198]}
2023-05-30 19:58:44,310 - ERROR [Stream-Deserializer-/127.0.0.1:7012-313f83d7:StreamSession@675] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming error occurred on session with peer 127.0.0.1:7012
org.apache.cassandra.streaming.StreamReceiveException: java.io.IOException: Failing incoming file read from test!
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:60)
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:38)
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:53)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.run(StreamingInboundHandler.java:172)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failing incoming file read from test!
	at org.apache.cassandra.distributed.test.RepairErrorsTest$ByteBuddyHelperStreamFailure.read(RepairErrorsTest.java:252)
	at org.apache.cassandra.db.streaming.CassandraIncomingFile.read(CassandraIncomingFile.java)
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:53)
	... 5 common frames omitted
2023-05-30 19:58:44,310 - ERROR [Stream-Deserializer-/127.0.0.1:7012-313f83d7:StreamSession@675] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Streaming error occurred on session with peer 127.0.0.1:7012
org.apache.cassandra.streaming.StreamReceiveException: java.io.IOException: Failing incoming file read from test!
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:60)
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:38)
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:53)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.run(StreamingInboundHandler.java:172)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failing incoming file read from test!
	at org.apache.cassandra.distributed.test.RepairErrorsTest$ByteBuddyHelperStreamFailure.read(RepairErrorsTest.java:252)
	at org.apache.cassandra.db.streaming.CassandraIncomingFile.read(CassandraIncomingFile.java)
	at org.apache.cassandra.streaming.messages.IncomingStreamMessage$1.deserialize(IncomingStreamMessage.java:53)
	... 5 common frames omitted
2023-05-30 19:58:44,310 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-313f83d7:NettyStreamingMessageSender@261] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 2910f6c7] Sending Session Failed
2023-05-30 19:58:44,310 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-313f83d7:StreamSession@502] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Will close attached channels {2910f6c7=[id: 0x2910f6c7, L:/127.0.0.3:7012 - R:/127.0.0.1:39202], d35f00b7=[id: 0xd35f00b7, L:/127.0.0.1:50952 - R:/127.0.0.1:7012]}
2023-05-30 19:58:44,311 - INFO  [Stream-Deserializer-/127.0.0.1:7012-313f83d7:StreamResultFuture@193] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Session with /127.0.0.1:7012 is complete
2023-05-30 19:58:44,311 - INFO  [Stream-Deserializer-/127.0.0.2:7012-b142c5d2:StreamResultFuture@193] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Session with /127.0.0.2:7012 is complete
2023-05-30 19:58:44,312 - DEBUG [Streaming-EventLoop-4-1:NettyStreamingMessageSender@560] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Closing stream connection channels on /127.0.0.1:7012
2023-05-30 19:58:44,312 - DEBUG [Streaming-EventLoop-4-2:NettyStreamingMessageSender@560] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Closing stream connection channels on /127.0.0.2:7012
2023-05-30 19:58:44,313 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraIncomingFile@70] - Incoming stream entireSSTable=true components=org.apache.cassandra.db.streaming.ComponentManifest@314094e6
2023-05-30 19:58:44,313 - WARN  [Stream-Deserializer-/127.0.0.2:7012-b142c5d2:StreamResultFuture@220] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Stream failed
2023-05-30 19:58:44,313 - WARN  [Stream-Deserializer-/127.0.0.2:7012-b142c5d2:StreamResultFuture@220] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Stream failed
2023-05-30 19:58:44,313 - WARN  [Stream-Deserializer-/127.0.0.1:7012-313f83d7:StreamResultFuture@220] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Stream failed
2023-05-30 19:58:44,313 - WARN  [Stream-Deserializer-/127.0.0.1:7012-313f83d7:StreamResultFuture@220] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Stream failed
2023-05-30 19:58:44,314 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@100] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving sstable #0 from /127.0.0.1:7012, size = 4.783KiB, table = distributed_test_keyspace.tbl
2023-05-30 19:58:44,316 - WARN  [Streaming-EventLoop-4-2:DefaultChannelPipeline@1152] - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.UnpooledDirectByteBuf.setBytes(UnpooledDirectByteBuf.java:570)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1134)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:44,316 - WARN  [Streaming-EventLoop-4-3:DefaultChannelPipeline@1152] - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.UnpooledDirectByteBuf.setBytes(UnpooledDirectByteBuf.java:570)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1134)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:44,316 - WARN  [Streaming-EventLoop-4-3:DefaultChannelPipeline@1152] - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.UnpooledDirectByteBuf.setBytes(UnpooledDirectByteBuf.java:570)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1134)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:44,316 - WARN  [Streaming-EventLoop-4-2:DefaultChannelPipeline@1152] - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.UnpooledDirectByteBuf.setBytes(UnpooledDirectByteBuf.java:570)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1134)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:44,316 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@181] - [Table #distributed_test_keyspace.tbl] /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Data.db Components to write: [Data.db, Index.db, Statistics.db, CompressionInfo.db, Filter.db, Summary.db, Digest.crc32]
2023-05-30 19:58:44,316 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-790fcdcd:StreamSession@639] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Socket closed after session completed with state FAILED
2023-05-30 19:58:44,316 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-2910f6c7:StreamSession@639] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Socket closed after session completed with state FAILED
2023-05-30 19:58:44,327 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving Data.db component from /127.0.0.1:7012, componentSize = 0.033KiB, readBytes = 0.000KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,327 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@203] - Writing component DATA to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Data.db length 0.033KiB
2023-05-30 19:58:44,327 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Data.db length 0.033KiB
2023-05-30 19:58:44,327 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraIncomingFile@70] - Incoming stream entireSSTable=true components=org.apache.cassandra.db.streaming.ComponentManifest@b5e9f283
2023-05-30 19:58:44,328 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraIncomingFile@70] - Incoming stream entireSSTable=true components=org.apache.cassandra.db.streaming.ComponentManifest@314094e4
2023-05-30 19:58:44,328 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@100] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Started receiving sstable #0 from /127.0.0.3:7012, size = 4.781KiB, table = distributed_test_keyspace.tbl
2023-05-30 19:58:44,328 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@181] - [Table #distributed_test_keyspace.tbl] /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Data.db Components to write: [Data.db, Index.db, Statistics.db, CompressionInfo.db, Filter.db, Summary.db, Digest.crc32]
2023-05-30 19:58:44,328 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@100] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Started receiving sstable #0 from /127.0.0.3:7012, size = 4.781KiB, table = distributed_test_keyspace.tbl
2023-05-30 19:58:44,329 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@181] - [Table #distributed_test_keyspace.tbl] /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Data.db Components to write: [Data.db, Index.db, Statistics.db, CompressionInfo.db, Filter.db, Summary.db, Digest.crc32]
2023-05-30 19:58:44,337 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Data.db component from /127.0.0.1:7012, componentSize = 0.033KiB, readBytes = 0.033KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,337 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving Index.db component from /127.0.0.1:7012, componentSize = 0.008KiB, readBytes = 0.033KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,337 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@203] - Writing component PRIMARY_INDEX to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Index.db length 0.008KiB
2023-05-30 19:58:44,337 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Index.db length 0.008KiB
2023-05-30 19:58:44,346 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Index.db component from /127.0.0.1:7012, componentSize = 0.008KiB, readBytes = 0.041KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,346 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving Statistics.db component from /127.0.0.1:7012, componentSize = 4.616KiB, readBytes = 0.041KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,346 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@203] - Writing component STATS to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Statistics.db length 4.616KiB
2023-05-30 19:58:44,346 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Statistics.db length 4.616KiB
2023-05-30 19:58:44,355 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Statistics.db component from /127.0.0.1:7012, componentSize = 4.616KiB, readBytes = 4.657KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,356 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving CompressionInfo.db component from /127.0.0.1:7012, componentSize = 0.046KiB, readBytes = 4.657KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,356 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@203] - Writing component COMPRESSION_INFO to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-CompressionInfo.db length 0.046KiB
2023-05-30 19:58:44,356 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-CompressionInfo.db length 0.046KiB
2023-05-30 19:58:44,365 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving CompressionInfo.db component from /127.0.0.1:7012, componentSize = 0.046KiB, readBytes = 4.703KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,365 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving Filter.db component from /127.0.0.1:7012, componentSize = 0.016KiB, readBytes = 4.703KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,365 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@203] - Writing component FILTER to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Filter.db length 0.016KiB
2023-05-30 19:58:44,365 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Filter.db length 0.016KiB
2023-05-30 19:58:44,375 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Filter.db component from /127.0.0.1:7012, componentSize = 0.016KiB, readBytes = 4.719KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,375 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving Summary.db component from /127.0.0.1:7012, componentSize = 0.055KiB, readBytes = 4.719KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,375 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@203] - Writing component SUMMARY to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Summary.db length 0.055KiB
2023-05-30 19:58:44,375 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Summary.db length 0.055KiB
2023-05-30 19:58:44,384 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Summary.db component from /127.0.0.1:7012, componentSize = 0.055KiB, readBytes = 4.773KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,384 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving Digest.crc32 component from /127.0.0.1:7012, componentSize = 0.010KiB, readBytes = 4.773KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,384 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@203] - Writing component DIGEST to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Digest.crc32 length 0.010KiB
2023-05-30 19:58:44,384 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Digest.crc32 length 0.010KiB
2023-05-30 19:58:44,393 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Digest.crc32 component from /127.0.0.1:7012, componentSize = 0.010KiB, readBytes = 4.783KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,396 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@117] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Started receiving Data.db component from /127.0.0.3:7012, componentSize = 0.033KiB, readBytes = 0.000KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,396 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@203] - Writing component DATA to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Data.db length 0.033KiB
2023-05-30 19:58:44,396 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Started receiving Data.db component from /127.0.0.3:7012, componentSize = 0.033KiB, readBytes = 0.000KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,396 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: 7b13a7bc] Received IncomingStreamMessage{header=Header (tableId: e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0, repairedAt: 0, pendingRepair: e7885010-ff45-11ed-bc52-8b144d1e6fed, sendByFollower: false), stream=CassandraIncomingFile{sstable=/tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Data.db}}
2023-05-30 19:58:44,396 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Data.db length 0.033KiB
2023-05-30 19:58:44,397 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@203] - Writing component DATA to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Data.db length 0.033KiB
2023-05-30 19:58:44,397 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:NettyStreamingMessageSender@261] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: 7ee83ec9] Sending Received (e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0)
2023-05-30 19:58:44,397 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Data.db length 0.033KiB
2023-05-30 19:58:44,397 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:StreamReceiveTask@88] - received 7 of 7 total files, 4898 of total bytes 4898
2023-05-30 19:58:44,399 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:SSTableReaderBuilder$ForRead@351] - Opening /tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big (0.033KiB)
2023-05-30 19:58:44,403 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@129] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished receiving Data.db component from /127.0.0.3:7012, componentSize = 0.033KiB, readBytes = 0.033KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,403 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Data.db component from /127.0.0.3:7012, componentSize = 0.033KiB, readBytes = 0.033KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,403 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@117] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Started receiving Index.db component from /127.0.0.3:7012, componentSize = 0.008KiB, readBytes = 0.033KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,403 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Started receiving Index.db component from /127.0.0.3:7012, componentSize = 0.008KiB, readBytes = 0.033KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,404 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@203] - Writing component PRIMARY_INDEX to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Index.db length 0.008KiB
2023-05-30 19:58:44,404 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@203] - Writing component PRIMARY_INDEX to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Index.db length 0.008KiB
2023-05-30 19:58:44,404 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Index.db length 0.008KiB
2023-05-30 19:58:44,404 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Index.db length 0.008KiB
2023-05-30 19:58:44,412 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@129] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished receiving Index.db component from /127.0.0.3:7012, componentSize = 0.008KiB, readBytes = 0.041KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,412 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Index.db component from /127.0.0.3:7012, componentSize = 0.008KiB, readBytes = 0.041KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,412 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@117] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Started receiving Statistics.db component from /127.0.0.3:7012, componentSize = 4.616KiB, readBytes = 0.041KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,412 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Started receiving Statistics.db component from /127.0.0.3:7012, componentSize = 4.616KiB, readBytes = 0.041KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,412 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@203] - Writing component STATS to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Statistics.db length 4.616KiB
2023-05-30 19:58:44,412 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@203] - Writing component STATS to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Statistics.db length 4.616KiB
2023-05-30 19:58:44,412 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Statistics.db length 4.616KiB
2023-05-30 19:58:44,412 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Statistics.db length 4.616KiB
2023-05-30 19:58:44,421 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Statistics.db component from /127.0.0.3:7012, componentSize = 4.616KiB, readBytes = 4.657KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,421 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@129] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished receiving Statistics.db component from /127.0.0.3:7012, componentSize = 4.616KiB, readBytes = 4.657KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,421 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Started receiving CompressionInfo.db component from /127.0.0.3:7012, componentSize = 0.046KiB, readBytes = 4.657KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,421 - DEBUG [node2_StreamReceiveTask:1:CassandraStreamReceiver@237] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Received 1 sstables from /127.0.0.1:7012 ([BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Data.db')])
2023-05-30 19:58:44,421 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@117] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Started receiving CompressionInfo.db component from /127.0.0.3:7012, componentSize = 0.046KiB, readBytes = 4.657KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,421 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@203] - Writing component COMPRESSION_INFO to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-CompressionInfo.db length 0.046KiB
2023-05-30 19:58:44,421 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@203] - Writing component COMPRESSION_INFO to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-CompressionInfo.db length 0.046KiB
2023-05-30 19:58:44,421 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-CompressionInfo.db length 0.046KiB
2023-05-30 19:58:44,421 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-CompressionInfo.db length 0.046KiB
2023-05-30 19:58:44,422 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished receiving CompressionInfo.db component from /127.0.0.3:7012, componentSize = 0.046KiB, readBytes = 4.703KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,422 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@129] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished receiving CompressionInfo.db component from /127.0.0.3:7012, componentSize = 0.046KiB, readBytes = 4.703KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,422 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Started receiving Filter.db component from /127.0.0.3:7012, componentSize = 0.016KiB, readBytes = 4.703KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,422 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@117] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Started receiving Filter.db component from /127.0.0.3:7012, componentSize = 0.016KiB, readBytes = 4.703KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,422 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@203] - Writing component FILTER to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Filter.db length 0.016KiB
2023-05-30 19:58:44,422 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@203] - Writing component FILTER to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Filter.db length 0.016KiB
2023-05-30 19:58:44,422 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Filter.db length 0.016KiB
2023-05-30 19:58:44,422 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Filter.db length 0.016KiB
2023-05-30 19:58:44,430 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@129] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished receiving Filter.db component from /127.0.0.3:7012, componentSize = 0.016KiB, readBytes = 4.719KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,430 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Filter.db component from /127.0.0.3:7012, componentSize = 0.016KiB, readBytes = 4.719KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,430 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@117] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Started receiving Summary.db component from /127.0.0.3:7012, componentSize = 0.055KiB, readBytes = 4.719KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,430 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Started receiving Summary.db component from /127.0.0.3:7012, componentSize = 0.055KiB, readBytes = 4.719KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,430 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@203] - Writing component SUMMARY to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Summary.db length 0.055KiB
2023-05-30 19:58:44,430 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@203] - Writing component SUMMARY to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Summary.db length 0.055KiB
2023-05-30 19:58:44,430 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Summary.db length 0.055KiB
2023-05-30 19:58:44,430 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Summary.db length 0.055KiB
2023-05-30 19:58:44,438 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Summary.db component from /127.0.0.3:7012, componentSize = 0.055KiB, readBytes = 4.773KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,439 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@129] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished receiving Summary.db component from /127.0.0.3:7012, componentSize = 0.055KiB, readBytes = 4.773KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,439 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Started receiving Digest.crc32 component from /127.0.0.3:7012, componentSize = 0.008KiB, readBytes = 4.773KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,439 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@203] - Writing component DIGEST to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Digest.crc32 length 0.008KiB
2023-05-30 19:58:44,439 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@117] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Started receiving Digest.crc32 component from /127.0.0.3:7012, componentSize = 0.008KiB, readBytes = 4.773KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,439 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@203] - Writing component DIGEST to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Digest.crc32 length 0.008KiB
2023-05-30 19:58:44,439 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Digest.crc32 length 0.008KiB
2023-05-30 19:58:44,439 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Digest.crc32 length 0.008KiB
2023-05-30 19:58:44,447 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:CassandraEntireSSTableStreamReader@129] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Finished receiving Digest.crc32 component from /127.0.0.3:7012, componentSize = 0.008KiB, readBytes = 4.781KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,447 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Digest.crc32 component from /127.0.0.3:7012, componentSize = 0.008KiB, readBytes = 4.781KiB, totalSize = 4.781KiB
2023-05-30 19:58:44,448 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 1486e1d3] Received IncomingStreamMessage{header=Header (tableId: e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0, repairedAt: 0, pendingRepair: e7885010-ff45-11ed-bc52-8b144d1e6fed, sendByFollower: true), stream=CassandraIncomingFile{sstable=/tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Data.db}}
2023-05-30 19:58:44,448 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:NettyStreamingMessageSender@261] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 72d81333] Sending Received (e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0)
2023-05-30 19:58:44,449 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: ca05ba6b] Received IncomingStreamMessage{header=Header (tableId: e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0, repairedAt: 0, pendingRepair: e7885010-ff45-11ed-bc52-8b144d1e6fed, sendByFollower: true), stream=CassandraIncomingFile{sstable=/tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Data.db}}
2023-05-30 19:58:44,449 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:StreamReceiveTask@88] - received 7 of 7 total files, 4896 of total bytes 4896
2023-05-30 19:58:44,449 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:NettyStreamingMessageSender@261] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 03197f6e] Sending Received (e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0)
2023-05-30 19:58:44,449 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:StreamReceiveTask@88] - received 7 of 7 total files, 4896 of total bytes 4896
2023-05-30 19:58:44,449 - INFO  [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:SSTableReaderBuilder$ForRead@351] - Opening /tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big (0.033KiB)
2023-05-30 19:58:44,451 - INFO  [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:SSTableReaderBuilder$ForRead@351] - Opening /tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big (0.033KiB)
2023-05-30 19:58:44,456 - DEBUG [node2_StreamReceiveTask:1:CassandraStreamReceiver@237] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Received 1 sstables from /127.0.0.3:7012 ([BigTableReader(path='/tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Data.db')])
2023-05-30 19:58:44,456 - DEBUG [node1_StreamReceiveTask:1:CassandraStreamReceiver@237] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Received 1 sstables from /127.0.0.3:7012 ([BigTableReader(path='/tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Data.db')])
2023-05-30 19:58:44,456 - DEBUG [node2_StreamReceiveTask:1:PendingRepairManager@118] - Creating distributed_test_keyspace.tbl compaction strategy for pending repair: e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:44,456 - DEBUG [node1_StreamReceiveTask:1:PendingRepairManager@118] - Creating distributed_test_keyspace.tbl compaction strategy for pending repair: e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:44,700 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-72d81333:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80 channel: 72d81333] Received Session Failed
2023-05-30 19:58:44,700 - ERROR [Stream-Deserializer-/127.0.0.3:7012-72d81333:StreamSession@883] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Remote peer /127.0.0.3:7012 failed stream session.
2023-05-30 19:58:44,700 - ERROR [Stream-Deserializer-/127.0.0.3:7012-72d81333:StreamSession@883] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Remote peer /127.0.0.3:7012 failed stream session.
2023-05-30 19:58:44,700 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-72d81333:StreamSession@502] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Will close attached channels {72d81333=[id: 0x72d81333, L:/127.0.0.1:39198 - R:/127.0.0.3:7012]}
2023-05-30 19:58:44,701 - INFO  [Stream-Deserializer-/127.0.0.3:7012-72d81333:StreamResultFuture@193] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Session with /127.0.0.3:7012 is complete
2023-05-30 19:58:44,702 - DEBUG [Streaming-EventLoop-4-1:NettyStreamingMessageSender@560] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Closing stream connection channels on /127.0.0.3:7012
2023-05-30 19:58:44,703 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraIncomingFile@70] - Incoming stream entireSSTable=true components=org.apache.cassandra.db.streaming.ComponentManifest@b5e9f285
2023-05-30 19:58:44,703 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@100] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving sstable #0 from /127.0.0.2:7012, size = 4.783KiB, table = distributed_test_keyspace.tbl
2023-05-30 19:58:44,703 - WARN  [Stream-Deserializer-/127.0.0.3:7012-72d81333:StreamResultFuture@220] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Stream failed
2023-05-30 19:58:44,703 - WARN  [Stream-Deserializer-/127.0.0.3:7012-72d81333:StreamResultFuture@220] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Stream failed
2023-05-30 19:58:44,704 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@181] - [Table #distributed_test_keyspace.tbl] /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Data.db Components to write: [Data.db, Index.db, Statistics.db, CompressionInfo.db, Filter.db, Summary.db, Digest.crc32]
2023-05-30 19:58:44,705 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-03197f6e:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed channel: 03197f6e] Received Session Failed
2023-05-30 19:58:44,705 - ERROR [Stream-Deserializer-/127.0.0.3:7012-03197f6e:StreamSession@883] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Remote peer /127.0.0.3:7012 failed stream session.
2023-05-30 19:58:44,705 - ERROR [Stream-Deserializer-/127.0.0.3:7012-03197f6e:StreamSession@883] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Remote peer /127.0.0.3:7012 failed stream session.
2023-05-30 19:58:44,706 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-03197f6e:StreamSession@502] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Will close attached channels {03197f6e=[id: 0x03197f6e, L:/127.0.0.1:39202 - R:/127.0.0.3:7012]}
2023-05-30 19:58:44,706 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-eb9c209e:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: eb9c209e] Received Received (e68c8af0-ff45-11ed-bc52-8b144d1e6fed, #0)
2023-05-30 19:58:44,706 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-eb9c209e:StreamTransferTask@95] - recevied sequenceNumber 0, remaining files []
2023-05-30 19:58:44,707 - INFO  [Stream-Deserializer-/127.0.0.3:7012-03197f6e:StreamResultFuture@193] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Session with /127.0.0.3:7012 is complete
2023-05-30 19:58:44,708 - DEBUG [Streaming-EventLoop-4-1:NettyStreamingMessageSender@560] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Closing stream connection channels on /127.0.0.3:7012
2023-05-30 19:58:44,708 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-72d81333:StreamSession@639] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Socket closed after session completed with state FAILED
2023-05-30 19:58:44,709 - WARN  [Stream-Deserializer-/127.0.0.3:7012-03197f6e:StreamResultFuture@220] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Stream failed
2023-05-30 19:58:44,709 - WARN  [Stream-Deserializer-/127.0.0.3:7012-03197f6e:StreamResultFuture@220] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Stream failed
2023-05-30 19:58:44,709 - DEBUG [node1_AntiEntropyStage:1:RepairSession@224] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Repair completed between /127.0.0.2:7012 and /127.0.0.3:7012 on tbl
2023-05-30 19:58:44,711 - INFO  [node1_RepairJobTask:1:StreamSession@1048] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Aborting stream session with peer /127.0.0.2:7012...
2023-05-30 19:58:44,712 - DEBUG [node1_RepairJobTask:1:NettyStreamingMessageSender@261] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: eb9c209e] Sending Session Failed
2023-05-30 19:58:44,712 - DEBUG [node1_RepairJobTask:1:StreamSession@502] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Will close attached channels {7be9c090=[id: 0x7be9c090, L:/127.0.0.1:50580 - R:/127.0.0.2:7012], eb9c209e=[id: 0xeb9c209e, L:/127.0.0.1:50574 - R:/127.0.0.2:7012]}
2023-05-30 19:58:44,714 - INFO  [node1_RepairJobTask:1:StreamResultFuture@193] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Session with /127.0.0.2:7012 is complete
2023-05-30 19:58:44,716 - DEBUG [Streaming-EventLoop-4-4:NettyStreamingMessageSender@560] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Closing stream connection channels on /127.0.0.2:7012
2023-05-30 19:58:44,716 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving Data.db component from /127.0.0.2:7012, componentSize = 0.033KiB, readBytes = 0.000KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,716 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@203] - Writing component DATA to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Data.db length 0.033KiB
2023-05-30 19:58:44,716 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Data.db length 0.033KiB
2023-05-30 19:58:44,716 - INFO  [node1_RepairJobTask:1:StreamResultFuture@225] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Stream aborted
2023-05-30 19:58:44,717 - INFO  [node1_RepairJobTask:1:LocalSyncTask@166] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Sync aborted using session e79aedb0-ff45-11ed-bc52-8b144d1e6fed between /127.0.0.1:7012 and /127.0.0.2:7012 on tbl
May 30, 2023 7:58:44 PM com.google.common.util.concurrent.AggregateFuture$RunningState handleException
SEVERE: Got more than one input Future failure. Logging failures after the first
org.apache.cassandra.streaming.StreamException: Stream failed
	at org.apache.cassandra.streaming.management.StreamEventJMXNotifier.onFailure(StreamEventJMXNotifier.java:88)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1056)
	at com.google.common.util.concurrent.DirectExecutor.execute(DirectExecutor.java:30)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1138)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:958)
	at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:748)
	at org.apache.cassandra.streaming.StreamResultFuture.maybeComplete(StreamResultFuture.java:221)
	at org.apache.cassandra.streaming.StreamResultFuture.handleSessionComplete(StreamResultFuture.java:197)
	at org.apache.cassandra.streaming.StreamSession.closeSession(StreamSession.java:507)
	at org.apache.cassandra.streaming.StreamSession.sessionFailed(StreamSession.java:884)
	at org.apache.cassandra.streaming.StreamSession.messageReceived(StreamSession.java:603)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.run(StreamingInboundHandler.java:189)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

2023-05-30 19:58:44,718 - DEBUG [node1_RepairJobTask:1:StreamSession@1044] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Stream session with peer /127.0.0.3:7012 is already in a final state on abort.
2023-05-30 19:58:44,718 - WARN  [node1_RepairJobTask:1:RepairJob$2@177] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] distributed_test_keyspace.tbl sync failed
2023-05-30 19:58:44,718 - WARN  [node1_RepairJobTask:1:RepairJob$2@177] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] distributed_test_keyspace.tbl sync failed
2023-05-30 19:58:44,718 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-03197f6e:StreamSession@639] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Socket closed after session completed with state FAILED
2023-05-30 19:58:44,723 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Data.db component from /127.0.0.2:7012, componentSize = 0.033KiB, readBytes = 0.033KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,723 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving Index.db component from /127.0.0.2:7012, componentSize = 0.008KiB, readBytes = 0.033KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,723 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@203] - Writing component PRIMARY_INDEX to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Index.db length 0.008KiB
2023-05-30 19:58:44,723 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Index.db length 0.008KiB
2023-05-30 19:58:44,723 - ERROR [node1_Repair#1:1:RepairSession$1@321] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Session completed with the following error
org.apache.cassandra.exceptions.RepairException: [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed on distributed_test_keyspace/tbl, [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]]] Sync failed between /127.0.0.2:7012 and /127.0.0.3:7012
	at org.apache.cassandra.repair.SymmetricRemoteSyncTask.syncComplete(SymmetricRemoteSyncTask.java:82)
	at org.apache.cassandra.repair.RepairSession.syncComplete(RepairSession.java:225)
	at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:744)
	at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:202)
	at org.apache.cassandra.net.InboundSink.lambda$new$0(InboundSink.java:78)
	at org.apache.cassandra.net.InboundSink$Filtered.accept(InboundSink.java:64)
	at org.apache.cassandra.net.InboundSink$Filtered.accept(InboundSink.java:50)
	at org.apache.cassandra.net.InboundSink.accept(InboundSink.java:97)
	at org.apache.cassandra.net.InboundSink.accept(InboundSink.java:45)
	at org.apache.cassandra.net.InboundMessageHandler$ProcessMessage.run(InboundMessageHandler.java:432)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:44,723 - ERROR [node1_Repair#1:1:RepairSession$1@321] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] Session completed with the following error
org.apache.cassandra.exceptions.RepairException: [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed on distributed_test_keyspace/tbl, [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]]] Sync failed between /127.0.0.2:7012 and /127.0.0.3:7012
	at org.apache.cassandra.repair.SymmetricRemoteSyncTask.syncComplete(SymmetricRemoteSyncTask.java:82)
	at org.apache.cassandra.repair.RepairSession.syncComplete(RepairSession.java:225)
	at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:744)
	at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:202)
	at org.apache.cassandra.net.InboundSink.lambda$new$0(InboundSink.java:78)
	at org.apache.cassandra.net.InboundSink$Filtered.accept(InboundSink.java:64)
	at org.apache.cassandra.net.InboundSink$Filtered.accept(InboundSink.java:50)
	at org.apache.cassandra.net.InboundSink.accept(InboundSink.java:97)
	at org.apache.cassandra.net.InboundSink.accept(InboundSink.java:45)
	at org.apache.cassandra.net.InboundMessageHandler$ProcessMessage.run(InboundMessageHandler.java:432)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:44,724 - ERROR [node1_Repair#1:1:RepairRunnable@178] - Repair e7885010-ff45-11ed-bc52-8b144d1e6fed failed:
java.lang.RuntimeException: Repair session e79aedb0-ff45-11ed-bc52-8b144d1e6fed for range [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]] failed with error [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed on distributed_test_keyspace/tbl, [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]]] Sync failed between /127.0.0.2:7012 and /127.0.0.3:7012
	at org.apache.cassandra.repair.RepairRunnable$RepairSessionCallback.onFailure(RepairRunnable.java:698)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1056)
	at com.google.common.util.concurrent.DirectExecutor.execute(DirectExecutor.java:30)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1138)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:958)
	at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:748)
	at org.apache.cassandra.repair.RepairSession.forceShutdown(RepairSession.java:342)
	at org.apache.cassandra.repair.RepairSession$1.onFailure(RepairSession.java:323)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1056)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.cassandra.exceptions.RepairException: [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed on distributed_test_keyspace/tbl, [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]]] Sync failed between /127.0.0.2:7012 and /127.0.0.3:7012
	at org.apache.cassandra.repair.SymmetricRemoteSyncTask.syncComplete(SymmetricRemoteSyncTask.java:82)
	at org.apache.cassandra.repair.RepairSession.syncComplete(RepairSession.java:225)
	at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:744)
	at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:202)
	at org.apache.cassandra.net.InboundSink.lambda$new$0(InboundSink.java:78)
	at org.apache.cassandra.net.InboundSink$Filtered.accept(InboundSink.java:64)
	at org.apache.cassandra.net.InboundSink$Filtered.accept(InboundSink.java:50)
	at org.apache.cassandra.net.InboundSink.accept(InboundSink.java:97)
	at org.apache.cassandra.net.InboundSink.accept(InboundSink.java:45)
	at org.apache.cassandra.net.InboundMessageHandler$ProcessMessage.run(InboundMessageHandler.java:432)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 4 common frames omitted
2023-05-30 19:58:44,724 - ERROR [node1_Repair#1:1:RepairRunnable@178] - Repair e7885010-ff45-11ed-bc52-8b144d1e6fed failed:
java.lang.RuntimeException: Repair session e79aedb0-ff45-11ed-bc52-8b144d1e6fed for range [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]] failed with error [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed on distributed_test_keyspace/tbl, [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]]] Sync failed between /127.0.0.2:7012 and /127.0.0.3:7012
	at org.apache.cassandra.repair.RepairRunnable$RepairSessionCallback.onFailure(RepairRunnable.java:698)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1056)
	at com.google.common.util.concurrent.DirectExecutor.execute(DirectExecutor.java:30)
	at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1138)
	at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:958)
	at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:748)
	at org.apache.cassandra.repair.RepairSession.forceShutdown(RepairSession.java:342)
	at org.apache.cassandra.repair.RepairSession$1.onFailure(RepairSession.java:323)
	at com.google.common.util.concurrent.Futures$CallbackListener.run(Futures.java:1056)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.cassandra.exceptions.RepairException: [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed on distributed_test_keyspace/tbl, [(-3074457345618258603,3074457345618258601], (9223372036854775805,-3074457345618258603], (3074457345618258601,9223372036854775805]]] Sync failed between /127.0.0.2:7012 and /127.0.0.3:7012
	at org.apache.cassandra.repair.SymmetricRemoteSyncTask.syncComplete(SymmetricRemoteSyncTask.java:82)
	at org.apache.cassandra.repair.RepairSession.syncComplete(RepairSession.java:225)
	at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:744)
	at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:202)
	at org.apache.cassandra.net.InboundSink.lambda$new$0(InboundSink.java:78)
	at org.apache.cassandra.net.InboundSink$Filtered.accept(InboundSink.java:64)
	at org.apache.cassandra.net.InboundSink$Filtered.accept(InboundSink.java:50)
	at org.apache.cassandra.net.InboundSink.accept(InboundSink.java:97)
	at org.apache.cassandra.net.InboundSink.accept(InboundSink.java:45)
	at org.apache.cassandra.net.InboundMessageHandler$ProcessMessage.run(InboundMessageHandler.java:432)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 4 common frames omitted
2023-05-30 19:58:44,732 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Index.db component from /127.0.0.2:7012, componentSize = 0.008KiB, readBytes = 0.041KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,732 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving Statistics.db component from /127.0.0.2:7012, componentSize = 4.616KiB, readBytes = 0.041KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,732 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@203] - Writing component STATS to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Statistics.db length 4.616KiB
2023-05-30 19:58:44,732 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Statistics.db length 4.616KiB
2023-05-30 19:58:44,733 - DEBUG [node1_Repair#1:1:CoordinatorSession$2@328] - Incremental repair e7885010-ff45-11ed-bc52-8b144d1e6fed validation/stream phase completed in 2 seconds
2023-05-30 19:58:44,734 - DEBUG [node1_Repair#1:1:CoordinatorSession$3@381] - Incremental repair e7885010-ff45-11ed-bc52-8b144d1e6fed phase failed in 2 seconds
2023-05-30 19:58:44,734 - INFO  [node1_Repair#1:1:CoordinatorSession@266] - Incremental repair session e7885010-ff45-11ed-bc52-8b144d1e6fed failed
2023-05-30 19:58:44,736 - INFO  [node1_AntiEntropyStage:1:CoordinatorSession@266] - Incremental repair session e7885010-ff45-11ed-bc52-8b144d1e6fed failed
2023-05-30 19:58:44,736 - INFO  [node1_AntiEntropyStage:1:LocalSessions@732] - Failing local repair session e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:44,736 - INFO  [node3_AntiEntropyStage:1:LocalSessions@732] - Failing local repair session e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:44,736 - INFO  [node2_AntiEntropyStage:1:LocalSessions@732] - Failing local repair session e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:44,738 - INFO  [node1_Repair#1:1:RepairRunnable@216] - [repair #e7885010-ff45-11ed-bc52-8b144d1e6fed]Repair command #1 finished with error
2023-05-30 19:58:44,739 - DEBUG [node1_Repair#1:1:RepairSession@353] - [repair #e79aedb0-ff45-11ed-bc52-8b144d1e6fed] session task executor shut down gracefully
2023-05-30 19:58:44,741 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Statistics.db component from /127.0.0.2:7012, componentSize = 4.616KiB, readBytes = 4.657KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,741 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving CompressionInfo.db component from /127.0.0.2:7012, componentSize = 0.046KiB, readBytes = 4.657KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,741 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@203] - Writing component COMPRESSION_INFO to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-CompressionInfo.db length 0.046KiB
2023-05-30 19:58:44,741 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-CompressionInfo.db length 0.046KiB
2023-05-30 19:58:44,742 - INFO  [node1_CompactionExecutor:1:PendingRepairManager$RepairFinishedCompactionTask@520] - Moving [BigTableReader(path='/tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db')] from pending to repaired with repaired at = 0 and session id = e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:44,742 - INFO  [node3_CompactionExecutor:1:PendingRepairManager$RepairFinishedCompactionTask@520] - Moving [BigTableReader(path='/tmp/dtests293447409190997823/node3/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-3-big-Data.db')] from pending to repaired with repaired at = 0 and session id = e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:44,742 - INFO  [node2_CompactionExecutor:1:PendingRepairManager$RepairFinishedCompactionTask@520] - Moving [BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-1-big-Data.db'), BigTableReader(path='/tmp/dtests293447409190997823/node2/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Data.db')] from pending to repaired with repaired at = 0 and session id = e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:44,744 - DEBUG [node1_CompactionExecutor:1:PendingRepairManager@145] - Removing compaction strategy for pending repair e7885010-ff45-11ed-bc52-8b144d1e6fed on  distributed_test_keyspace.tbl
2023-05-30 19:58:44,744 - DEBUG [node3_CompactionExecutor:1:PendingRepairManager@145] - Removing compaction strategy for pending repair e7885010-ff45-11ed-bc52-8b144d1e6fed on  distributed_test_keyspace.tbl
2023-05-30 19:58:44,745 - DEBUG [node2_CompactionExecutor:1:PendingRepairManager@145] - Removing compaction strategy for pending repair e7885010-ff45-11ed-bc52-8b144d1e6fed on  distributed_test_keyspace.tbl
2023-05-30 19:58:44,749 - INFO  [node1_CompactionExecutor:1:PendingRepairManager$RepairFinishedCompactionTask@520] - Moving [BigTableReader(path='/tmp/dtests293447409190997823/node1/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-4-big-Data.db')] from pending to repaired with repaired at = 0 and session id = e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:44,749 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving CompressionInfo.db component from /127.0.0.2:7012, componentSize = 0.046KiB, readBytes = 4.703KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,749 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving Filter.db component from /127.0.0.2:7012, componentSize = 0.016KiB, readBytes = 4.703KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,749 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@203] - Writing component FILTER to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Filter.db length 0.016KiB
2023-05-30 19:58:44,749 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Filter.db length 0.016KiB
2023-05-30 19:58:44,750 - DEBUG [node1_CompactionExecutor:1:PendingRepairManager@145] - Removing compaction strategy for pending repair e7885010-ff45-11ed-bc52-8b144d1e6fed on  distributed_test_keyspace.tbl
2023-05-30 19:58:44,751 - INFO  [node1_CompactionExecutor:1:CompactionTask@150] - Compacting (e921b4c0-ff45-11ed-bc52-8b144d1e6fed) [/tmp/dtests293447409190997823/node1/data0/system/peers_v2-c4325fbb8e5e3bafbd070f9250ed818e/nb-1-big-Data.db:level=0, ]
2023-05-30 19:58:44,751 - INFO  [node2_CompactionExecutor:1:PendingRepairManager$RepairFinishedCompactionTask@520] - Moving [BigTableReader(path='/tmp/dtests293447409190997823/node2/data2/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Data.db')] from pending to repaired with repaired at = 0 and session id = e7885010-ff45-11ed-bc52-8b144d1e6fed
2023-05-30 19:58:44,751 - DEBUG [node2_CompactionExecutor:1:PendingRepairManager@145] - Removing compaction strategy for pending repair e7885010-ff45-11ed-bc52-8b144d1e6fed on  distributed_test_keyspace.tbl
2023-05-30 19:58:44,761 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Filter.db component from /127.0.0.2:7012, componentSize = 0.016KiB, readBytes = 4.719KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,761 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving Summary.db component from /127.0.0.2:7012, componentSize = 0.055KiB, readBytes = 4.719KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,761 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@203] - Writing component SUMMARY to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Summary.db length 0.055KiB
2023-05-30 19:58:44,761 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Summary.db length 0.055KiB
2023-05-30 19:58:44,770 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Summary.db component from /127.0.0.2:7012, componentSize = 0.055KiB, readBytes = 4.773KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,770 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@117] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Started receiving Digest.crc32 component from /127.0.0.2:7012, componentSize = 0.010KiB, readBytes = 4.773KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,770 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@203] - Writing component DIGEST to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Digest.crc32 length 0.010KiB
2023-05-30 19:58:44,770 - INFO  [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:BigTableZeroCopyWriter@213] - Block Writing component to /tmp/dtests293447409190997823/node1/data0/distributed_test_keyspace/tbl-e68c8af0ff4511edbc528b144d1e6fed/nb-5-big-Digest.crc32 length 0.010KiB
2023-05-30 19:58:44,771 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:CassandraEntireSSTableStreamReader@129] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Finished receiving Digest.crc32 component from /127.0.0.2:7012, componentSize = 0.010KiB, readBytes = 4.783KiB, totalSize = 4.783KiB
2023-05-30 19:58:44,771 - ERROR [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:StreamingInboundHandler$StreamDeserializingTask@205] - [Stream channel: 9c970f1a] stream operation from /127.0.0.2:7012 failed
java.lang.RuntimeException: Stream e7a43c80-ff45-11ed-bc52-8b144d1e6fed is finished with state ABORTED
	at org.apache.cassandra.streaming.StreamSession.failIfFinished(StreamSession.java:426)
	at org.apache.cassandra.streaming.StreamSession.attachInbound(StreamSession.java:313)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.deriveSession(StreamingInboundHandler.java:232)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.run(StreamingInboundHandler.java:184)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:44,771 - ERROR [Stream-Deserializer-/127.0.0.2:7012-9c970f1a:StreamingInboundHandler$StreamDeserializingTask@205] - [Stream channel: 9c970f1a] stream operation from /127.0.0.2:7012 failed
java.lang.RuntimeException: Stream e7a43c80-ff45-11ed-bc52-8b144d1e6fed is finished with state ABORTED
	at org.apache.cassandra.streaming.StreamSession.failIfFinished(StreamSession.java:426)
	at org.apache.cassandra.streaming.StreamSession.attachInbound(StreamSession.java:313)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.deriveSession(StreamingInboundHandler.java:232)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.run(StreamingInboundHandler.java:184)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:44,803 - ERROR [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:StreamSession@645] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Socket closed before session completion, peer 127.0.0.1:7012 is probably down.
java.io.EOFException: null
	at org.apache.cassandra.net.AsyncStreamingInputPlus.reBuffer(AsyncStreamingInputPlus.java:133)
	at org.apache.cassandra.io.util.RebufferingInputStream.readByte(RebufferingInputStream.java:178)
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:52)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.run(StreamingInboundHandler.java:172)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:44,803 - ERROR [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:StreamSession@645] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Socket closed before session completion, peer 127.0.0.1:7012 is probably down.
java.io.EOFException: null
	at org.apache.cassandra.net.AsyncStreamingInputPlus.reBuffer(AsyncStreamingInputPlus.java:133)
	at org.apache.cassandra.io.util.RebufferingInputStream.readByte(RebufferingInputStream.java:178)
	at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:52)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.run(StreamingInboundHandler.java:172)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:44,803 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:StreamSession@502] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Will close attached channels {7ee83ec9=[id: 0x7ee83ec9, L:/127.0.0.2:7012 - R:/127.0.0.1:50574]}
2023-05-30 19:58:44,803 - INFO  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:StreamResultFuture@193] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Session with /127.0.0.1:7012 is complete
2023-05-30 19:58:44,803 - WARN  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:StreamResultFuture@220] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Stream failed
2023-05-30 19:58:44,803 - WARN  [Stream-Deserializer-/127.0.0.1:7012-7b13a7bc:StreamResultFuture@220] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Stream failed
2023-05-30 19:58:44,803 - DEBUG [node2_Messaging-EventLoop-3-10:NettyStreamingMessageSender@560] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Closing stream connection channels on /127.0.0.1:7012
2023-05-30 19:58:44,851 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-1486e1d3:StreamSession@639] - [Stream #e7a4ffd0-ff45-11ed-8fcf-679a97013a80] Socket closed after session completed with state FAILED
2023-05-30 19:58:44,853 - DEBUG [Stream-Deserializer-/127.0.0.3:7012-ca05ba6b:StreamSession@639] - [Stream #e7a43c81-ff45-11ed-bc52-8b144d1e6fed] Socket closed after session completed with state FAILED
2023-05-30 19:58:44,862 - INFO  [node1_NonPeriodicTasks:1:SSTable@111] - Deleting sstable: /tmp/dtests293447409190997823/node1/data0/system/peers_v2-c4325fbb8e5e3bafbd070f9250ed818e/nb-1-big
2023-05-30 19:58:44,862 - INFO  [node1_CompactionExecutor:1:CompactionTask@241] - Compacted (e921b4c0-ff45-11ed-bc52-8b144d1e6fed) 1 sstables to [/tmp/dtests293447409190997823/node1/data0/system/peers_v2-c4325fbb8e5e3bafbd070f9250ed818e/nb-2-big,] to level=0.  0.250KiB to 0.240KiB (~96% of original) in 103ms.  Read Throughput = 2.424KiB/s, Write Throughput = 2.329KiB/s, Row Throughput = ~4/s.  2 total partitions merged to 2.  Partition merge counts were {1:2, }
2023-05-30 19:58:44,956 - DEBUG [node3_BatchlogTasks:1:BatchlogManager@244] - Updating batchlog replay throttle to 1024 KB/s, 341 KB/s per endpoint
2023-05-30 19:58:44,956 - DEBUG [node2_BatchlogTasks:1:BatchlogManager@244] - Updating batchlog replay throttle to 1024 KB/s, 341 KB/s per endpoint
2023-05-30 19:58:45,100 - DEBUG [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:StreamingInboundHandler$StreamDeserializingTask@187] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed channel: 7ee83ec9] Received Session Failed
2023-05-30 19:58:45,100 - ERROR [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:StreamSession@675] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming error occurred on session with peer 127.0.0.1:7012
java.lang.RuntimeException: Stream e7a43c80-ff45-11ed-bc52-8b144d1e6fed is finished with state FAILED
	at org.apache.cassandra.streaming.StreamSession.failIfFinished(StreamSession.java:426)
	at org.apache.cassandra.streaming.StreamSession.messageReceived(StreamSession.java:566)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.run(StreamingInboundHandler.java:189)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:45,100 - ERROR [Stream-Deserializer-/127.0.0.1:7012-7ee83ec9:StreamSession@675] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Streaming error occurred on session with peer 127.0.0.1:7012
java.lang.RuntimeException: Stream e7a43c80-ff45-11ed-bc52-8b144d1e6fed is finished with state FAILED
	at org.apache.cassandra.streaming.StreamSession.failIfFinished(StreamSession.java:426)
	at org.apache.cassandra.streaming.StreamSession.messageReceived(StreamSession.java:566)
	at org.apache.cassandra.streaming.async.StreamingInboundHandler$StreamDeserializingTask.run(StreamingInboundHandler.java:189)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
2023-05-30 19:58:45,106 - DEBUG [Stream-Deserializer-/127.0.0.2:7012-eb9c209e:StreamSession@639] - [Stream #e7a43c80-ff45-11ed-bc52-8b144d1e6fed] Socket closed after session completed with state ABORTED
2023-05-30 19:58:45,199 - INFO  [node1_isolatedExecutor:3:Gossiper@2023] - Announcing shutdown
2023-05-30 19:58:45,199 - INFO  [node2_isolatedExecutor:3:Gossiper@2023] - Announcing shutdown
2023-05-30 19:58:45,199 - DEBUG [node1_isolatedExecutor:3:StorageService@2782] - Node /127.0.0.1:7012 state shutdown, token [-3074457345618258603]
2023-05-30 19:58:45,199 - DEBUG [node2_isolatedExecutor:3:StorageService@2782] - Node /127.0.0.2:7012 state shutdown, token [3074457345618258601]
2023-05-30 19:58:45,200 - INFO  [node1_isolatedExecutor:6:HintsService@222] - Paused hints dispatch
2023-05-30 19:58:45,200 - INFO  [node1_isolatedExecutor:3:StorageService@2785] - Node /127.0.0.1:7012 state jump to shutdown
2023-05-30 19:58:45,201 - INFO  [node2_isolatedExecutor:6:HintsService@222] - Paused hints dispatch
2023-05-30 19:58:45,200 - INFO  [node2_isolatedExecutor:3:StorageService@2785] - Node /127.0.0.2:7012 state jump to shutdown
2023-05-30 19:58:45,201 - DEBUG [node2_isolatedExecutor:3:StorageService@2782] - Node /127.0.0.2:7012 state shutdown, token [3074457345618258601]
2023-05-30 19:58:45,202 - INFO  [node2_isolatedExecutor:3:StorageService@2785] - Node /127.0.0.2:7012 state jump to shutdown
2023-05-30 19:58:45,202 - DEBUG [node1_isolatedExecutor:3:StorageService@2782] - Node /127.0.0.1:7012 state shutdown, token [-3074457345618258603]
2023-05-30 19:58:45,202 - INFO  [node1_isolatedExecutor:3:StorageService@2785] - Node /127.0.0.1:7012 state jump to shutdown
2023-05-30 19:58:45,203 - INFO  [node1_GossipStage:1:Gossiper@1328] - InetAddress /127.0.0.2:7012 is now DOWN
2023-05-30 19:58:45,203 - INFO  [node3_isolatedExecutor:4:Gossiper@2023] - Announcing shutdown
2023-05-30 19:58:45,203 - INFO  [node3_GossipStage:1:Gossiper@1328] - InetAddress /127.0.0.2:7012 is now DOWN
2023-05-30 19:58:45,203 - DEBUG [node3_isolatedExecutor:4:StorageService@2782] - Node /127.0.0.3:7012 state shutdown, token [9223372036854775805]
2023-05-30 19:58:45,203 - INFO  [node2_GossipStage:1:Gossiper@1328] - InetAddress /127.0.0.1:7012 is now DOWN
2023-05-30 19:58:45,203 - INFO  [node3_isolatedExecutor:4:StorageService@2785] - Node /127.0.0.3:7012 state jump to shutdown
2023-05-30 19:58:45,204 - DEBUG [node3_isolatedExecutor:4:StorageService@2782] - Node /127.0.0.3:7012 state shutdown, token [9223372036854775805]
2023-05-30 19:58:45,204 - INFO  [node3_isolatedExecutor:4:StorageService@2785] - Node /127.0.0.3:7012 state jump to shutdown
2023-05-30 19:58:45,204 - DEBUG [node3_GossipStage:1:FailureDetector@354] - Forcing conviction of /127.0.0.2:7012
2023-05-30 19:58:45,204 - DEBUG [node1_GossipStage:1:FailureDetector@354] - Forcing conviction of /127.0.0.2:7012
2023-05-30 19:58:45,204 - DEBUG [node2_GossipStage:1:FailureDetector@354] - Forcing conviction of /127.0.0.1:7012
2023-05-30 19:58:45,206 - DEBUG [node1_GossipStage:1:StorageService@2782] - Node /127.0.0.2:7012 state shutdown, token [3074457345618258601]
2023-05-30 19:58:45,206 - INFO  [node1_GossipStage:1:StorageService@2785] - Node /127.0.0.2:7012 state jump to shutdown
2023-05-30 19:58:45,215 - INFO  [node3_isolatedExecutor:6:HintsService@222] - Paused hints dispatch
2023-05-30 19:58:45,218 - DEBUG [node2_GossipStage:1:StorageService@2782] - Node /127.0.0.1:7012 state shutdown, token [-3074457345618258603]
2023-05-30 19:58:45,218 - INFO  [node2_GossipStage:1:StorageService@2785] - Node /127.0.0.1:7012 state jump to shutdown
2023-05-30 19:58:45,217 - DEBUG [node3_GossipStage:1:StorageService@2782] - Node /127.0.0.2:7012 state shutdown, token [3074457345618258601]
2023-05-30 19:58:45,218 - INFO  [node3_GossipStage:1:StorageService@2785] - Node /127.0.0.2:7012 state jump to shutdown
2023-05-30 19:58:45,221 - DEBUG [node1_GossipStage:1:Gossiper@588] - Marked /127.0.0.2:7012 as shutdown
2023-05-30 19:58:45,225 - INFO  [node1_GossipStage:1:Gossiper@1328] - InetAddress /127.0.0.3:7012 is now DOWN
2023-05-30 19:58:45,225 - DEBUG [node1_GossipStage:1:FailureDetector@354] - Forcing conviction of /127.0.0.3:7012
2023-05-30 19:58:45,225 - DEBUG [node1_GossipStage:1:StorageService@2782] - Node /127.0.0.3:7012 state shutdown, token [9223372036854775805]
2023-05-30 19:58:45,225 - INFO  [node1_GossipStage:1:StorageService@2785] - Node /127.0.0.3:7012 state jump to shutdown
2023-05-30 19:58:45,235 - DEBUG [node3_GossipStage:1:Gossiper@588] - Marked /127.0.0.2:7012 as shutdown
2023-05-30 19:58:45,235 - INFO  [node3_GossipStage:1:Gossiper@1328] - InetAddress /127.0.0.1:7012 is now DOWN
2023-05-30 19:58:45,235 - DEBUG [node3_GossipStage:1:FailureDetector@354] - Forcing conviction of /127.0.0.1:7012
2023-05-30 19:58:45,235 - DEBUG [node2_GossipStage:1:Gossiper@588] - Marked /127.0.0.1:7012 as shutdown
2023-05-30 19:58:45,235 - DEBUG [node3_GossipStage:1:StorageService@2782] - Node /127.0.0.1:7012 state shutdown, token [-3074457345618258603]
2023-05-30 19:58:45,235 - INFO  [node3_GossipStage:1:StorageService@2785] - Node /127.0.0.1:7012 state jump to shutdown
2023-05-30 19:58:45,235 - DEBUG [node1_GossipStage:1:Gossiper@588] - Marked /127.0.0.3:7012 as shutdown
2023-05-30 19:58:45,242 - DEBUG [node3_GossipStage:1:Gossiper@588] - Marked /127.0.0.1:7012 as shutdown
2023-05-30 19:58:45,638 - INFO  [node3_Messaging-EventLoop-3-14:InboundConnectionInitiator$Handler@464] - /127.0.0.1:7012(/127.0.0.1:39216)->/127.0.0.3:7012-URGENT_MESSAGES-298d3f2b messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:45,638 - INFO  [node1_Messaging-EventLoop-3-8:OutboundConnection$1Initiate@1150] - /127.0.0.1:7012(/127.0.0.1:39216)->/127.0.0.3:7012-URGENT_MESSAGES-fb7ccfd9 successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:45,641 - INFO  [node3_Messaging-EventLoop-3-3:OutboundConnection$1Initiate@1150] - /127.0.0.3:7012(/127.0.0.1:50960)->/127.0.0.1:7012-URGENT_MESSAGES-ecdf2024 successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:45,641 - INFO  [node1_Messaging-EventLoop-3-17:InboundConnectionInitiator$Handler@464] - /127.0.0.3:7012(/127.0.0.1:50960)->/127.0.0.1:7012-URGENT_MESSAGES-db2561c0 messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:45,974 - INFO  [node3_Messaging-EventLoop-3-8:OutboundConnection$1Initiate@1150] - /127.0.0.3:7012(/127.0.0.1:50596)->/127.0.0.2:7012-URGENT_MESSAGES-83ab78b8 successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:45,975 - INFO  [node1_Messaging-EventLoop-3-18:InboundConnectionInitiator$Handler@464] - /127.0.0.2:7012(/127.0.0.1:50962)->/127.0.0.1:7012-URGENT_MESSAGES-8f3da37a messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:45,974 - INFO  [node2_Messaging-EventLoop-3-3:OutboundConnection$1Initiate@1150] - /127.0.0.2:7012(/127.0.0.1:50962)->/127.0.0.1:7012-URGENT_MESSAGES-537f0b26 successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:45,975 - INFO  [node2_Messaging-EventLoop-3-13:InboundConnectionInitiator$Handler@464] - /127.0.0.3:7012(/127.0.0.1:50596)->/127.0.0.2:7012-URGENT_MESSAGES-e16ce887 messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:45,975 - DEBUG [node2_GossipStage:1:StorageService@2782] - Node /127.0.0.3:7012 state shutdown, token [9223372036854775805]
2023-05-30 19:58:45,975 - INFO  [node2_GossipStage:1:StorageService@2785] - Node /127.0.0.3:7012 state jump to shutdown
2023-05-30 19:58:45,977 - INFO  [node1_Messaging-EventLoop-3-5:OutboundConnection$1Initiate@1150] - /127.0.0.1:7012(/127.0.0.1:50598)->/127.0.0.2:7012-URGENT_MESSAGES-6e4bd270 successfully connected, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:45,977 - INFO  [node2_Messaging-EventLoop-3-14:InboundConnectionInitiator$Handler@464] - /127.0.0.1:7012(/127.0.0.1:50598)->/127.0.0.2:7012-URGENT_MESSAGES-3d03f4ad messaging connection established, version = 12, framing = CRC, encryption = unencrypted
2023-05-30 19:58:45,982 - DEBUG [node2_GossipStage:1:StorageService@2782] - Node /127.0.0.3:7012 state shutdown, token [9223372036854775805]
2023-05-30 19:58:45,982 - INFO  [node2_GossipStage:1:StorageService@2785] - Node /127.0.0.3:7012 state jump to shutdown
2023-05-30 19:58:47,204 - INFO  [node2_isolatedExecutor:12:MessagingService@441] - Waiting for messaging service to quiesce
2023-05-30 19:58:47,204 - INFO  [node1_isolatedExecutor:6:MessagingService@441] - Waiting for messaging service to quiesce
2023-05-30 19:58:47,207 - INFO  [node3_isolatedExecutor:6:MessagingService@441] - Waiting for messaging service to quiesce

Time: 37.142

OK (1 test)

