JUnit version 4.13
.2022-07-12 17:23:50,053 - INFO  [main:ConnectIntegrationTestUtils$1@33] - Starting test testSourceTaskNotBlockedOnShutdownWithNonExistentTopic
2022-07-12 17:23:50,194 - INFO  [main:Log4jControllerRegistration$@31] - Registered kafka:type=kafka.Log4jController MBean
2022-07-12 17:23:50,237 - INFO  [main:Environment@109] - Server environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
2022-07-12 17:23:50,237 - INFO  [main:Environment@109] - Server environment:host.name=razor15
2022-07-12 17:23:50,237 - INFO  [main:Environment@109] - Server environment:java.version=1.8.0_275
2022-07-12 17:23:50,237 - INFO  [main:Environment@109] - Server environment:java.vendor=Private Build
2022-07-12 17:23:50,237 - INFO  [main:Environment@109] - Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2022-07-12 17:23:50,238 - INFO  [main:Environment@109] - Server environment:java.class.path=/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/examples/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/generator/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/clients/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/jmh-benchmarks/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/streams/examples/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/streams/streams-scala/build/classes/scala/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/streams/test-utils/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/streams/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/metadata/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/raft/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/log4j-appender/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/api/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/runtime/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/mirror-client/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/mirror/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/file/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/transforms/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/json/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/basic-auth-extension/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/tools/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/core/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/core/build/classes/scala/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/shell/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/clients/build/classes/java/test:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/runtime/build/classes/java/test:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/core/build/classes/scala/test:/home/tonypan/flaky-reproduction/experiment/kafka-10340:/home/tonypan/.gradle/caches/modules-2/files-2.1/commons-cli/commons-cli/1.4/c51c00206bb913cd8612b24abd9fa98ae89719b1/commons-cli-1.4.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-common/4.1.51.Final/ef64ad6fe8a8bc380a96f6d67e9fc442689dd7e1/netty-common-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-buffer/4.1.51.Final/2f4efc2ed376b46f4eb27f9405fa5a32a3695177/netty-buffer-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-resolver/4.1.51.Final/47c0b7a0e0faf059d5b8c58b64d78b8f2cfc0463/netty-resolver-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-transport/4.1.51.Final/dbbe2d21879ceb82e7b44cd505aba83b752001a4/netty-transport-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-transport-native-unix-common/4.1.51.Final/170f987d8dbba498734c0d15eb88b16cd38eebdf/netty-transport-native-unix-common-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-codec/4.1.51.Final/69b830d381b64e988632561d823b53f783efe9c5/netty-codec-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-transport-native-epoll/4.1.51.Final/df33912f0adb51ba47f74fc4d3d8e391f8cb7fdd/netty-transport-native-epoll-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-handler/4.1.51.Final/b4b1db4b71e4e082587da3a5684df101dab2dc3a/netty-handler-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.yetus/audience-annotations/0.5.0/55762d3191a8d6610ef46d11e8cb70c7667342a3/audience-annotations-0.5.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.zookeeper/zookeeper-jute/3.5.9/9f14e67a10bfe1ff02347c02116ab4ca03febb6f/zookeeper-jute-3.5.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/net.sf.jopt-simple/jopt-simple/5.0.4/4fdac2fbe92dfad86aa6e9301736f6b4342a3f5c/jopt-simple-5.0.4.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.thoughtworks.paranamer/paranamer/2.8/619eba74c19ccf1da8ebec97a2d7f8ba05773dd6/paranamer-2.8.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.scala-lang/scala-library/2.13.5/d0df6e78b6ccb0102cb0395bfa8cb806e9e81b61/scala-library-2.13.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.scala-lang/scala-reflect/2.13.5/8dee4d8c5374920f2db2f5f55d9dd6ecd4194cc/scala-reflect-2.13.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.scala-lang.modules/scala-java8-compat_2.13/0.9.1/970d8d65f42a76c2fad104ea7f50e8f1daf38b8/scala-java8-compat_2.13-0.9.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.scala-lang.modules/scala-collection-compat_2.13/2.3.0/c992f4285e6d3a9375a8c41788db4bef5649c777/scala-collection-compat_2.13-2.3.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/commons-codec/commons-codec/1.11/3acb4705652e16236558f0f4f2192cc33c3bd189/commons-codec-1.11.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/commons-logging/commons-logging/1.2/4bfc12adfe4842bf07b657f0369c4cb522955686/commons-logging-1.2.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpcore/4.4.13/853b96d3afbb7bf8cc303fe27ee96836a10c1834/httpcore-4.4.13.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/cglib/cglib-nodep/3.2.9/27ca91ebc2b82f844e62a7ba8c2c1fdf9b84fa80/cglib-nodep-3.2.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/net.bytebuddy/byte-buddy-agent/1.10.15/7f0cc687ee3177fd451d17b9b80325a8cdd1c7ff/byte-buddy-agent-1.10.15.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/net.bytebuddy/byte-buddy/1.10.15/259957c76d345cb3db5411f57a0654300aaca04c/byte-buddy-1.10.15.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/42a25dc3219429f0e5d060061f71acb49bf010a0/hamcrest-core-1.3.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/junit/junit/4.13/e49ccba652b735c93bd6e6f59760d8254cf597dd/junit-4.13.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.opentest4j/opentest4j/1.2.0/28c11eb91f9b6d8e200631d46e20a7f407f2a046/opentest4j-1.2.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apiguardian/apiguardian-api/1.1.0/fc9dff4bb36d627bdc553de77e1f17efd790876c/apiguardian-api-1.1.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/3.1/48f12deaae83a8dfc3775d830c9fd60ea59bbbca/objenesis-3.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-reflect/2.0.9/4bb9ed43e5221926fb86cae44b445de110a51d05/powermock-reflect-2.0.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.commons/commons-lang3/3.8.1/6505a72a097d9270f7a9e7bf42c4238283247755/commons-lang3-3.8.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.codehaus.plexus/plexus-utils/3.2.1/13b015768e0d04849d2794e4c47eb02d01a0de32/plexus-utils-3.2.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-continuation/9.4.36.v20210114/84dcd3bc44258d6e2e552f59c77966c4ed252373/jetty-continuation-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-util/9.4.36.v20210114/925257fbcca6b501a25252c7447dbedb021f7404/jetty-util-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-util-ajax/9.4.36.v20210114/2f478130c21787073facb64d7242e06f94980c60/jetty-util-ajax-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-io/9.4.36.v20210114/84a8faf9031eb45a5a2ddb7681e22c483d81ab3a/jetty-io-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-http/9.4.36.v20210114/1eee89a55e04ff94df0f85d95200fc48acb43d86/jetty-http-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/javax.servlet/javax.servlet-api/3.1.0/3cd63d075497751784b2fa84be59432f4905bf7c/javax.servlet-api-3.1.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.javassist/javassist/3.27.0-GA/f63e6aa899e15eca8fdaa402a79af4c417252213/javassist-3.27.0-GA.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-core/2.0.9/50e5d2652fd311ee9c33919dfadd44504a582210/powermock-core-2.0.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-api-support/2.0.9/65deba8a4207715b7d8fa6c1b8d8cac06e6ecb00/powermock-api-support-2.0.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-module-junit4-common/2.0.9/661b819ad3e8b5cab72bea3816ba2602d82d7f00/powermock-module-junit4-common-2.0.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.hk2.external/aopalliance-repackaged/2.6.1/b2eb0a83bcbb44cc5d25f8b18f23be116313a638/aopalliance-repackaged-2.6.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/jakarta.validation/jakarta.validation-api/2.0.2/5eacc6522521f7eacb081f95cee1e231648461e7/jakarta.validation-api-2.0.2.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.hk2/osgi-resource-locator/1.0.3/de3b21279df7e755e38275137539be5e2c80dd58/osgi-resource-locator-1.0.3.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/jakarta.annotation/jakarta.annotation-api/1.3.5/59eb84ee0d616332ff44aba065f3888cf002cd2d/jakarta.annotation-api-1.3.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/jakarta.ws.rs/jakarta.ws.rs-api/2.1.6/1dcb770bce80a490dff49729b99c7a60e9ecb122/jakarta.ws.rs-api-2.1.6.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.hk2.external/jakarta.inject/2.6.1/8096ebf722902e75fbd4f532a751e514f02e1eb7/jakarta.inject-2.6.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.hk2/hk2-utils/2.6.1/396513aa96c1d5a10aa4f75c4dcbf259a698d62d/hk2-utils-2.6.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.hk2/hk2-api/2.6.1/114bd7afb4a1bd9993527f52a08a252b5d2acac5/hk2-api-2.6.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.hk2/hk2-locator/2.6.1/9dedf9d2022e38ec0743ed44c1ac94ad6149acdd/hk2-locator-2.6.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.core/jersey-common/2.31/b918c028c3c8c8b92a1ebb764571c369a85de04b/jersey-common-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.media/jersey-media-jaxb/2.31/33a9245a4796a1cce9d8ac9decb219b35825e6c2/jersey-media-jaxb-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.core/jersey-client/2.31/fc9d5bc22f679085f9e5754429bdcff46a6844fa/jersey-client-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.core/jersey-server/2.31/c9d42ddd4f8342381889cf1e0df15c1777aaffd6/jersey-server-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.containers/jersey-container-servlet-core/2.31/23911098a6abb0ad528d3908b89d564e2f9ef6b1/jersey-container-servlet-core-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/jakarta.activation/jakarta.activation-api/1.2.1/562a587face36ec7eff2db7f2fc95425c6602bc1/jakarta.activation-api-1.2.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/jakarta.xml.bind/jakarta.xml.bind-api/2.3.2/8d49996a4338670764d7ca4b85a1c4ccf7fe665d/jakarta.xml.bind-api-2.3.2.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.10.5/db2ba27938de7f2d478a97d6abcdaa17cbbd3cea/jackson-core-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.10.5/33298de8da86f92f8ccd61ced214d3b16f8c531e/jackson-annotations-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.10.5.1/7ff756c3af1fe95cb3cddba9158fc3289ca06387/jackson-databind-2.10.5.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.module/jackson-module-paranamer/2.10.5/3907141093e7a5523becedba1dd27f7448caf0c/jackson-module-paranamer-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-csv/2.10.5/2fdba33036a74540f59ec21f956a3a5427e1c9db/jackson-dataformat-csv-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.module/jackson-module-scala_2.13/2.10.5/f8e550e7b1a937e805e9b3c8ce16aeb16bc56a66/jackson-module-scala_2.13-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.module/jackson-module-jaxb-annotations/2.10.5/f438b5eb66d15cbffca1497408b4cb379af9b068/jackson-module-jaxb-annotations-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.jaxrs/jackson-jaxrs-base/2.10.5/2c0c330f121ca5396560a692113c8339f7aac9b5/jackson-jaxrs-base-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jdk8/2.10.5/2e145b4eeccdfe0efc8f4aa38b80d493465f7064/jackson-datatype-jdk8-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/net.sourceforge.argparse4j/argparse4j/0.7.0/6f0621d0c3888de39e0f06d01f37ba53a798e657/argparse4j-0.7.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.17/5af35056b4d257e4b64b9e8069c0746e8b08629f/log4j-1.2.17.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/javax.ws.rs/javax.ws.rs-api/2.1.1/d3466bc9321fe84f268a1adb3b90373fc14b0eb5/javax.ws.rs-api-2.1.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.8.1/d30aaf4d41d6ff0c760c8931d3b8dafc0293c91a/snappy-java-1.1.8.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.lz4/lz4-java/1.7.1/c4d931ef8ad2c9c35d65b231a33e61428472d0da/lz4-java-1.7.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.github.luben/zstd-jni/1.4.8-4/ef41e7e37b045187179d404ae51b71d7c398e54a/zstd-jni-1.4.8-4.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpclient/4.5.13/e5f6cae5ca7ecaac1ec2827a9e2d65ae2869cada/httpclient-4.5.13.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/3.6.0/48657987075fea2e2176634ae35aaa5e93c929ef/mockito-core-3.6.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-module-junit4/2.0.9/9f13da80a3d75cc9579b55389e919f661ec42f0/powermock-module-junit4-2.0.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.junit.jupiter/junit-jupiter-api/5.7.1/a7261dff44e64aea7f621842eac5977fd6d2412d/junit-jupiter-api-5.7.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.junit.platform/junit-platform-commons/1.7.1/7c49f0074842d07f4335de2389d624a7437d1407/junit-platform-commons-1.7.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.junit.platform/junit-platform-engine/1.7.1/d276a968c57f5d60a421dedd1f8b6ca2fae09e86/junit-platform-engine-1.7.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.junit.vintage/junit-vintage-engine/5.7.1/8184800e1a38965b3fb62a104458678835311e94/junit-vintage-engine-5.7.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.easymock/easymock/4.2/251b26f1b853673c1aac277fd2fb0c8d5844cdc8/easymock-4.2.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-api-easymock/2.0.9/ace3f16a82c0f1f4edbb810699b76705a1a50b6c/powermock-api-easymock-2.0.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-artifact/3.6.3/f8ff8032903882376e8d000c51e3e16d20fc7df7/maven-artifact-3.6.3.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.reflections/reflections/0.9.12/1c9d44c563eebe9b8a3afebd29ed5c4646db800c/reflections-0.9.12.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-client/9.4.36.v20210114/5689f7953e2c305e3353ac4205cd342fd6acdffc/jetty-client-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-servlets/9.4.36.v20210114/80d85ab9b82acb0af174ee5b6d5669b4ad3faf2/jetty-servlets-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-server/9.4.36.v20210114/88a7d342974aadca658e7386e8d0fcc5c0788f41/jetty-server-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-security/9.4.36.v20210114/42030d6ed7dfc0f75818cde0adcf738efc477574/jetty-security-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-servlet/9.4.36.v20210114/b189e52a5ee55ae172e4e99e29c5c314f5daf4b9/jetty-servlet-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/javax.activation/activation/1.1.1/485de3a253e23f645037828c07f1d7f1af40763a/activation-1.1.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/javax.xml.bind/jaxb-api/2.3.0/99f802e0cb3e953ba3d6e698795c4aeb98d37c48/jaxb-api-2.3.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.inject/jersey-hk2/2.31/bbc4b2a9192beceeaa50bf8a6ebaf6953fc9d4d/jersey-hk2-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.containers/jersey-container-servlet/2.31/cb77f7f25ea435fc8a316787babbfeaf7dfb1b79/jersey-container-servlet-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.jaxrs/jackson-jaxrs-json-provider/2.10.5/e7be01e92f7ef9361118eef78f1974c5f778dd6a/jackson-jaxrs-json-provider-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.30/b5a4b6d16ab13e34a88fae84c35cd5d68cac922c/slf4j-api-1.7.30.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.zookeeper/zookeeper/3.5.9/3b0e8eaff97fce87075c02fd764e4f2d04996f31/zookeeper-3.5.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.typesafe.scala-logging/scala-logging_2.13/3.9.2/6986314976f55419819ca7ae9f9d077ba070fe42/scala-logging_2.13-3.9.2.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.yammer.metrics/metrics-core/2.2.0/f82c035cfa786d3cbec362c38c22a5f5b1bc8724/metrics-core-2.2.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-log4j12/1.7.30/c21f55139d8141d2231214fb1feaf50a1edca95e/slf4j-log4j12-1.7.30.jar:/home/tonypan/flaky-reproduction/systems/kafka-10340/core/build/resources/test/:/home/tonypan/flaky-reproduction/systems/kafka-10340/core/build/classes/scala/test/:/home/tonypan/flaky-reproduction/systems/kafka-10340/core/build/classes/java/test:/home/tonypan/flaky-reproduction/systems/kafka-10340/clients/build/resources/test/:/home/tonypan/flaky-reproduction/systems/kafka-10340/clients/build/classes/java/test/:/home/tonypan/flaky-reproduction/systems/kafka-10340/connect/runtime/build/resources/main/:/home/tonypan/flaky-reproduction/systems/kafka-10340/connect/runtime/build/classes/java/main/:/home/tonypan/flaky-reproduction/systems/kafka-10340/connect/runtime/build/resources/test/:/home/tonypan/flaky-reproduction/systems/kafka-10340/connect/runtime/build/classes/java/test/:/home/tonypan/flaky-reproduction/experiment/kafka-10340
2022-07-12 17:23:50,239 - INFO  [main:Environment@109] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2022-07-12 17:23:50,239 - INFO  [main:Environment@109] - Server environment:java.io.tmpdir=/tmp
2022-07-12 17:23:50,239 - INFO  [main:Environment@109] - Server environment:java.compiler=<NA>
2022-07-12 17:23:50,239 - INFO  [main:Environment@109] - Server environment:os.name=Linux
2022-07-12 17:23:50,239 - INFO  [main:Environment@109] - Server environment:os.arch=amd64
2022-07-12 17:23:50,240 - INFO  [main:Environment@109] - Server environment:os.version=4.15.0-128-generic
2022-07-12 17:23:50,240 - INFO  [main:Environment@109] - Server environment:user.name=tonypan
2022-07-12 17:23:50,240 - INFO  [main:Environment@109] - Server environment:user.home=/home/tonypan
2022-07-12 17:23:50,241 - INFO  [main:Environment@109] - Server environment:user.dir=/home/tonypan/flaky-reproduction/experiment/kafka-10340
2022-07-12 17:23:50,241 - INFO  [main:Environment@109] - Server environment:os.memory.free=403MB
2022-07-12 17:23:50,241 - INFO  [main:Environment@109] - Server environment:os.memory.max=7051MB
2022-07-12 17:23:50,241 - INFO  [main:Environment@109] - Server environment:os.memory.total=475MB
2022-07-12 17:23:50,245 - INFO  [main:FileTxnSnapLog@115] - zookeeper.snapshot.trust.empty : false
2022-07-12 17:23:50,261 - INFO  [main:ZKDatabase@117] - zookeeper.snapshotSizeFactor = 0.33
2022-07-12 17:23:50,265 - INFO  [main:ZooKeeperServer@953] - minSessionTimeout set to 1600
2022-07-12 17:23:50,265 - INFO  [main:ZooKeeperServer@962] - maxSessionTimeout set to 16000
2022-07-12 17:23:50,266 - INFO  [main:ZooKeeperServer@181] - Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 datadir /tmp/kafka-4875769703842615187/version-2 snapdir /tmp/kafka-8038492462732678149/version-2
2022-07-12 17:23:50,275 - INFO  [main:NIOServerCnxnFactory@673] - Configuring NIO connection handler with 10s sessionless connection timeout, 3 selector thread(s), 40 worker threads, and 64 kB direct buffers.
2022-07-12 17:23:50,280 - INFO  [main:NIOServerCnxnFactory@686] - binding to port /127.0.0.1:0
2022-07-12 17:23:50,289 - INFO  [main:FileTxnSnapLog@404] - Snapshotting: 0x0 to /tmp/kafka-8038492462732678149/version-2/snapshot.0
2022-07-12 17:23:50,291 - INFO  [main:FileTxnSnapLog@404] - Snapshotting: 0x0 to /tmp/kafka-8038492462732678149/version-2/snapshot.0
2022-07-12 17:23:50,305 - INFO  [ProcessThread(sid:0 cport:37769)::PrepRequestProcessor@132] - PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2022-07-12 17:23:50,580 - INFO  [main:AbstractConfig@372] - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = localhost
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/EmbeddedKafkaCluster7379043744743579021
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 0
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:37769
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000

2022-07-12 17:23:50,594 - INFO  [main:X509Util@79] - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2022-07-12 17:23:50,670 - INFO  [main:Logging@66] - starting
2022-07-12 17:23:50,671 - INFO  [main:Logging@66] - Connecting to zookeeper on 127.0.0.1:37769
2022-07-12 17:23:50,688 - INFO  [main:Logging@66] - [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:37769.
2022-07-12 17:23:50,692 - INFO  [main:Environment@109] - Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
2022-07-12 17:23:50,692 - INFO  [main:Environment@109] - Client environment:host.name=razor15
2022-07-12 17:23:50,693 - INFO  [main:Environment@109] - Client environment:java.version=1.8.0_275
2022-07-12 17:23:50,693 - INFO  [main:Environment@109] - Client environment:java.vendor=Private Build
2022-07-12 17:23:50,693 - INFO  [main:Environment@109] - Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2022-07-12 17:23:50,693 - INFO  [main:Environment@109] - Client environment:java.class.path=/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/examples/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/generator/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/clients/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/jmh-benchmarks/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/streams/examples/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/streams/streams-scala/build/classes/scala/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/streams/test-utils/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/streams/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/metadata/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/raft/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/log4j-appender/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/api/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/runtime/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/mirror-client/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/mirror/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/file/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/transforms/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/json/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/basic-auth-extension/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/tools/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/core/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/core/build/classes/scala/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/shell/build/classes/java/main:/home/tonypan/flaky-reproduction/experiment/kafka-10340:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/clients/build/classes/java/test:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/connect/runtime/build/classes/java/test:/home/tonypan/flaky-reproduction/experiment/kafka-10340/../../systems/kafka-10340/core/build/classes/scala/test:/home/tonypan/flaky-reproduction/experiment/kafka-10340:/home/tonypan/.gradle/caches/modules-2/files-2.1/commons-cli/commons-cli/1.4/c51c00206bb913cd8612b24abd9fa98ae89719b1/commons-cli-1.4.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-common/4.1.51.Final/ef64ad6fe8a8bc380a96f6d67e9fc442689dd7e1/netty-common-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-buffer/4.1.51.Final/2f4efc2ed376b46f4eb27f9405fa5a32a3695177/netty-buffer-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-resolver/4.1.51.Final/47c0b7a0e0faf059d5b8c58b64d78b8f2cfc0463/netty-resolver-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-transport/4.1.51.Final/dbbe2d21879ceb82e7b44cd505aba83b752001a4/netty-transport-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-transport-native-unix-common/4.1.51.Final/170f987d8dbba498734c0d15eb88b16cd38eebdf/netty-transport-native-unix-common-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-codec/4.1.51.Final/69b830d381b64e988632561d823b53f783efe9c5/netty-codec-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-transport-native-epoll/4.1.51.Final/df33912f0adb51ba47f74fc4d3d8e391f8cb7fdd/netty-transport-native-epoll-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/io.netty/netty-handler/4.1.51.Final/b4b1db4b71e4e082587da3a5684df101dab2dc3a/netty-handler-4.1.51.Final.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.yetus/audience-annotations/0.5.0/55762d3191a8d6610ef46d11e8cb70c7667342a3/audience-annotations-0.5.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.zookeeper/zookeeper-jute/3.5.9/9f14e67a10bfe1ff02347c02116ab4ca03febb6f/zookeeper-jute-3.5.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/net.sf.jopt-simple/jopt-simple/5.0.4/4fdac2fbe92dfad86aa6e9301736f6b4342a3f5c/jopt-simple-5.0.4.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.thoughtworks.paranamer/paranamer/2.8/619eba74c19ccf1da8ebec97a2d7f8ba05773dd6/paranamer-2.8.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.scala-lang/scala-library/2.13.5/d0df6e78b6ccb0102cb0395bfa8cb806e9e81b61/scala-library-2.13.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.scala-lang/scala-reflect/2.13.5/8dee4d8c5374920f2db2f5f55d9dd6ecd4194cc/scala-reflect-2.13.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.scala-lang.modules/scala-java8-compat_2.13/0.9.1/970d8d65f42a76c2fad104ea7f50e8f1daf38b8/scala-java8-compat_2.13-0.9.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.scala-lang.modules/scala-collection-compat_2.13/2.3.0/c992f4285e6d3a9375a8c41788db4bef5649c777/scala-collection-compat_2.13-2.3.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/commons-codec/commons-codec/1.11/3acb4705652e16236558f0f4f2192cc33c3bd189/commons-codec-1.11.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/commons-logging/commons-logging/1.2/4bfc12adfe4842bf07b657f0369c4cb522955686/commons-logging-1.2.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpcore/4.4.13/853b96d3afbb7bf8cc303fe27ee96836a10c1834/httpcore-4.4.13.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/cglib/cglib-nodep/3.2.9/27ca91ebc2b82f844e62a7ba8c2c1fdf9b84fa80/cglib-nodep-3.2.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/net.bytebuddy/byte-buddy-agent/1.10.15/7f0cc687ee3177fd451d17b9b80325a8cdd1c7ff/byte-buddy-agent-1.10.15.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/net.bytebuddy/byte-buddy/1.10.15/259957c76d345cb3db5411f57a0654300aaca04c/byte-buddy-1.10.15.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/42a25dc3219429f0e5d060061f71acb49bf010a0/hamcrest-core-1.3.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/junit/junit/4.13/e49ccba652b735c93bd6e6f59760d8254cf597dd/junit-4.13.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.opentest4j/opentest4j/1.2.0/28c11eb91f9b6d8e200631d46e20a7f407f2a046/opentest4j-1.2.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apiguardian/apiguardian-api/1.1.0/fc9dff4bb36d627bdc553de77e1f17efd790876c/apiguardian-api-1.1.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/3.1/48f12deaae83a8dfc3775d830c9fd60ea59bbbca/objenesis-3.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-reflect/2.0.9/4bb9ed43e5221926fb86cae44b445de110a51d05/powermock-reflect-2.0.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.commons/commons-lang3/3.8.1/6505a72a097d9270f7a9e7bf42c4238283247755/commons-lang3-3.8.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.codehaus.plexus/plexus-utils/3.2.1/13b015768e0d04849d2794e4c47eb02d01a0de32/plexus-utils-3.2.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-continuation/9.4.36.v20210114/84dcd3bc44258d6e2e552f59c77966c4ed252373/jetty-continuation-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-util/9.4.36.v20210114/925257fbcca6b501a25252c7447dbedb021f7404/jetty-util-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-util-ajax/9.4.36.v20210114/2f478130c21787073facb64d7242e06f94980c60/jetty-util-ajax-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-io/9.4.36.v20210114/84a8faf9031eb45a5a2ddb7681e22c483d81ab3a/jetty-io-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-http/9.4.36.v20210114/1eee89a55e04ff94df0f85d95200fc48acb43d86/jetty-http-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/javax.servlet/javax.servlet-api/3.1.0/3cd63d075497751784b2fa84be59432f4905bf7c/javax.servlet-api-3.1.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.javassist/javassist/3.27.0-GA/f63e6aa899e15eca8fdaa402a79af4c417252213/javassist-3.27.0-GA.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-core/2.0.9/50e5d2652fd311ee9c33919dfadd44504a582210/powermock-core-2.0.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-api-support/2.0.9/65deba8a4207715b7d8fa6c1b8d8cac06e6ecb00/powermock-api-support-2.0.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-module-junit4-common/2.0.9/661b819ad3e8b5cab72bea3816ba2602d82d7f00/powermock-module-junit4-common-2.0.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.hk2.external/aopalliance-repackaged/2.6.1/b2eb0a83bcbb44cc5d25f8b18f23be116313a638/aopalliance-repackaged-2.6.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/jakarta.validation/jakarta.validation-api/2.0.2/5eacc6522521f7eacb081f95cee1e231648461e7/jakarta.validation-api-2.0.2.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.hk2/osgi-resource-locator/1.0.3/de3b21279df7e755e38275137539be5e2c80dd58/osgi-resource-locator-1.0.3.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/jakarta.annotation/jakarta.annotation-api/1.3.5/59eb84ee0d616332ff44aba065f3888cf002cd2d/jakarta.annotation-api-1.3.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/jakarta.ws.rs/jakarta.ws.rs-api/2.1.6/1dcb770bce80a490dff49729b99c7a60e9ecb122/jakarta.ws.rs-api-2.1.6.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.hk2.external/jakarta.inject/2.6.1/8096ebf722902e75fbd4f532a751e514f02e1eb7/jakarta.inject-2.6.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.hk2/hk2-utils/2.6.1/396513aa96c1d5a10aa4f75c4dcbf259a698d62d/hk2-utils-2.6.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.hk2/hk2-api/2.6.1/114bd7afb4a1bd9993527f52a08a252b5d2acac5/hk2-api-2.6.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.hk2/hk2-locator/2.6.1/9dedf9d2022e38ec0743ed44c1ac94ad6149acdd/hk2-locator-2.6.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.core/jersey-common/2.31/b918c028c3c8c8b92a1ebb764571c369a85de04b/jersey-common-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.media/jersey-media-jaxb/2.31/33a9245a4796a1cce9d8ac9decb219b35825e6c2/jersey-media-jaxb-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.core/jersey-client/2.31/fc9d5bc22f679085f9e5754429bdcff46a6844fa/jersey-client-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.core/jersey-server/2.31/c9d42ddd4f8342381889cf1e0df15c1777aaffd6/jersey-server-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.containers/jersey-container-servlet-core/2.31/23911098a6abb0ad528d3908b89d564e2f9ef6b1/jersey-container-servlet-core-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/jakarta.activation/jakarta.activation-api/1.2.1/562a587face36ec7eff2db7f2fc95425c6602bc1/jakarta.activation-api-1.2.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/jakarta.xml.bind/jakarta.xml.bind-api/2.3.2/8d49996a4338670764d7ca4b85a1c4ccf7fe665d/jakarta.xml.bind-api-2.3.2.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.10.5/db2ba27938de7f2d478a97d6abcdaa17cbbd3cea/jackson-core-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.10.5/33298de8da86f92f8ccd61ced214d3b16f8c531e/jackson-annotations-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.10.5.1/7ff756c3af1fe95cb3cddba9158fc3289ca06387/jackson-databind-2.10.5.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.module/jackson-module-paranamer/2.10.5/3907141093e7a5523becedba1dd27f7448caf0c/jackson-module-paranamer-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-csv/2.10.5/2fdba33036a74540f59ec21f956a3a5427e1c9db/jackson-dataformat-csv-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.module/jackson-module-scala_2.13/2.10.5/f8e550e7b1a937e805e9b3c8ce16aeb16bc56a66/jackson-module-scala_2.13-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.module/jackson-module-jaxb-annotations/2.10.5/f438b5eb66d15cbffca1497408b4cb379af9b068/jackson-module-jaxb-annotations-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.jaxrs/jackson-jaxrs-base/2.10.5/2c0c330f121ca5396560a692113c8339f7aac9b5/jackson-jaxrs-base-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jdk8/2.10.5/2e145b4eeccdfe0efc8f4aa38b80d493465f7064/jackson-datatype-jdk8-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/net.sourceforge.argparse4j/argparse4j/0.7.0/6f0621d0c3888de39e0f06d01f37ba53a798e657/argparse4j-0.7.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.17/5af35056b4d257e4b64b9e8069c0746e8b08629f/log4j-1.2.17.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/javax.ws.rs/javax.ws.rs-api/2.1.1/d3466bc9321fe84f268a1adb3b90373fc14b0eb5/javax.ws.rs-api-2.1.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.8.1/d30aaf4d41d6ff0c760c8931d3b8dafc0293c91a/snappy-java-1.1.8.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.lz4/lz4-java/1.7.1/c4d931ef8ad2c9c35d65b231a33e61428472d0da/lz4-java-1.7.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.github.luben/zstd-jni/1.4.8-4/ef41e7e37b045187179d404ae51b71d7c398e54a/zstd-jni-1.4.8-4.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpclient/4.5.13/e5f6cae5ca7ecaac1ec2827a9e2d65ae2869cada/httpclient-4.5.13.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/3.6.0/48657987075fea2e2176634ae35aaa5e93c929ef/mockito-core-3.6.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-module-junit4/2.0.9/9f13da80a3d75cc9579b55389e919f661ec42f0/powermock-module-junit4-2.0.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.junit.jupiter/junit-jupiter-api/5.7.1/a7261dff44e64aea7f621842eac5977fd6d2412d/junit-jupiter-api-5.7.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.junit.platform/junit-platform-commons/1.7.1/7c49f0074842d07f4335de2389d624a7437d1407/junit-platform-commons-1.7.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.junit.platform/junit-platform-engine/1.7.1/d276a968c57f5d60a421dedd1f8b6ca2fae09e86/junit-platform-engine-1.7.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.junit.vintage/junit-vintage-engine/5.7.1/8184800e1a38965b3fb62a104458678835311e94/junit-vintage-engine-5.7.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.easymock/easymock/4.2/251b26f1b853673c1aac277fd2fb0c8d5844cdc8/easymock-4.2.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-api-easymock/2.0.9/ace3f16a82c0f1f4edbb810699b76705a1a50b6c/powermock-api-easymock-2.0.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-artifact/3.6.3/f8ff8032903882376e8d000c51e3e16d20fc7df7/maven-artifact-3.6.3.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.reflections/reflections/0.9.12/1c9d44c563eebe9b8a3afebd29ed5c4646db800c/reflections-0.9.12.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-client/9.4.36.v20210114/5689f7953e2c305e3353ac4205cd342fd6acdffc/jetty-client-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-servlets/9.4.36.v20210114/80d85ab9b82acb0af174ee5b6d5669b4ad3faf2/jetty-servlets-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-server/9.4.36.v20210114/88a7d342974aadca658e7386e8d0fcc5c0788f41/jetty-server-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-security/9.4.36.v20210114/42030d6ed7dfc0f75818cde0adcf738efc477574/jetty-security-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.eclipse.jetty/jetty-servlet/9.4.36.v20210114/b189e52a5ee55ae172e4e99e29c5c314f5daf4b9/jetty-servlet-9.4.36.v20210114.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/javax.activation/activation/1.1.1/485de3a253e23f645037828c07f1d7f1af40763a/activation-1.1.1.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/javax.xml.bind/jaxb-api/2.3.0/99f802e0cb3e953ba3d6e698795c4aeb98d37c48/jaxb-api-2.3.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.inject/jersey-hk2/2.31/bbc4b2a9192beceeaa50bf8a6ebaf6953fc9d4d/jersey-hk2-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.glassfish.jersey.containers/jersey-container-servlet/2.31/cb77f7f25ea435fc8a316787babbfeaf7dfb1b79/jersey-container-servlet-2.31.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.jaxrs/jackson-jaxrs-json-provider/2.10.5/e7be01e92f7ef9361118eef78f1974c5f778dd6a/jackson-jaxrs-json-provider-2.10.5.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.30/b5a4b6d16ab13e34a88fae84c35cd5d68cac922c/slf4j-api-1.7.30.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.apache.zookeeper/zookeeper/3.5.9/3b0e8eaff97fce87075c02fd764e4f2d04996f31/zookeeper-3.5.9.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.typesafe.scala-logging/scala-logging_2.13/3.9.2/6986314976f55419819ca7ae9f9d077ba070fe42/scala-logging_2.13-3.9.2.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/com.yammer.metrics/metrics-core/2.2.0/f82c035cfa786d3cbec362c38c22a5f5b1bc8724/metrics-core-2.2.0.jar:/home/tonypan/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-log4j12/1.7.30/c21f55139d8141d2231214fb1feaf50a1edca95e/slf4j-log4j12-1.7.30.jar:/home/tonypan/flaky-reproduction/systems/kafka-10340/core/build/resources/test/:/home/tonypan/flaky-reproduction/systems/kafka-10340/core/build/classes/scala/test/:/home/tonypan/flaky-reproduction/systems/kafka-10340/core/build/classes/java/test:/home/tonypan/flaky-reproduction/systems/kafka-10340/clients/build/resources/test/:/home/tonypan/flaky-reproduction/systems/kafka-10340/clients/build/classes/java/test/:/home/tonypan/flaky-reproduction/systems/kafka-10340/connect/runtime/build/resources/main/:/home/tonypan/flaky-reproduction/systems/kafka-10340/connect/runtime/build/classes/java/main/:/home/tonypan/flaky-reproduction/systems/kafka-10340/connect/runtime/build/resources/test/:/home/tonypan/flaky-reproduction/systems/kafka-10340/connect/runtime/build/classes/java/test/:/home/tonypan/flaky-reproduction/experiment/kafka-10340
2022-07-12 17:23:50,693 - INFO  [main:Environment@109] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2022-07-12 17:23:50,693 - INFO  [main:Environment@109] - Client environment:java.io.tmpdir=/tmp
2022-07-12 17:23:50,694 - INFO  [main:Environment@109] - Client environment:java.compiler=<NA>
2022-07-12 17:23:50,694 - INFO  [main:Environment@109] - Client environment:os.name=Linux
2022-07-12 17:23:50,694 - INFO  [main:Environment@109] - Client environment:os.arch=amd64
2022-07-12 17:23:50,694 - INFO  [main:Environment@109] - Client environment:os.version=4.15.0-128-generic
2022-07-12 17:23:50,694 - INFO  [main:Environment@109] - Client environment:user.name=tonypan
2022-07-12 17:23:50,694 - INFO  [main:Environment@109] - Client environment:user.home=/home/tonypan
2022-07-12 17:23:50,694 - INFO  [main:Environment@109] - Client environment:user.dir=/home/tonypan/flaky-reproduction/experiment/kafka-10340
2022-07-12 17:23:50,694 - INFO  [main:Environment@109] - Client environment:os.memory.free=411MB
2022-07-12 17:23:50,694 - INFO  [main:Environment@109] - Client environment:os.memory.max=7051MB
2022-07-12 17:23:50,695 - INFO  [main:Environment@109] - Client environment:os.memory.total=475MB
2022-07-12 17:23:50,698 - INFO  [main:ZooKeeper@868] - Initiating client connection, connectString=127.0.0.1:37769 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5b12b668
2022-07-12 17:23:50,700 - INFO  [main:ClientCnxnSocket@237] - jute.maxbuffer value is 4194304 Bytes
2022-07-12 17:23:50,706 - INFO  [main:ClientCnxn@1653] - zookeeper.request.timeout value is 0. feature enabled=
2022-07-12 17:23:50,707 - INFO  [main:Logging@66] - [ZooKeeperClient Kafka server] Waiting until connected.
2022-07-12 17:23:50,712 - INFO  [main-SendThread(127.0.0.1:37769):ClientCnxn$SendThread@1112] - Opening socket connection to server localhost/127.0.0.1:37769. Will not attempt to authenticate using SASL (unknown error)
2022-07-12 17:23:50,714 - INFO  [main-SendThread(127.0.0.1:37769):ClientCnxn$SendThread@959] - Socket connection established, initiating session, client: /127.0.0.1:49910, server: localhost/127.0.0.1:37769
2022-07-12 17:23:50,722 - INFO  [SyncThread:0:FileTxnLog@218] - Creating new log file: log.1
2022-07-12 17:23:50,728 - INFO  [main-SendThread(127.0.0.1:37769):ClientCnxn$SendThread@1394] - Session establishment complete on server localhost/127.0.0.1:37769, sessionid = 0x100cb920a040000, negotiated timeout = 16000
2022-07-12 17:23:50,733 - INFO  [main:Logging@66] - [ZooKeeperClient Kafka server] Connected.
2022-07-12 17:23:50,809 - INFO  [feature-zk-node-event-process-thread:Logging@66] - [feature-zk-node-event-process-thread]: Starting
2022-07-12 17:23:50,819 - INFO  [feature-zk-node-event-process-thread:Logging@66] - Feature ZK node at path: /feature does not exist
2022-07-12 17:23:50,819 - INFO  [feature-zk-node-event-process-thread:Logging@66] - Cleared cache
2022-07-12 17:23:51,036 - INFO  [main:Logging@66] - Cluster ID = nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:51,039 - WARN  [main:Logging@70] - No meta.properties file under dir /tmp/EmbeddedKafkaCluster7379043744743579021/meta.properties
2022-07-12 17:23:51,090 - INFO  [main:AbstractConfig@372] - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = localhost
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/EmbeddedKafkaCluster7379043744743579021
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 0
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:37769
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000

2022-07-12 17:23:51,101 - INFO  [main:AbstractConfig@372] - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = localhost
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.8-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/EmbeddedKafkaCluster7379043744743579021
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.8-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = -1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 0
	principal.builder.class = null
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:37769
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000

2022-07-12 17:23:51,136 - INFO  [ThrottledChannelReaper-Fetch:Logging@66] - [ThrottledChannelReaper-Fetch]: Starting
2022-07-12 17:23:51,137 - INFO  [ThrottledChannelReaper-Produce:Logging@66] - [ThrottledChannelReaper-Produce]: Starting
2022-07-12 17:23:51,138 - INFO  [ThrottledChannelReaper-Request:Logging@66] - [ThrottledChannelReaper-Request]: Starting
2022-07-12 17:23:51,139 - INFO  [ThrottledChannelReaper-ControllerMutation:Logging@66] - [ThrottledChannelReaper-ControllerMutation]: Starting
2022-07-12 17:23:51,167 - INFO  [main:Logging@66] - Loading logs from log dirs ArraySeq(/tmp/EmbeddedKafkaCluster7379043744743579021)
2022-07-12 17:23:51,169 - INFO  [main:Logging@66] - Attempting recovery for all logs in /tmp/EmbeddedKafkaCluster7379043744743579021 since no clean shutdown file was found
2022-07-12 17:23:51,174 - INFO  [main:Logging@66] - Loaded 0 logs in 0ms.
2022-07-12 17:23:51,175 - INFO  [main:Logging@66] - Starting log cleanup with a period of 300000 ms.
2022-07-12 17:23:51,177 - INFO  [main:Logging@66] - Starting log flusher with a default period of 9223372036854775807 ms.
2022-07-12 17:23:51,543 - INFO  [main:Logging@66] - Updated connection-accept-rate max connection creation rate to 2147483647
2022-07-12 17:23:51,546 - INFO  [main:Logging@66] - Awaiting socket connections on localhost:39653.
2022-07-12 17:23:51,579 - INFO  [main:Logging@66] - [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2022-07-12 17:23:51,606 - INFO  [broker-0-to-controller-send-thread:Logging@66] - [broker-0-to-controller-send-thread]: Starting
2022-07-12 17:23:51,623 - INFO  [ExpirationReaper-0-Produce:Logging@66] - [ExpirationReaper-0-Produce]: Starting
2022-07-12 17:23:51,624 - INFO  [ExpirationReaper-0-Fetch:Logging@66] - [ExpirationReaper-0-Fetch]: Starting
2022-07-12 17:23:51,624 - INFO  [ExpirationReaper-0-DeleteRecords:Logging@66] - [ExpirationReaper-0-DeleteRecords]: Starting
2022-07-12 17:23:51,624 - INFO  [ExpirationReaper-0-ElectLeader:Logging@66] - [ExpirationReaper-0-ElectLeader]: Starting
2022-07-12 17:23:51,635 - INFO  [LogDirFailureHandler:Logging@66] - [LogDirFailureHandler]: Starting
2022-07-12 17:23:51,665 - INFO  [main:Logging@66] - Creating /brokers/ids/0 (is it secure? false)
2022-07-12 17:23:51,681 - INFO  [main:Logging@66] - Stat of the created znode at /brokers/ids/0 is: 25,25,1657661031676,1657661031676,1,0,0,72281422131625984,204,0,25

2022-07-12 17:23:51,682 - INFO  [main:Logging@66] - Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:39653, czxid (broker epoch): 25
2022-07-12 17:23:51,736 - INFO  [ExpirationReaper-0-topic:Logging@66] - [ExpirationReaper-0-topic]: Starting
2022-07-12 17:23:51,741 - INFO  [ExpirationReaper-0-Heartbeat:Logging@66] - [ExpirationReaper-0-Heartbeat]: Starting
2022-07-12 17:23:51,741 - INFO  [ExpirationReaper-0-Rebalance:Logging@66] - [ExpirationReaper-0-Rebalance]: Starting
2022-07-12 17:23:51,742 - INFO  [controller-event-thread:Logging@66] - Successfully created /controller_epoch with initial epoch 0
2022-07-12 17:23:51,836 - INFO  [main-EventThread:Logging@66] - Feature ZK node created at path: /feature
2022-07-12 17:23:51,840 - INFO  [main:Logging@66] - [GroupCoordinator 0]: Starting up.
2022-07-12 17:23:51,843 - INFO  [main:Logging@66] - [GroupCoordinator 0]: Startup complete.
2022-07-12 17:23:51,866 - INFO  [main:Logging@66] - [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2022-07-12 17:23:51,867 - INFO  [main:Logging@66] - [TransactionCoordinator id=0] Starting up.
2022-07-12 17:23:51,868 - INFO  [feature-zk-node-event-process-thread:Logging@66] - Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0).
2022-07-12 17:23:51,869 - INFO  [TxnMarkerSenderThread-0:Logging@66] - [Transaction Marker Channel Manager 0]: Starting
2022-07-12 17:23:51,869 - INFO  [main:Logging@66] - [TransactionCoordinator id=0] Startup complete.
2022-07-12 17:23:51,899 - INFO  [ExpirationReaper-0-AlterAcls:Logging@66] - [ExpirationReaper-0-AlterAcls]: Starting
2022-07-12 17:23:51,922 - INFO  [/config/changes-event-process-thread:Logging@66] - [/config/changes-event-process-thread]: Starting
2022-07-12 17:23:51,929 - INFO  [main:Logging@66] - [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors
2022-07-12 17:23:51,934 - INFO  [main:Logging@66] - [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT)
2022-07-12 17:23:51,934 - INFO  [main:Logging@66] - [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors
2022-07-12 17:23:51,935 - WARN  [main:AppInfoParser@46] - Error while loading kafka-version.properties: null
2022-07-12 17:23:51,936 - INFO  [main:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:51,936 - INFO  [main:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:51,936 - INFO  [main:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661030112
2022-07-12 17:23:51,937 - INFO  [main:Logging@66] - [KafkaServer id=0] started
2022-07-12 17:23:51,945 - INFO  [main:AbstractConfig@372] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:39653]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2022-07-12 17:23:51,961 - INFO  [main:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:51,961 - INFO  [main:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:51,961 - INFO  [main:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661031961
2022-07-12 17:23:51,961 - INFO  [main:EmbeddedConnectCluster@242] - Starting Connect cluster 'connect-cluster' with 1 workers
2022-07-12 17:23:51,965 - INFO  [main:ConnectDistributed@92] - Scanning for plugin classes. This might take a moment ...
2022-07-12 17:23:51,993 - INFO  [kafka-producer-network-thread | producer-1:Metadata@279] - [Producer clientId=producer-1] Cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:51,996 - WARN  [org.reflections-scanner-3:DelegatingClassLoader$InternalReflections@453] - could not create Vfs.Dir from url. ignoring the exception and continuing
org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/home/tonypan/flaky-reproduction/systems/kafka-10340/core/build/classes/java/test]
either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:114)
	at org.reflections.vfs.Vfs.fromURL(Vfs.java:96)
	at org.reflections.Reflections.scan(Reflections.java:257)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.scan(DelegatingClassLoader.java:449)
	at org.reflections.Reflections.lambda$scan$0(Reflections.java:213)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2022-07-12 17:23:52,029 - INFO  [broker-0-to-controller-send-thread:Logging@66] - [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker localhost:39653 (id: 0 rack: null)
2022-07-12 17:23:52,960 - INFO  [main:Reflections@239] - Reflections took 955 ms to scan 134 urls, producing 5582 keys and 18521 values [using 20 cores]
2022-07-12 17:23:52,981 - WARN  [main:ReflectionUtils@318] - could not get type for name org.rocksdb.Options from any class loader
org.reflections.ReflectionsException: could not get type for name org.rocksdb.Options
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.rocksdb.Options
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:52,992 - WARN  [main:ReflectionUtils@318] - could not get type for name org.mockito.internal.creation.bytebuddy.inject.MockMethodDispatcher from any class loader
org.reflections.ReflectionsException: could not get type for name org.mockito.internal.creation.bytebuddy.inject.MockMethodDispatcher
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.mockito.internal.creation.bytebuddy.inject.MockMethodDispatcher
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,036 - WARN  [main:ReflectionUtils@318] - could not get type for name org.osgi.framework.BundleListener from any class loader
org.reflections.ReflectionsException: could not get type for name org.osgi.framework.BundleListener
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.osgi.framework.BundleListener
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,040 - WARN  [main:ReflectionUtils@318] - could not get type for name org.testng.IInvokedMethodListener from any class loader
org.reflections.ReflectionsException: could not get type for name org.testng.IInvokedMethodListener
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.testng.IInvokedMethodListener
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,042 - WARN  [main:ReflectionUtils@318] - could not get type for name com.sun.jna.Library from any class loader
org.reflections.ReflectionsException: could not get type for name com.sun.jna.Library
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: com.sun.jna.Library
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,043 - WARN  [main:ReflectionUtils@318] - could not get type for name io.netty.internal.tcnative.CertificateVerifier from any class loader
org.reflections.ReflectionsException: could not get type for name io.netty.internal.tcnative.CertificateVerifier
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: io.netty.internal.tcnative.CertificateVerifier
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,054 - WARN  [main:ReflectionUtils@318] - could not get type for name reactor.blockhound.integration.BlockHoundIntegration from any class loader
org.reflections.ReflectionsException: could not get type for name reactor.blockhound.integration.BlockHoundIntegration
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: reactor.blockhound.integration.BlockHoundIntegration
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,060 - WARN  [main:ReflectionUtils@318] - could not get type for name jline.console.completer.Completer from any class loader
org.reflections.ReflectionsException: could not get type for name jline.console.completer.Completer
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: jline.console.completer.Completer
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,111 - WARN  [main:ReflectionUtils@318] - could not get type for name java.util.concurrent.Flow$Subscriber from any class loader
org.reflections.ReflectionsException: could not get type for name java.util.concurrent.Flow$Subscriber
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: java.util.concurrent.Flow$Subscriber
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,113 - WARN  [main:ReflectionUtils@318] - could not get type for name org.jboss.marshalling.ByteInput from any class loader
org.reflections.ReflectionsException: could not get type for name org.jboss.marshalling.ByteInput
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.jboss.marshalling.ByteInput
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,162 - WARN  [main:ReflectionUtils@318] - could not get type for name java.util.concurrent.Flow$Subscription from any class loader
org.reflections.ReflectionsException: could not get type for name java.util.concurrent.Flow$Subscription
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: java.util.concurrent.Flow$Subscription
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,164 - WARN  [main:ReflectionUtils@318] - could not get type for name org.conscrypt.BufferAllocator from any class loader
org.reflections.ReflectionsException: could not get type for name org.conscrypt.BufferAllocator
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.conscrypt.BufferAllocator
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,172 - WARN  [main:ReflectionUtils@318] - could not get type for name io.netty.internal.tcnative.CertificateCallback from any class loader
org.reflections.ReflectionsException: could not get type for name io.netty.internal.tcnative.CertificateCallback
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: io.netty.internal.tcnative.CertificateCallback
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,232 - WARN  [main:ReflectionUtils@318] - could not get type for name javax.mail.Authenticator from any class loader
org.reflections.ReflectionsException: could not get type for name javax.mail.Authenticator
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: javax.mail.Authenticator
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,238 - WARN  [main:ReflectionUtils@318] - could not get type for name io.netty.internal.tcnative.SniHostNameMatcher from any class loader
org.reflections.ReflectionsException: could not get type for name io.netty.internal.tcnative.SniHostNameMatcher
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: io.netty.internal.tcnative.SniHostNameMatcher
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,262 - WARN  [main:ReflectionUtils@318] - could not get type for name kotlin.jvm.internal.Lambda from any class loader
org.reflections.ReflectionsException: could not get type for name kotlin.jvm.internal.Lambda
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: kotlin.jvm.internal.Lambda
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,277 - WARN  [main:ReflectionUtils@318] - could not get type for name org.eclipse.jetty.alpn.ALPN$ServerProvider from any class loader
org.reflections.ReflectionsException: could not get type for name org.eclipse.jetty.alpn.ALPN$ServerProvider
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.eclipse.jetty.alpn.ALPN$ServerProvider
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,296 - WARN  [main:ReflectionUtils@318] - could not get type for name kotlin.jvm.functions.Function0 from any class loader
org.reflections.ReflectionsException: could not get type for name kotlin.jvm.functions.Function0
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: kotlin.jvm.functions.Function0
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,297 - WARN  [main:ReflectionUtils@318] - could not get type for name org.eclipse.jetty.npn.NextProtoNego$ServerProvider from any class loader
org.reflections.ReflectionsException: could not get type for name org.eclipse.jetty.npn.NextProtoNego$ServerProvider
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.eclipse.jetty.npn.NextProtoNego$ServerProvider
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,316 - WARN  [main:ReflectionUtils@318] - could not get type for name javax.jms.MessageListener from any class loader
org.reflections.ReflectionsException: could not get type for name javax.jms.MessageListener
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: javax.jms.MessageListener
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,320 - WARN  [main:ReflectionUtils@318] - could not get type for name org.apache.logging.log4j.spi.ExtendedLoggerWrapper from any class loader
org.reflections.ReflectionsException: could not get type for name org.apache.logging.log4j.spi.ExtendedLoggerWrapper
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.apache.logging.log4j.spi.ExtendedLoggerWrapper
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,330 - WARN  [main:ReflectionUtils@318] - could not get type for name org.apache.tools.ant.Task from any class loader
org.reflections.ReflectionsException: could not get type for name org.apache.tools.ant.Task
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.apache.tools.ant.Task
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,331 - WARN  [main:ReflectionUtils@318] - could not get type for name org.rocksdb.BlockBasedTableConfig from any class loader
org.reflections.ReflectionsException: could not get type for name org.rocksdb.BlockBasedTableConfig
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.rocksdb.BlockBasedTableConfig
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,346 - WARN  [main:ReflectionUtils@318] - could not get type for name org.eclipse.jetty.jmx.ObjectMBean from any class loader
org.reflections.ReflectionsException: could not get type for name org.eclipse.jetty.jmx.ObjectMBean
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.eclipse.jetty.jmx.ObjectMBean
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,352 - WARN  [main:ReflectionUtils@318] - could not get type for name org.eclipse.jetty.alpn.ALPN$ClientProvider from any class loader
org.reflections.ReflectionsException: could not get type for name org.eclipse.jetty.alpn.ALPN$ClientProvider
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.eclipse.jetty.alpn.ALPN$ClientProvider
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,373 - WARN  [main:ReflectionUtils@318] - could not get type for name org.conscrypt.HandshakeListener from any class loader
org.reflections.ReflectionsException: could not get type for name org.conscrypt.HandshakeListener
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.conscrypt.HandshakeListener
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,425 - WARN  [main:ReflectionUtils@318] - could not get type for name io.netty.internal.tcnative.SSLPrivateKeyMethod from any class loader
org.reflections.ReflectionsException: could not get type for name io.netty.internal.tcnative.SSLPrivateKeyMethod
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: io.netty.internal.tcnative.SSLPrivateKeyMethod
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,435 - WARN  [main:ReflectionUtils@318] - could not get type for name org.osgi.framework.BundleActivator from any class loader
org.reflections.ReflectionsException: could not get type for name org.osgi.framework.BundleActivator
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.osgi.framework.BundleActivator
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,469 - WARN  [main:ReflectionUtils@318] - could not get type for name com.sun.jna.win32.StdCallLibrary from any class loader
org.reflections.ReflectionsException: could not get type for name com.sun.jna.win32.StdCallLibrary
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: com.sun.jna.win32.StdCallLibrary
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,486 - WARN  [main:ReflectionUtils@318] - could not get type for name org.jboss.marshalling.ByteOutput from any class loader
org.reflections.ReflectionsException: could not get type for name org.jboss.marshalling.ByteOutput
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.jboss.marshalling.ByteOutput
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,502 - WARN  [main:ReflectionUtils@318] - could not get type for name com.sun.jna.Structure from any class loader
org.reflections.ReflectionsException: could not get type for name com.sun.jna.Structure
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: com.sun.jna.Structure
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,511 - WARN  [main:ReflectionUtils@318] - could not get type for name org.osgi.framework.SynchronousBundleListener from any class loader
org.reflections.ReflectionsException: could not get type for name org.osgi.framework.SynchronousBundleListener
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.osgi.framework.SynchronousBundleListener
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,527 - WARN  [main:ReflectionUtils@318] - could not get type for name org.jline.reader.Completer from any class loader
org.reflections.ReflectionsException: could not get type for name org.jline.reader.Completer
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.jline.reader.Completer
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,537 - WARN  [main:ReflectionUtils@318] - could not get type for name org.eclipse.jetty.npn.NextProtoNego$ClientProvider from any class loader
org.reflections.ReflectionsException: could not get type for name org.eclipse.jetty.npn.NextProtoNego$ClientProvider
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.eclipse.jetty.npn.NextProtoNego$ClientProvider
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,546 - WARN  [main:ReflectionUtils@318] - could not get type for name org.junit.jupiter.params.provider.ArgumentsProvider from any class loader
org.reflections.ReflectionsException: could not get type for name org.junit.jupiter.params.provider.ArgumentsProvider
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.junit.jupiter.params.provider.ArgumentsProvider
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,557 - WARN  [main:ReflectionUtils@318] - could not get type for name org.conscrypt.AllocatedBuffer from any class loader
org.reflections.ReflectionsException: could not get type for name org.conscrypt.AllocatedBuffer
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:312)
	at org.reflections.Reflections.expandSuperTypes(Reflections.java:382)
	at org.reflections.Reflections.<init>(Reflections.java:140)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader$InternalReflections.<init>(DelegatingClassLoader.java:441)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:331)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:268)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:216)
	at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:209)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61)
	at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:93)
	at org.apache.kafka.connect.util.clusters.WorkerHandle.start(WorkerHandle.java:50)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker(EmbeddedConnectCluster.java:174)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect(EmbeddedConnectCluster.java:260)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.start(EmbeddedConnectCluster.java:141)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:301)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
Caused by: java.lang.ClassNotFoundException: org.conscrypt.AllocatedBuffer
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.reflections.ReflectionUtils.forName(ReflectionUtils.java:310)
	... 50 more
2022-07-12 17:23:53,609 - INFO  [main:DelegatingClassLoader@269] - Registered loader: sun.misc.Launcher$AppClassLoader@3fee733d
2022-07-12 17:23:53,610 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$ConfigBlockingConnector'
2022-07-12 17:23:53,610 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector'
2022-07-12 17:23:53,610 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector'
2022-07-12 17:23:53,610 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector'
2022-07-12 17:23:53,610 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.WorkerWithTopicCreationTest$WorkerTestConnector'
2022-07-12 17:23:53,610 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$BlockingSinkConnector'
2022-07-12 17:23:53,610 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$BlockingConnector'
2022-07-12 17:23:53,610 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.TestSourceConnector'
2022-07-12 17:23:53,610 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.integration.MonitorableSourceConnector'
2022-07-12 17:23:53,610 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$TaskInitializeBlockingSourceConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$ValidateBlockingConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$BlockingSourceConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$InitializeBlockingConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.integration.ErrantRecordSinkConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.integration.MonitorableSinkConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.TestSinkConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$TaskInitializeBlockingSinkConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector'
2022-07-12 17:23:53,611 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.WorkerTest$WorkerTestConnector'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.tools.MockConnector'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResourceTest$ConnectorPluginsResourceTestConnector'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.converters.FloatConverter'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.ErrorHandlingTaskTest$FaultyConverter'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.isolation.PluginsTest$TestInternalConverter'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.converters.LongConverter'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.converters.IntegerConverter'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.WorkerTest$TestConfigurableConverter'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.WorkerWithTopicCreationTest$TestConfigurableConverter'
2022-07-12 17:23:53,612 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.isolation.PluginsTest$TestConverter'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.WorkerTest$TestConverter'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.WorkerWithTopicCreationTest$TestConverter'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.converters.DoubleConverter'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.json.JsonConverter'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.storage.StringConverter'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.TestConverterWithHeaders'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.converters.ShortConverter'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.ErrorHandlingTaskWithTopicCreationTest$FaultyConverter'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.isolation.PluginsTest$TestHeaderConverter'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformationTest$1TestTransformation'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key'
2022-07-12 17:23:53,613 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.Filter'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.ConnectorConfigTest$AbstractKeyValueTransformation$Key'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.ConnectorConfigTest$HasDuplicateConfigTransformation'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.AbstractHerderTest$SampleTransformation'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.integration.ErrorHandlingIntegrationTest$FaultyPassthrough'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.ErrorHandlingTaskTest$FaultyPassthrough'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.RegexRouter'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.ValueToKey'
2022-07-12 17:23:53,614 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key'
2022-07-12 17:23:53,615 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.ErrorHandlingTaskWithTopicCreationTest$FaultyPassthrough'
2022-07-12 17:23:53,615 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.Cast$Key'
2022-07-12 17:23:53,615 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.Cast$Value'
2022-07-12 17:23:53,615 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation'
2022-07-12 17:23:53,615 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key'
2022-07-12 17:23:53,615 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.ConnectorConfigTest$SimpleTransformation'
2022-07-12 17:23:53,615 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value'
2022-07-12 17:23:53,615 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key'
2022-07-12 17:23:53,615 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key'
2022-07-12 17:23:53,615 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key'
2022-07-12 17:23:53,615 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value'
2022-07-12 17:23:53,615 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.ConnectorConfigTest$AbstractKeyValueTransformation$Value'
2022-07-12 17:23:53,616 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value'
2022-07-12 17:23:53,616 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key'
2022-07-12 17:23:53,616 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.ConnectorConfigTest$TestPredicate'
2022-07-12 17:23:53,616 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey'
2022-07-12 17:23:53,616 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformationTest$1TestPredicate'
2022-07-12 17:23:53,616 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone'
2022-07-12 17:23:53,616 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches'
2022-07-12 17:23:53,616 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.AbstractHerderTest$SamplePredicate'
2022-07-12 17:23:53,616 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.runtime.isolation.PluginsTest$TestConnectRestExtension'
2022-07-12 17:23:53,616 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy'
2022-07-12 17:23:53,617 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy'
2022-07-12 17:23:53,617 - INFO  [main:DelegatingClassLoader@198] - Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy'
2022-07-12 17:23:53,621 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector'
2022-07-12 17:23:53,621 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector'
2022-07-12 17:23:53,621 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'BlockingConnector' and 'Blocking' to plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$BlockingConnector'
2022-07-12 17:23:53,621 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'BlockingSinkConnector' and 'BlockingSink' to plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$BlockingSinkConnector'
2022-07-12 17:23:53,621 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'BlockingSourceConnector' and 'BlockingSource' to plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$BlockingSourceConnector'
2022-07-12 17:23:53,622 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'ConfigBlockingConnector' and 'ConfigBlocking' to plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$ConfigBlockingConnector'
2022-07-12 17:23:53,622 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'InitializeBlockingConnector' and 'InitializeBlocking' to plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$InitializeBlockingConnector'
2022-07-12 17:23:53,622 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'TaskInitializeBlockingSinkConnector' and 'TaskInitializeBlockingSink' to plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$TaskInitializeBlockingSinkConnector'
2022-07-12 17:23:53,622 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'TaskInitializeBlockingSourceConnector' and 'TaskInitializeBlockingSource' to plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$TaskInitializeBlockingSourceConnector'
2022-07-12 17:23:53,622 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'ValidateBlockingConnector' and 'ValidateBlocking' to plugin 'org.apache.kafka.connect.integration.BlockingConnectorTest$ValidateBlockingConnector'
2022-07-12 17:23:53,622 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'ErrantRecordSinkConnector' and 'ErrantRecordSink' to plugin 'org.apache.kafka.connect.integration.ErrantRecordSinkConnector'
2022-07-12 17:23:53,622 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'MonitorableSinkConnector' and 'MonitorableSink' to plugin 'org.apache.kafka.connect.integration.MonitorableSinkConnector'
2022-07-12 17:23:53,622 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'MonitorableSourceConnector' and 'MonitorableSource' to plugin 'org.apache.kafka.connect.integration.MonitorableSourceConnector'
2022-07-12 17:23:53,623 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector'
2022-07-12 17:23:53,623 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector'
2022-07-12 17:23:53,623 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector'
2022-07-12 17:23:53,623 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'TestSinkConnector' and 'TestSink' to plugin 'org.apache.kafka.connect.runtime.TestSinkConnector'
2022-07-12 17:23:53,623 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'TestSourceConnector' and 'TestSource' to plugin 'org.apache.kafka.connect.runtime.TestSourceConnector'
2022-07-12 17:23:53,623 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'ConnectorPluginsResourceTestConnector' and 'ConnectorPluginsResourceTest' to plugin 'org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResourceTest$ConnectorPluginsResourceTestConnector'
2022-07-12 17:23:53,623 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector'
2022-07-12 17:23:53,623 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector'
2022-07-12 17:23:53,623 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector'
2022-07-12 17:23:53,623 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector'
2022-07-12 17:23:53,624 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector'
2022-07-12 17:23:53,624 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector'
2022-07-12 17:23:53,625 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter'
2022-07-12 17:23:53,626 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter'
2022-07-12 17:23:53,626 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter'
2022-07-12 17:23:53,626 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter'
2022-07-12 17:23:53,626 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter'
2022-07-12 17:23:53,626 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter'
2022-07-12 17:23:53,626 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter'
2022-07-12 17:23:53,626 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'TestInternalConverter' and 'TestInternal' to plugin 'org.apache.kafka.connect.runtime.isolation.PluginsTest$TestInternalConverter'
2022-07-12 17:23:53,626 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter'
2022-07-12 17:23:53,626 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter'
2022-07-12 17:23:53,627 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter'
2022-07-12 17:23:53,627 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter'
2022-07-12 17:23:53,627 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter'
2022-07-12 17:23:53,627 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter'
2022-07-12 17:23:53,627 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter'
2022-07-12 17:23:53,627 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter'
2022-07-12 17:23:53,627 - INFO  [main:DelegatingClassLoader@424] - Added alias 'TestHeaderConverter' to plugin 'org.apache.kafka.connect.runtime.isolation.PluginsTest$TestHeaderConverter'
2022-07-12 17:23:53,627 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'TestInternalConverter' and 'TestInternal' to plugin 'org.apache.kafka.connect.runtime.isolation.PluginsTest$TestInternalConverter'
2022-07-12 17:23:53,627 - INFO  [main:DelegatingClassLoader@424] - Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter'
2022-07-12 17:23:53,627 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter'
2022-07-12 17:23:53,630 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'SampleTransformation' and 'Sample' to plugin 'org.apache.kafka.connect.runtime.AbstractHerderTest$SampleTransformation'
2022-07-12 17:23:53,630 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'HasDuplicateConfigTransformation' and 'HasDuplicateConfig' to plugin 'org.apache.kafka.connect.runtime.ConnectorConfigTest$HasDuplicateConfigTransformation'
2022-07-12 17:23:53,631 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'SimpleTransformation' and 'Simple' to plugin 'org.apache.kafka.connect.runtime.ConnectorConfigTest$SimpleTransformation'
2022-07-12 17:23:53,631 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation'
2022-07-12 17:23:53,631 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'TestTransformation' and 'Test' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformationTest$1TestTransformation'
2022-07-12 17:23:53,632 - INFO  [main:DelegatingClassLoader@424] - Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter'
2022-07-12 17:23:53,632 - INFO  [main:DelegatingClassLoader@424] - Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter'
2022-07-12 17:23:53,632 - INFO  [main:DelegatingClassLoader@424] - Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter'
2022-07-12 17:23:53,633 - INFO  [main:DelegatingClassLoader@424] - Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey'
2022-07-12 17:23:53,633 - INFO  [main:DelegatingClassLoader@424] - Added alias 'SamplePredicate' to plugin 'org.apache.kafka.connect.runtime.AbstractHerderTest$SamplePredicate'
2022-07-12 17:23:53,633 - INFO  [main:DelegatingClassLoader@424] - Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey'
2022-07-12 17:23:53,633 - INFO  [main:DelegatingClassLoader@424] - Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone'
2022-07-12 17:23:53,633 - INFO  [main:DelegatingClassLoader@424] - Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches'
2022-07-12 17:23:53,633 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'TestConnectRestExtension' and 'Test' to plugin 'org.apache.kafka.connect.runtime.isolation.PluginsTest$TestConnectRestExtension'
2022-07-12 17:23:53,633 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy'
2022-07-12 17:23:53,633 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy'
2022-07-12 17:23:53,633 - INFO  [main:DelegatingClassLoader@427] - Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy'
2022-07-12 17:23:53,661 - INFO  [main:AbstractConfig@372] - DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-config-topic-connect-cluster
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	group.id = connect-integration-test-connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 30000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offset-topic-connect-cluster
	plugin.path = null
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = localhost
	rest.port = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-storage-topic-connect-cluster
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.storage.StringConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000

2022-07-12 17:23:53,661 - WARN  [main:WorkerConfig@423] - Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results.
2022-07-12 17:23:53,663 - INFO  [main:ConnectUtils@49] - Creating Kafka admin client
2022-07-12 17:23:53,664 - INFO  [main:AbstractConfig@372] - AdminClientConfig values: 
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-12 17:23:53,681 - WARN  [main:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:53,681 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,682 - WARN  [main:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:53,682 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,682 - WARN  [main:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:53,682 - WARN  [main:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:53,682 - WARN  [main:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:53,682 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,682 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,682 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,682 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,682 - WARN  [main:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,682 - WARN  [main:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,682 - INFO  [main:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:53,682 - INFO  [main:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:53,682 - INFO  [main:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661033682
2022-07-12 17:23:53,696 - INFO  [main:ConnectUtils@65] - Kafka cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:53,697 - INFO  [kafka-admin-client-thread | adminclient-1:AppInfoParser@83] - App info kafka.admin.client for adminclient-1 unregistered
2022-07-12 17:23:53,700 - INFO  [kafka-admin-client-thread | adminclient-1:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:53,700 - INFO  [kafka-admin-client-thread | adminclient-1:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:53,700 - INFO  [kafka-admin-client-thread | adminclient-1:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:53,717 - INFO  [main:Log@169] - Logging initialized @3971ms to org.eclipse.jetty.util.log.Slf4jLog
2022-07-12 17:23:53,773 - INFO  [main:RestServer@133] - Added connector for http://localhost:0
2022-07-12 17:23:53,773 - INFO  [main:RestServer@205] - Initializing REST server
2022-07-12 17:23:53,781 - INFO  [main:Server@375] - jetty-9.4.36.v20210114; built: 2021-01-14T16:44:28.689Z; git: 238ec6997c7806b055319a6d11f8ae7564adc0de; jvm 1.8.0_275-8u275-b01-0ubuntu1~18.04-b01
2022-07-12 17:23:53,806 - INFO  [main:AbstractConnector@331] - Started http_localhost0@9fec931{HTTP/1.1, (http/1.1)}{localhost:38783}
2022-07-12 17:23:53,807 - INFO  [main:Server@415] - Started @4061ms
2022-07-12 17:23:53,832 - INFO  [main:RestServer@372] - Advertised URI: http://localhost:38783/
2022-07-12 17:23:53,832 - INFO  [main:RestServer@220] - REST server listening at http://localhost:38783/, advertising URL http://localhost:38783/
2022-07-12 17:23:53,832 - INFO  [main:RestServer@372] - Advertised URI: http://localhost:38783/
2022-07-12 17:23:53,832 - INFO  [main:RestServer@221] - REST admin endpoints at http://localhost:38783/
2022-07-12 17:23:53,832 - INFO  [main:RestServer@372] - Advertised URI: http://localhost:38783/
2022-07-12 17:23:53,835 - INFO  [main:ConnectUtils@49] - Creating Kafka admin client
2022-07-12 17:23:53,835 - INFO  [main:AbstractConfig@372] - AdminClientConfig values: 
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-12 17:23:53,837 - WARN  [main:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:53,837 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,837 - WARN  [main:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:53,837 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,837 - WARN  [main:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:53,838 - WARN  [main:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:53,838 - WARN  [main:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:53,838 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,838 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,838 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,838 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,838 - WARN  [main:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,838 - WARN  [main:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,838 - INFO  [main:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:53,838 - INFO  [main:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:53,838 - INFO  [main:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661033838
2022-07-12 17:23:53,848 - INFO  [main:ConnectUtils@65] - Kafka cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:53,849 - INFO  [kafka-admin-client-thread | adminclient-2:AppInfoParser@83] - App info kafka.admin.client for adminclient-2 unregistered
2022-07-12 17:23:53,850 - INFO  [kafka-admin-client-thread | adminclient-2:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:53,850 - INFO  [kafka-admin-client-thread | adminclient-2:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:53,850 - INFO  [kafka-admin-client-thread | adminclient-2:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:53,853 - INFO  [main:AllConnectorClientConfigOverridePolicy@44] - Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden
2022-07-12 17:23:53,854 - INFO  [main:ConnectUtils@49] - Creating Kafka admin client
2022-07-12 17:23:53,855 - INFO  [main:AbstractConfig@372] - AdminClientConfig values: 
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-12 17:23:53,856 - WARN  [main:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:53,856 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,856 - WARN  [main:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:53,856 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,856 - WARN  [main:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:53,856 - WARN  [main:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:53,857 - WARN  [main:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:53,857 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,857 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,857 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,857 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,857 - WARN  [main:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,857 - WARN  [main:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,857 - INFO  [main:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:53,857 - INFO  [main:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:53,857 - INFO  [main:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661033857
2022-07-12 17:23:53,864 - INFO  [main:ConnectUtils@65] - Kafka cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:53,865 - INFO  [kafka-admin-client-thread | adminclient-3:AppInfoParser@83] - App info kafka.admin.client for adminclient-3 unregistered
2022-07-12 17:23:53,866 - INFO  [kafka-admin-client-thread | adminclient-3:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:53,866 - INFO  [kafka-admin-client-thread | adminclient-3:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:53,866 - INFO  [kafka-admin-client-thread | adminclient-3:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:53,868 - INFO  [main:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:53,868 - INFO  [main:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:53,868 - INFO  [main:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661033868
2022-07-12 17:23:53,881 - INFO  [main:AbstractConfig@372] - JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false

2022-07-12 17:23:53,882 - INFO  [main:AbstractConfig@372] - JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false

2022-07-12 17:23:53,882 - INFO  [main:ConnectUtils@49] - Creating Kafka admin client
2022-07-12 17:23:53,882 - INFO  [main:AbstractConfig@372] - AdminClientConfig values: 
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-12 17:23:53,884 - WARN  [main:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:53,884 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,884 - WARN  [main:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:53,884 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,884 - WARN  [main:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:53,884 - WARN  [main:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:53,884 - WARN  [main:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:53,885 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,885 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,885 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,885 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,885 - WARN  [main:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,885 - WARN  [main:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,885 - INFO  [main:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:53,885 - INFO  [main:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:53,885 - INFO  [main:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661033885
2022-07-12 17:23:53,894 - INFO  [main:ConnectUtils@65] - Kafka cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:53,894 - INFO  [kafka-admin-client-thread | adminclient-4:AppInfoParser@83] - App info kafka.admin.client for adminclient-4 unregistered
2022-07-12 17:23:53,895 - INFO  [kafka-admin-client-thread | adminclient-4:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:53,895 - INFO  [kafka-admin-client-thread | adminclient-4:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:53,895 - INFO  [kafka-admin-client-thread | adminclient-4:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:53,902 - INFO  [main:ConnectUtils@49] - Creating Kafka admin client
2022-07-12 17:23:53,902 - INFO  [main:AbstractConfig@372] - AdminClientConfig values: 
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-12 17:23:53,903 - WARN  [main:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:53,903 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,903 - WARN  [main:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:53,903 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,903 - WARN  [main:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:53,903 - WARN  [main:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:53,903 - WARN  [main:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:53,904 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,904 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,904 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,904 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,904 - WARN  [main:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,904 - WARN  [main:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,904 - INFO  [main:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:53,904 - INFO  [main:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:53,904 - INFO  [main:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661033904
2022-07-12 17:23:53,912 - INFO  [main:ConnectUtils@65] - Kafka cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:53,912 - INFO  [kafka-admin-client-thread | adminclient-5:AppInfoParser@83] - App info kafka.admin.client for adminclient-5 unregistered
2022-07-12 17:23:53,913 - INFO  [kafka-admin-client-thread | adminclient-5:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:53,913 - INFO  [kafka-admin-client-thread | adminclient-5:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:53,913 - INFO  [kafka-admin-client-thread | adminclient-5:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:53,916 - INFO  [main:ConnectUtils@49] - Creating Kafka admin client
2022-07-12 17:23:53,916 - INFO  [main:AbstractConfig@372] - AdminClientConfig values: 
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,918 - WARN  [main:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,919 - INFO  [main:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:53,919 - INFO  [main:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:53,919 - INFO  [main:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661033919
2022-07-12 17:23:53,925 - INFO  [main:ConnectUtils@65] - Kafka cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:53,925 - INFO  [kafka-admin-client-thread | adminclient-6:AppInfoParser@83] - App info kafka.admin.client for adminclient-6 unregistered
2022-07-12 17:23:53,926 - INFO  [kafka-admin-client-thread | adminclient-6:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:53,926 - INFO  [kafka-admin-client-thread | adminclient-6:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:53,926 - INFO  [kafka-admin-client-thread | adminclient-6:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:53,940 - INFO  [main:ConnectUtils@49] - Creating Kafka admin client
2022-07-12 17:23:53,941 - INFO  [main:AbstractConfig@372] - AdminClientConfig values: 
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-12 17:23:53,942 - WARN  [main:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:53,942 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,943 - WARN  [main:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:53,943 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,943 - WARN  [main:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:53,943 - WARN  [main:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:53,943 - WARN  [main:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:53,943 - WARN  [main:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,943 - WARN  [main:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,943 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,943 - WARN  [main:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,943 - WARN  [main:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,943 - WARN  [main:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,943 - INFO  [main:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:53,943 - INFO  [main:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:53,944 - INFO  [main:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661033943
2022-07-12 17:23:53,950 - INFO  [main:ConnectUtils@65] - Kafka cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:53,950 - INFO  [kafka-admin-client-thread | adminclient-7:AppInfoParser@83] - App info kafka.admin.client for adminclient-7 unregistered
2022-07-12 17:23:53,951 - INFO  [kafka-admin-client-thread | adminclient-7:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:53,951 - INFO  [kafka-admin-client-thread | adminclient-7:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:53,951 - INFO  [kafka-admin-client-thread | adminclient-7:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:53,965 - INFO  [main:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:53,965 - INFO  [main:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:53,965 - INFO  [main:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661033965
2022-07-12 17:23:53,967 - INFO  [main:ConnectDistributed@138] - Kafka Connect distributed worker initialization took 2001ms
2022-07-12 17:23:53,967 - INFO  [main:Connect@51] - Kafka Connect starting
2022-07-12 17:23:53,967 - INFO  [main:RestServer@225] - Initializing REST resources
2022-07-12 17:23:53,967 - INFO  [DistributedHerder-connect-1-1:DistributedHerder@308] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Herder starting
2022-07-12 17:23:53,967 - INFO  [DistributedHerder-connect-1-1:Worker@195] - Worker starting
2022-07-12 17:23:53,967 - INFO  [DistributedHerder-connect-1-1:KafkaOffsetBackingStore@144] - Starting KafkaOffsetBackingStore
2022-07-12 17:23:53,967 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@162] - Starting KafkaBasedLog with topic connect-offset-topic-connect-cluster
2022-07-12 17:23:53,968 - INFO  [DistributedHerder-connect-1-1:AbstractConfig@372] - AdminClientConfig values: 
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-12 17:23:53,969 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:53,969 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,969 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:53,969 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:53,969 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,969 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:53,969 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:53,969 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:53,969 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,970 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:53,970 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,970 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:53,970 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:53,970 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,970 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:53,970 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:53,970 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:53,970 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661033970
2022-07-12 17:23:54,006 - INFO  [data-plane-kafka-request-handler-5:Logging@66] - Creating topic connect-offset-topic-connect-cluster with configuration {cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 23 -> ArrayBuffer(0), 24 -> ArrayBuffer(0))
2022-07-12 17:23:54,011 - INFO  [main:RestServer@242] - Adding admin resources to main listener
2022-07-12 17:23:54,098 - INFO  [main:DefaultSessionIdManager@334] - DefaultSessionIdManager workerName=node0
2022-07-12 17:23:54,098 - INFO  [main:DefaultSessionIdManager@339] - No SessionScavenger set, using defaults
2022-07-12 17:23:54,099 - INFO  [main:HouseKeeper@132] - node0 Scavenging every 600000ms
2022-07-12 17:23:54,109 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(connect-offset-topic-connect-cluster-24, connect-offset-topic-connect-cluster-13, connect-offset-topic-connect-cluster-4, connect-offset-topic-connect-cluster-6, connect-offset-topic-connect-cluster-9, connect-offset-topic-connect-cluster-2, connect-offset-topic-connect-cluster-22, connect-offset-topic-connect-cluster-8, connect-offset-topic-connect-cluster-15, connect-offset-topic-connect-cluster-10, connect-offset-topic-connect-cluster-7, connect-offset-topic-connect-cluster-3, connect-offset-topic-connect-cluster-23, connect-offset-topic-connect-cluster-11, connect-offset-topic-connect-cluster-5, connect-offset-topic-connect-cluster-21, connect-offset-topic-connect-cluster-0, connect-offset-topic-connect-cluster-17, connect-offset-topic-connect-cluster-20, connect-offset-topic-connect-cluster-12, connect-offset-topic-connect-cluster-14, connect-offset-topic-connect-cluster-19, connect-offset-topic-connect-cluster-18, connect-offset-topic-connect-cluster-16, connect-offset-topic-connect-cluster-1)
2022-07-12 17:23:54,314 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-9, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,317 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-9 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,318 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-9 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-9
2022-07-12 17:23:54,319 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-9 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-9 with initial high watermark 0
2022-07-12 17:23:54,328 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-24, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,329 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-24 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,329 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-24 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-24
2022-07-12 17:23:54,329 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-24 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-24 with initial high watermark 0
2022-07-12 17:23:54,335 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-13, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,336 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-13 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,336 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-13 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-13
2022-07-12 17:23:54,336 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-13 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-13 with initial high watermark 0
2022-07-12 17:23:54,343 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-1, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,344 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-1 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,344 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-1 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-1
2022-07-12 17:23:54,344 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-1 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-1 with initial high watermark 0
2022-07-12 17:23:54,351 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-16, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,352 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-16 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,352 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-16 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-16
2022-07-12 17:23:54,352 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-16 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-16 with initial high watermark 0
2022-07-12 17:23:54,359 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-5, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,360 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-5 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,360 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-5 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-5
2022-07-12 17:23:54,360 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-5 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-5 with initial high watermark 0
2022-07-12 17:23:54,368 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-20, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,368 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-20 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,368 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-20 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-20
2022-07-12 17:23:54,368 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-20 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-20 with initial high watermark 0
2022-07-12 17:23:54,376 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-23, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,377 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-23 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,377 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-23 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-23
2022-07-12 17:23:54,377 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-23 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-23 with initial high watermark 0
2022-07-12 17:23:54,384 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-8, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,385 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-8 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,385 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-8 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-8
2022-07-12 17:23:54,385 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-8 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-8 with initial high watermark 0
2022-07-12 17:23:54,392 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-12, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,393 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-12 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,393 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-12 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-12
2022-07-12 17:23:54,393 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-12 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-12 with initial high watermark 0
2022-07-12 17:23:54,401 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-15, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,401 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-15 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,401 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-15 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-15
2022-07-12 17:23:54,401 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-15 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-15 with initial high watermark 0
2022-07-12 17:23:54,409 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-0, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,410 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-0 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,410 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-0 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-0
2022-07-12 17:23:54,410 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-0 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-0 with initial high watermark 0
2022-07-12 17:23:54,418 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-19, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,419 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-19 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,419 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-19 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-19
2022-07-12 17:23:54,419 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-19 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-19 with initial high watermark 0
2022-07-12 17:23:54,426 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-4, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,427 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-4 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,427 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-4 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-4
2022-07-12 17:23:54,427 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-4 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-4 with initial high watermark 0
2022-07-12 17:23:54,434 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-7, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,434 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-7 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,435 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-7 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-7
2022-07-12 17:23:54,435 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-7 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-7 with initial high watermark 0
2022-07-12 17:23:54,442 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-11, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,443 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-11 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,443 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-11 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-11
2022-07-12 17:23:54,443 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-11 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-11 with initial high watermark 0
2022-07-12 17:23:54,450 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-18, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,451 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-18 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,451 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-18 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-18
2022-07-12 17:23:54,451 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-18 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-18 with initial high watermark 0
2022-07-12 17:23:54,458 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-22, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,459 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-22 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,459 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-22 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-22
2022-07-12 17:23:54,459 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-22 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-22 with initial high watermark 0
2022-07-12 17:23:54,467 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-3, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,467 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-3 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,467 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-3 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-3
2022-07-12 17:23:54,467 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-3 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-3 with initial high watermark 0
2022-07-12 17:23:54,475 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-10, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,475 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-10 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,475 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-10 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-10
2022-07-12 17:23:54,476 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-10 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-10 with initial high watermark 0
2022-07-12 17:23:54,483 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-14, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,484 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-14 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,484 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-14 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-14
2022-07-12 17:23:54,484 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-14 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-14 with initial high watermark 0
2022-07-12 17:23:54,492 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-17, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,492 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-17 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,492 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-17 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-17
2022-07-12 17:23:54,493 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-17 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-17 with initial high watermark 0
2022-07-12 17:23:54,500 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-2, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,500 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-2 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,500 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-2 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-2
2022-07-12 17:23:54,500 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-2 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-2 with initial high watermark 0
2022-07-12 17:23:54,508 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-21, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,509 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-21 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,509 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-21 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-21
2022-07-12 17:23:54,509 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-21 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-21 with initial high watermark 0
2022-07-12 17:23:54,516 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=connect-offset-topic-connect-cluster-6, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,517 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition connect-offset-topic-connect-cluster-6 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-offset-topic-connect-cluster-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,517 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-6 broker=0] No checkpointed highwatermark is found for partition connect-offset-topic-connect-cluster-6
2022-07-12 17:23:54,517 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition connect-offset-topic-connect-cluster-6 broker=0] Log loaded for partition connect-offset-topic-connect-cluster-6 with initial high watermark 0
2022-07-12 17:23:54,544 - INFO  [DistributedHerder-connect-1-1:TopicAdmin@389] - Created topic (name=connect-offset-topic-connect-cluster, numPartitions=25, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:39653
2022-07-12 17:23:54,545 - INFO  [DistributedHerder-connect-1-1:AbstractConfig@372] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:39653]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2022-07-12 17:23:54,547 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:54,547 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,547 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:54,547 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:54,547 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,547 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:54,547 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:54,547 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:54,548 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,548 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:54,548 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,548 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,548 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,548 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:54,548 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:54,548 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:54,548 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:54,548 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661034548
2022-07-12 17:23:54,550 - INFO  [kafka-producer-network-thread | producer-2:Metadata@279] - [Producer clientId=producer-2] Cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:54,554 - INFO  [DistributedHerder-connect-1-1:AbstractConfig@372] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:39653]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-connect-integration-test-connect-cluster-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration-test-connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:54,573 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:54,573 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:54,574 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661034573
2022-07-12 17:23:54,578 - INFO  [DistributedHerder-connect-1-1:Metadata@279] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:54,586 - INFO  [DistributedHerder-connect-1-1:KafkaConsumer@1121] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Subscribed to partition(s): connect-offset-topic-connect-cluster-0, connect-offset-topic-connect-cluster-5, connect-offset-topic-connect-cluster-10, connect-offset-topic-connect-cluster-20, connect-offset-topic-connect-cluster-15, connect-offset-topic-connect-cluster-9, connect-offset-topic-connect-cluster-11, connect-offset-topic-connect-cluster-4, connect-offset-topic-connect-cluster-16, connect-offset-topic-connect-cluster-17, connect-offset-topic-connect-cluster-3, connect-offset-topic-connect-cluster-24, connect-offset-topic-connect-cluster-23, connect-offset-topic-connect-cluster-13, connect-offset-topic-connect-cluster-18, connect-offset-topic-connect-cluster-22, connect-offset-topic-connect-cluster-8, connect-offset-topic-connect-cluster-2, connect-offset-topic-connect-cluster-12, connect-offset-topic-connect-cluster-19, connect-offset-topic-connect-cluster-14, connect-offset-topic-connect-cluster-1, connect-offset-topic-connect-cluster-6, connect-offset-topic-connect-cluster-7, connect-offset-topic-connect-cluster-21
2022-07-12 17:23:54,588 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-0
2022-07-12 17:23:54,588 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-5
2022-07-12 17:23:54,588 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-10
2022-07-12 17:23:54,588 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-20
2022-07-12 17:23:54,588 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-15
2022-07-12 17:23:54,588 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-9
2022-07-12 17:23:54,588 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-11
2022-07-12 17:23:54,588 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-4
2022-07-12 17:23:54,588 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-16
2022-07-12 17:23:54,588 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-17
2022-07-12 17:23:54,588 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-3
2022-07-12 17:23:54,588 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-24
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-23
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-13
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-18
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-22
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-8
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-2
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-12
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-19
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-14
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-1
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-6
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-7
2022-07-12 17:23:54,589 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-offset-topic-connect-cluster-21
2022-07-12 17:23:54,630 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,630 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,631 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,631 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,631 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,631 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,631 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,631 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,631 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,631 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,631 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,631 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,631 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,632 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,632 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,632 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,632 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,632 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,632 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,632 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,632 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,632 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
Jul 12, 2022 5:23:54 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
WARNING: A provider org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource will be ignored. 
2022-07-12 17:23:54,633 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,633 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,633 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-1, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-offset-topic-connect-cluster-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
Jul 12, 2022 5:23:54 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
WARNING: A provider org.apache.kafka.connect.runtime.rest.resources.RootResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider org.apache.kafka.connect.runtime.rest.resources.RootResource will be ignored. 
Jul 12, 2022 5:23:54 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
WARNING: A provider org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource will be ignored. 
2022-07-12 17:23:54,633 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@202] - Finished reading KafkaBasedLog for topic connect-offset-topic-connect-cluster
2022-07-12 17:23:54,633 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@204] - Started KafkaBasedLog for topic connect-offset-topic-connect-cluster
2022-07-12 17:23:54,633 - INFO  [DistributedHerder-connect-1-1:KafkaOffsetBackingStore@146] - Finished reading offsets topic and starting KafkaOffsetBackingStore
Jul 12, 2022 5:23:54 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
WARNING: A provider org.apache.kafka.connect.runtime.rest.resources.LoggingResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider org.apache.kafka.connect.runtime.rest.resources.LoggingResource will be ignored. 
2022-07-12 17:23:54,635 - INFO  [DistributedHerder-connect-1-1:Worker@202] - Worker started
2022-07-12 17:23:54,635 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@162] - Starting KafkaBasedLog with topic connect-storage-topic-connect-cluster
2022-07-12 17:23:54,640 - INFO  [data-plane-kafka-request-handler-2:Logging@66] - Creating topic connect-storage-topic-connect-cluster with configuration {cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2022-07-12 17:23:54,661 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(connect-storage-topic-connect-cluster-4, connect-storage-topic-connect-cluster-1, connect-storage-topic-connect-cluster-3, connect-storage-topic-connect-cluster-2, connect-storage-topic-connect-cluster-0)
2022-07-12 17:23:54,664 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=connect-storage-topic-connect-cluster-4, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,665 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition connect-storage-topic-connect-cluster-4 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-storage-topic-connect-cluster-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,666 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition connect-storage-topic-connect-cluster-4 broker=0] No checkpointed highwatermark is found for partition connect-storage-topic-connect-cluster-4
2022-07-12 17:23:54,667 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition connect-storage-topic-connect-cluster-4 broker=0] Log loaded for partition connect-storage-topic-connect-cluster-4 with initial high watermark 0
2022-07-12 17:23:54,670 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=connect-storage-topic-connect-cluster-3, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,671 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition connect-storage-topic-connect-cluster-3 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-storage-topic-connect-cluster-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,671 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition connect-storage-topic-connect-cluster-3 broker=0] No checkpointed highwatermark is found for partition connect-storage-topic-connect-cluster-3
2022-07-12 17:23:54,671 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition connect-storage-topic-connect-cluster-3 broker=0] Log loaded for partition connect-storage-topic-connect-cluster-3 with initial high watermark 0
2022-07-12 17:23:54,679 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=connect-storage-topic-connect-cluster-2, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,679 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition connect-storage-topic-connect-cluster-2 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-storage-topic-connect-cluster-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,680 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition connect-storage-topic-connect-cluster-2 broker=0] No checkpointed highwatermark is found for partition connect-storage-topic-connect-cluster-2
2022-07-12 17:23:54,680 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition connect-storage-topic-connect-cluster-2 broker=0] Log loaded for partition connect-storage-topic-connect-cluster-2 with initial high watermark 0
2022-07-12 17:23:54,687 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=connect-storage-topic-connect-cluster-1, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,688 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition connect-storage-topic-connect-cluster-1 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-storage-topic-connect-cluster-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,688 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition connect-storage-topic-connect-cluster-1 broker=0] No checkpointed highwatermark is found for partition connect-storage-topic-connect-cluster-1
2022-07-12 17:23:54,688 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition connect-storage-topic-connect-cluster-1 broker=0] Log loaded for partition connect-storage-topic-connect-cluster-1 with initial high watermark 0
2022-07-12 17:23:54,695 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=connect-storage-topic-connect-cluster-0, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,695 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition connect-storage-topic-connect-cluster-0 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-storage-topic-connect-cluster-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,696 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition connect-storage-topic-connect-cluster-0 broker=0] No checkpointed highwatermark is found for partition connect-storage-topic-connect-cluster-0
2022-07-12 17:23:54,696 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition connect-storage-topic-connect-cluster-0 broker=0] Log loaded for partition connect-storage-topic-connect-cluster-0 with initial high watermark 0
2022-07-12 17:23:54,705 - INFO  [DistributedHerder-connect-1-1:TopicAdmin@389] - Created topic (name=connect-storage-topic-connect-cluster, numPartitions=5, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:39653
2022-07-12 17:23:54,706 - INFO  [DistributedHerder-connect-1-1:AbstractConfig@372] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:39653]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2022-07-12 17:23:54,707 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:54,708 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,708 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:54,708 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:54,708 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,708 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:54,708 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:54,708 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:54,708 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,709 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:54,709 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,709 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,709 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,709 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:54,709 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:54,709 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:54,709 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:54,709 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661034709
2022-07-12 17:23:54,710 - INFO  [DistributedHerder-connect-1-1:AbstractConfig@372] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:39653]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-connect-integration-test-connect-cluster-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration-test-connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-07-12 17:23:54,711 - INFO  [kafka-producer-network-thread | producer-3:Metadata@279] - [Producer clientId=producer-3] Cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:54,712 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:54,713 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:54,713 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:54,713 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661034713
2022-07-12 17:23:54,716 - INFO  [DistributedHerder-connect-1-1:Metadata@279] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-2, groupId=connect-integration-test-connect-cluster] Cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:54,717 - INFO  [DistributedHerder-connect-1-1:KafkaConsumer@1121] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-2, groupId=connect-integration-test-connect-cluster] Subscribed to partition(s): connect-storage-topic-connect-cluster-0, connect-storage-topic-connect-cluster-4, connect-storage-topic-connect-cluster-1, connect-storage-topic-connect-cluster-2, connect-storage-topic-connect-cluster-3
2022-07-12 17:23:54,717 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-2, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-storage-topic-connect-cluster-0
2022-07-12 17:23:54,717 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-2, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-storage-topic-connect-cluster-4
2022-07-12 17:23:54,717 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-2, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-storage-topic-connect-cluster-1
2022-07-12 17:23:54,717 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-2, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-storage-topic-connect-cluster-2
2022-07-12 17:23:54,717 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-2, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-storage-topic-connect-cluster-3
2022-07-12 17:23:54,725 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-2, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-storage-topic-connect-cluster-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,725 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-2, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-storage-topic-connect-cluster-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,725 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-2, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-storage-topic-connect-cluster-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,726 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-2, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-storage-topic-connect-cluster-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,726 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-2, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-storage-topic-connect-cluster-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,726 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@202] - Finished reading KafkaBasedLog for topic connect-storage-topic-connect-cluster
2022-07-12 17:23:54,726 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@204] - Started KafkaBasedLog for topic connect-storage-topic-connect-cluster
2022-07-12 17:23:54,727 - INFO  [DistributedHerder-connect-1-1:KafkaConfigBackingStore@275] - Starting KafkaConfigBackingStore
2022-07-12 17:23:54,727 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@162] - Starting KafkaBasedLog with topic connect-config-topic-connect-cluster
2022-07-12 17:23:54,732 - INFO  [data-plane-kafka-request-handler-7:Logging@66] - Creating topic connect-config-topic-connect-cluster with configuration {cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2022-07-12 17:23:54,742 - INFO  [data-plane-kafka-request-handler-2:Logging@66] - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(connect-config-topic-connect-cluster-0)
2022-07-12 17:23:54,744 - INFO  [data-plane-kafka-request-handler-2:Logging@66] - [Log partition=connect-config-topic-connect-cluster-0, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,745 - INFO  [data-plane-kafka-request-handler-2:Logging@66] - Created log for partition connect-config-topic-connect-cluster-0 in /tmp/EmbeddedKafkaCluster7379043744743579021/connect-config-topic-connect-cluster-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,745 - INFO  [data-plane-kafka-request-handler-2:Logging@66] - [Partition connect-config-topic-connect-cluster-0 broker=0] No checkpointed highwatermark is found for partition connect-config-topic-connect-cluster-0
2022-07-12 17:23:54,746 - INFO  [data-plane-kafka-request-handler-2:Logging@66] - [Partition connect-config-topic-connect-cluster-0 broker=0] Log loaded for partition connect-config-topic-connect-cluster-0 with initial high watermark 0
2022-07-12 17:23:54,749 - INFO  [DistributedHerder-connect-1-1:TopicAdmin@389] - Created topic (name=connect-config-topic-connect-cluster, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:39653
2022-07-12 17:23:54,750 - INFO  [DistributedHerder-connect-1-1:AbstractConfig@372] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:39653]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-4
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2022-07-12 17:23:54,753 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:54,753 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,753 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:54,753 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:54,753 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,754 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:54,754 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:54,754 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:54,754 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,754 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:54,754 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,754 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,754 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,754 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:54,754 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:54,755 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:54,755 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:54,755 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661034755
2022-07-12 17:23:54,755 - INFO  [DistributedHerder-connect-1-1:AbstractConfig@372] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:39653]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-connect-integration-test-connect-cluster-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration-test-connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-07-12 17:23:54,756 - INFO  [kafka-producer-network-thread | producer-4:Metadata@279] - [Producer clientId=producer-4] Cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:54,758 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - WARN  [DistributedHerder-connect-1-1:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:54,759 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:54,759 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:54,759 - INFO  [DistributedHerder-connect-1-1:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661034759
2022-07-12 17:23:54,762 - INFO  [DistributedHerder-connect-1-1:Metadata@279] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-3, groupId=connect-integration-test-connect-cluster] Cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:54,763 - INFO  [DistributedHerder-connect-1-1:KafkaConsumer@1121] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-3, groupId=connect-integration-test-connect-cluster] Subscribed to partition(s): connect-config-topic-connect-cluster-0
2022-07-12 17:23:54,763 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@631] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-3, groupId=connect-integration-test-connect-cluster] Seeking to EARLIEST offset of partition connect-config-topic-connect-cluster-0
2022-07-12 17:23:54,768 - INFO  [DistributedHerder-connect-1-1:SubscriptionState@398] - [Consumer clientId=consumer-connect-integration-test-connect-cluster-3, groupId=connect-integration-test-connect-cluster] Resetting offset for partition connect-config-topic-connect-cluster-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39653 (id: 0 rack: null)], epoch=0}}.
2022-07-12 17:23:54,768 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@202] - Finished reading KafkaBasedLog for topic connect-config-topic-connect-cluster
2022-07-12 17:23:54,768 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@204] - Started KafkaBasedLog for topic connect-config-topic-connect-cluster
2022-07-12 17:23:54,769 - INFO  [DistributedHerder-connect-1-1:KafkaConfigBackingStore@290] - Started KafkaConfigBackingStore
2022-07-12 17:23:54,769 - INFO  [DistributedHerder-connect-1-1:DistributedHerder@312] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Herder started
2022-07-12 17:23:54,775 - INFO  [DistributedHerder-connect-1-1:Metadata@279] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:54,779 - INFO  [data-plane-kafka-request-handler-0:Logging@66] - Creating topic __consumer_offsets with configuration {segment.bytes=104857600, cleanup.policy=compact, compression.type=producer} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 23 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 49 -> ArrayBuffer(0))
Jul 12, 2022 5:23:54 PM org.glassfish.jersey.internal.Errors logErrors
WARNING: The following warnings have been detected: WARNING: The (sub)resource method listLoggers in org.apache.kafka.connect.runtime.rest.resources.LoggingResource contains empty path annotation.
WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.

2022-07-12 17:23:54,825 - INFO  [main:ContextHandler@916] - Started o.e.j.s.ServletContextHandler@7f5eae0f{/,null,AVAILABLE}
2022-07-12 17:23:54,825 - INFO  [main:RestServer@320] - REST resources initialized; server is started and ready to handle requests
2022-07-12 17:23:54,825 - INFO  [main:Connect@57] - Kafka Connect started
2022-07-12 17:23:54,825 - INFO  [main:EmbeddedConnectCluster@176] - Started worker WorkerHandle{workerName='connect-worker-0'workerURL='http://localhost:38783/'}
2022-07-12 17:23:54,829 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40)
2022-07-12 17:23:54,834 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-3, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,834 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-3 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,835 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2022-07-12 17:23:54,836 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2022-07-12 17:23:54,839 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-18, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,839 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-18 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,839 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18
2022-07-12 17:23:54,839 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0
2022-07-12 17:23:54,847 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-41, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,848 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-41 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,848 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41
2022-07-12 17:23:54,848 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0
2022-07-12 17:23:54,855 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-10, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,856 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-10 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,856 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10
2022-07-12 17:23:54,856 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0
2022-07-12 17:23:54,864 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-33, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,864 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-33 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,865 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33
2022-07-12 17:23:54,865 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0
2022-07-12 17:23:54,872 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-48, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,873 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-48 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,873 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48
2022-07-12 17:23:54,873 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0
2022-07-12 17:23:54,881 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-19, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,882 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-19 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,882 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19
2022-07-12 17:23:54,882 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0
2022-07-12 17:23:54,889 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-34, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,890 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-34 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,890 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34
2022-07-12 17:23:54,890 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0
2022-07-12 17:23:54,897 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-4, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,898 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-4 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,898 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2022-07-12 17:23:54,898 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2022-07-12 17:23:54,905 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-11, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,906 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-11 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,906 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11
2022-07-12 17:23:54,906 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0
2022-07-12 17:23:54,913 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-26, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,915 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-26 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,915 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26
2022-07-12 17:23:54,915 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0
2022-07-12 17:23:54,922 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-49, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,922 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-49 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,922 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49
2022-07-12 17:23:54,922 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0
2022-07-12 17:23:54,930 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-39, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,930 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-39 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,931 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39
2022-07-12 17:23:54,931 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0
2022-07-12 17:23:54,938 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-9, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,939 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-9 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,939 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9
2022-07-12 17:23:54,939 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0
2022-07-12 17:23:54,946 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-24, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,947 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-24 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,947 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24
2022-07-12 17:23:54,947 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0
2022-07-12 17:23:54,955 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-31, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,956 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-31 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,956 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31
2022-07-12 17:23:54,956 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0
2022-07-12 17:23:54,963 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-46, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,964 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-46 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,964 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46
2022-07-12 17:23:54,964 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0
2022-07-12 17:23:54,972 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-1, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,972 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-1 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,972 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2022-07-12 17:23:54,972 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2022-07-12 17:23:54,980 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-16, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,981 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-16 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,981 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16
2022-07-12 17:23:54,981 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0
2022-07-12 17:23:54,988 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-2, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,988 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-2 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,988 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2022-07-12 17:23:54,988 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2022-07-12 17:23:54,996 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-25, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:54,997 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-25 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:54,997 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25
2022-07-12 17:23:54,997 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0
2022-07-12 17:23:55,005 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-40, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,005 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-40 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,005 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40
2022-07-12 17:23:55,006 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0
2022-07-12 17:23:55,013 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-47, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,014 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-47 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,014 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47
2022-07-12 17:23:55,014 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0
2022-07-12 17:23:55,021 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-17, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,021 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-17 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,022 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17
2022-07-12 17:23:55,022 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0
2022-07-12 17:23:55,030 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-32, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,031 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-32 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,031 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32
2022-07-12 17:23:55,031 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0
2022-07-12 17:23:55,036 - INFO  [main:EmbeddedConnectCluster@696] - GET response for URL=http://localhost:38783/ is {"version":"unknown","commit":"unknown","kafka_cluster_id":"nB904s1USwG7jo_IqFsyWg"}
2022-07-12 17:23:55,039 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-37, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,039 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-37 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,039 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37
2022-07-12 17:23:55,039 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0
2022-07-12 17:23:55,046 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-7, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,046 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-7 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,047 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7
2022-07-12 17:23:55,047 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0
2022-07-12 17:23:55,054 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-22, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,055 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-22 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,055 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22
2022-07-12 17:23:55,055 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0
2022-07-12 17:23:55,070 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-29, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,071 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-29 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,071 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29
2022-07-12 17:23:55,071 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0
2022-07-12 17:23:55,075 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-44, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,076 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-44 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,076 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44
2022-07-12 17:23:55,076 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0
2022-07-12 17:23:55,083 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-14, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,084 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-14 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,084 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14
2022-07-12 17:23:55,084 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0
2022-07-12 17:23:55,091 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-23, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,092 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-23 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,092 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23
2022-07-12 17:23:55,092 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0
2022-07-12 17:23:55,100 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-38, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,101 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-38 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,101 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38
2022-07-12 17:23:55,101 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0
2022-07-12 17:23:55,108 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-8, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,108 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-8 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,109 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8
2022-07-12 17:23:55,109 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0
2022-07-12 17:23:55,116 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-45, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,117 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-45 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,117 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45
2022-07-12 17:23:55,117 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0
2022-07-12 17:23:55,124 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-15, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,125 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-15 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,125 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15
2022-07-12 17:23:55,125 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0
2022-07-12 17:23:55,133 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-30, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,133 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-30 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,133 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30
2022-07-12 17:23:55,133 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0
2022-07-12 17:23:55,141 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-0, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,142 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-0 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,142 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2022-07-12 17:23:55,142 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2022-07-12 17:23:55,149 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-35, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,150 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-35 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,150 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35
2022-07-12 17:23:55,150 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0
2022-07-12 17:23:55,157 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-5, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,158 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-5 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,158 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5
2022-07-12 17:23:55,158 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0
2022-07-12 17:23:55,166 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-20, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,167 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-20 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,167 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20
2022-07-12 17:23:55,167 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0
2022-07-12 17:23:55,174 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-27, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,175 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-27 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,175 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27
2022-07-12 17:23:55,175 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0
2022-07-12 17:23:55,182 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-42, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,183 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-42 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,184 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42
2022-07-12 17:23:55,184 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0
2022-07-12 17:23:55,191 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-12, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,191 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-12 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,191 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12
2022-07-12 17:23:55,191 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0
2022-07-12 17:23:55,199 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-21, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,200 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-21 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,200 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21
2022-07-12 17:23:55,200 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0
2022-07-12 17:23:55,207 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-36, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,208 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-36 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,208 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36
2022-07-12 17:23:55,208 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0
2022-07-12 17:23:55,216 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-6, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,216 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-6 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,216 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6
2022-07-12 17:23:55,216 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0
2022-07-12 17:23:55,224 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-43, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,224 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-43 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,224 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43
2022-07-12 17:23:55,224 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0
2022-07-12 17:23:55,232 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-13, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,233 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-13 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,233 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13
2022-07-12 17:23:55,233 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0
2022-07-12 17:23:55,240 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Log partition=__consumer_offsets-28, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,240 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - Created log for partition __consumer_offsets-28 in /tmp/EmbeddedKafkaCluster7379043744743579021/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,240 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28
2022-07-12 17:23:55,241 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0
2022-07-12 17:23:55,248 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 3
2022-07-12 17:23:55,248 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2022-07-12 17:23:55,249 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 18
2022-07-12 17:23:55,249 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18
2022-07-12 17:23:55,249 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 41
2022-07-12 17:23:55,249 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 10
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 33
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 48
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 19
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 34
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 4
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 11
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 26
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 49
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 39
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39
2022-07-12 17:23:55,250 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 9
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 24
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 31
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 46
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 1
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 16
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 2
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 25
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 40
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 47
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 17
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 32
2022-07-12 17:23:55,251 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 37
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 7
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 22
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 29
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 44
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 14
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 23
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 38
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 8
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 45
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 15
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 30
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30
2022-07-12 17:23:55,252 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 0
2022-07-12 17:23:55,253 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2022-07-12 17:23:55,253 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 35
2022-07-12 17:23:55,253 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35
2022-07-12 17:23:55,253 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 5
2022-07-12 17:23:55,253 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5
2022-07-12 17:23:55,253 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 20
2022-07-12 17:23:55,253 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20
2022-07-12 17:23:55,253 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 27
2022-07-12 17:23:55,253 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27
2022-07-12 17:23:55,253 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 42
2022-07-12 17:23:55,253 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42
2022-07-12 17:23:55,253 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 5 milliseconds, of which 1 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,253 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 12
2022-07-12 17:23:55,254 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12
2022-07-12 17:23:55,254 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 21
2022-07-12 17:23:55,254 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21
2022-07-12 17:23:55,254 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,254 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 36
2022-07-12 17:23:55,254 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36
2022-07-12 17:23:55,254 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 4 milliseconds, of which 4 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,254 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 6
2022-07-12 17:23:55,254 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6
2022-07-12 17:23:55,255 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 5 milliseconds, of which 4 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,255 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 43
2022-07-12 17:23:55,255 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43
2022-07-12 17:23:55,255 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,255 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 13
2022-07-12 17:23:55,255 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13
2022-07-12 17:23:55,255 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,255 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Elected as the group coordinator for partition 28
2022-07-12 17:23:55,255 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28
2022-07-12 17:23:55,255 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,255 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,255 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,255 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,255 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,255 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,256 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,256 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,256 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,256 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,256 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,256 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,256 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,256 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,256 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,256 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,257 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,257 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,257 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,257 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,257 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,257 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,257 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,257 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,257 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,258 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,258 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,258 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,258 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,258 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,258 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,258 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,258 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,258 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,259 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,259 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,259 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 6 milliseconds, of which 6 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,259 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,259 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,259 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,259 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 4 milliseconds, of which 4 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,259 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 4 milliseconds, of which 4 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,259 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 4 milliseconds, of which 4 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,260 - INFO  [group-metadata-manager-0:Logging@66] - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 5 milliseconds, of which 5 milliseconds was spent in the scheduler.
2022-07-12 17:23:55,293 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator$FindCoordinatorResponseHandler@848] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Discovered group coordinator localhost:39653 (id: 2147483647 rack: null)
2022-07-12 17:23:55,295 - INFO  [DistributedHerder-connect-1-1:WorkerCoordinator@221] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Rebalance started
2022-07-12 17:23:55,295 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator@538] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] (Re-)joining group
2022-07-12 17:23:55,308 - INFO  [data-plane-kafka-request-handler-2:Logging@66] - [GroupCoordinator 0]: Dynamic member with unknown member id joins group connect-integration-test-connect-cluster in Empty state. Created a new member id connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e and request the member to rejoin with this id.
2022-07-12 17:23:55,312 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator@538] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] (Re-)joining group
2022-07-12 17:23:55,317 - INFO  [data-plane-kafka-request-handler-0:Logging@66] - [GroupCoordinator 0]: Preparing to rebalance group connect-integration-test-connect-cluster in state PreparingRebalance with old generation 0 (__consumer_offsets-8) (reason: Adding new member connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e with group instance id None)
2022-07-12 17:23:55,321 - INFO  [executor-Rebalance:Logging@66] - [GroupCoordinator 0]: Stabilized group connect-integration-test-connect-cluster generation 1 (__consumer_offsets-8)
2022-07-12 17:23:55,323 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator$JoinGroupResponseHandler@594] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Successfully joined group with generation Generation{generationId=1, memberId='connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e', protocol='sessioned'}
2022-07-12 17:23:55,336 - INFO  [data-plane-kafka-request-handler-1:Logging@66] - [GroupCoordinator 0]: Assignment received from leader for group connect-integration-test-connect-cluster for generation 1
2022-07-12 17:23:55,374 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator$SyncGroupResponseHandler@758] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Successfully synced group in generation Generation{generationId=1, memberId='connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e', protocol='sessioned'}
2022-07-12 17:23:55,374 - INFO  [DistributedHerder-connect-1-1:DistributedHerder$RebalanceListener@1683] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e', leaderUrl='http://localhost:38783/', offset=-1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0
2022-07-12 17:23:55,375 - INFO  [DistributedHerder-connect-1-1:DistributedHerder@1234] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Starting connectors and tasks using config offset -1
2022-07-12 17:23:55,375 - INFO  [DistributedHerder-connect-1-1:DistributedHerder@1262] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Finished starting connectors and tasks
2022-07-12 17:23:55,402 - INFO  [KafkaBasedLog Work Thread - connect-config-topic-connect-cluster:DistributedHerder$ConfigUpdateListener@1572] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Session key updated
2022-07-12 17:23:55,408 - INFO  [pool-9-thread-1:MonitorableSourceConnector@88] - Configured MonitorableSourceConnector connector null
2022-07-12 17:23:55,408 - INFO  [pool-9-thread-1:MonitorableSourceConnector@88] - Configured MonitorableSourceConnector connector null
2022-07-12 17:23:55,409 - INFO  [pool-9-thread-1:AbstractConfig@372] - AbstractConfig values: 

2022-07-12 17:23:55,416 - INFO  [KafkaBasedLog Work Thread - connect-config-topic-connect-cluster:DistributedHerder$ConfigUpdateListener@1528] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Connector simple-source config updated
2022-07-12 17:23:55,417 - INFO  [DistributedHerder-connect-1-1:WorkerCoordinator@221] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Rebalance started
2022-07-12 17:23:55,417 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator@538] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] (Re-)joining group
2022-07-12 17:23:55,419 - INFO  [data-plane-kafka-request-handler-4:Logging@66] - [GroupCoordinator 0]: Preparing to rebalance group connect-integration-test-connect-cluster in state PreparingRebalance with old generation 1 (__consumer_offsets-8) (reason: leader connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e re-joining group during Stable)
2022-07-12 17:23:55,420 - INFO  [data-plane-kafka-request-handler-4:Logging@66] - [GroupCoordinator 0]: Stabilized group connect-integration-test-connect-cluster generation 2 (__consumer_offsets-8)
2022-07-12 17:23:55,421 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator$JoinGroupResponseHandler@594] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Successfully joined group with generation Generation{generationId=2, memberId='connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e', protocol='sessioned'}
2022-07-12 17:23:55,424 - INFO  [data-plane-kafka-request-handler-6:Logging@66] - [GroupCoordinator 0]: Assignment received from leader for group connect-integration-test-connect-cluster for generation 2
2022-07-12 17:23:55,424 - INFO  [main:EmbeddedConnectCluster@696] - PUT response for URL=http://localhost:38783/connectors/simple-source/config is {"name":"simple-source","config":{"connector.class":"MonitorableSourceConnector","messages.per.poll":"10","topic.creation.default.partitions":"1","tasks.max":"4","topic.creation.default.replication.factor":"1","topic":"nonexistenttopic","throughput":"10","value.converter":"org.apache.kafka.connect.storage.StringConverter","key.converter":"org.apache.kafka.connect.storage.StringConverter","name":"simple-source"},"tasks":[],"type":"source"}
2022-07-12 17:23:55,426 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator$SyncGroupResponseHandler@758] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Successfully synced group in generation Generation{generationId=2, memberId='connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e', protocol='sessioned'}
2022-07-12 17:23:55,426 - INFO  [DistributedHerder-connect-1-1:DistributedHerder$RebalanceListener@1683] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Joined group at generation 2 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e', leaderUrl='http://localhost:38783/', offset=2, connectorIds=[simple-source], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0
2022-07-12 17:23:55,426 - INFO  [DistributedHerder-connect-1-1:DistributedHerder@1234] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Starting connectors and tasks using config offset 2
2022-07-12 17:23:55,427 - INFO  [StartAndStopExecutor-connect-1-1:DistributedHerder@1311] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Starting connector simple-source
2022-07-12 17:23:55,429 - INFO  [StartAndStopExecutor-connect-1-1:Worker@274] - Creating connector simple-source of type MonitorableSourceConnector
2022-07-12 17:23:55,429 - INFO  [StartAndStopExecutor-connect-1-1:AbstractConfig@372] - SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,429 - INFO  [StartAndStopExecutor-connect-1-1:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,432 - INFO  [StartAndStopExecutor-connect-1-1:AbstractConfig@372] - EnrichedSourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = 1
	topic.creation.default.replication.factor = 1
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,432 - INFO  [StartAndStopExecutor-connect-1-1:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = 1
	topic.creation.default.replication.factor = 1
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,435 - INFO  [StartAndStopExecutor-connect-1-1:Worker@284] - Instantiated connector simple-source with version an entirely different version of type class org.apache.kafka.connect.integration.MonitorableSourceConnector
2022-07-12 17:23:55,435 - INFO  [StartAndStopExecutor-connect-1-1:Worker@310] - Finished creating connector simple-source
2022-07-12 17:23:55,436 - INFO  [DistributedHerder-connect-1-1:DistributedHerder@1262] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Finished starting connectors and tasks
2022-07-12 17:23:55,437 - INFO  [connector-thread-simple-source:MonitorableSourceConnector@59] - Started MonitorableSourceConnector connector simple-source
2022-07-12 17:23:55,439 - INFO  [main:EmbeddedConnectCluster@696] - GET response for URL=http://localhost:38783/connectors/simple-source/status is {"error_code":404,"message":"No status found for connector simple-source"}
2022-07-12 17:23:55,440 - ERROR [main:EmbeddedConnectClusterAssertions@420] - Could not check connector state info.
org.apache.kafka.connect.runtime.rest.errors.ConnectRestException: Could not read connector state. Error response: {"error_code":404,"message":"No status found for connector simple-source"}
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.connectorStatus(EmbeddedConnectCluster.java:466)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.checkConnectorState(EmbeddedConnectClusterAssertions.java:413)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.lambda$assertConnectorAndExactlyNumTasksAreRunning$18(EmbeddedConnectClusterAssertions.java:312)
	at org.apache.kafka.test.TestUtils.lambda$waitForCondition$3(TestUtils.java:303)
	at org.apache.kafka.test.TestUtils.retryOnExceptionWithTimeout(TestUtils.java:351)
	at org.apache.kafka.test.TestUtils.retryOnExceptionWithTimeout(TestUtils.java:319)
	at org.apache.kafka.test.TestUtils.waitForCondition(TestUtils.java:300)
	at org.apache.kafka.test.TestUtils.waitForCondition(TestUtils.java:290)
	at org.apache.kafka.connect.util.clusters.EmbeddedConnectClusterAssertions.assertConnectorAndExactlyNumTasksAreRunning(EmbeddedConnectClusterAssertions.java:311)
	at org.apache.kafka.connect.integration.ConnectWorkerIntegrationTest.testSourceTaskNotBlockedOnShutdownWithNonExistentTopic(ConnectWorkerIntegrationTest.java:314)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.runner.JUnitCore.runMain(JUnitCore.java:77)
	at org.junit.runner.JUnitCore.main(JUnitCore.java:36)
2022-07-12 17:23:55,443 - INFO  [DistributedHerder-connect-1-1:AbstractConfig@372] - SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,443 - INFO  [DistributedHerder-connect-1-1:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,444 - INFO  [DistributedHerder-connect-1-1:AbstractConfig@372] - EnrichedSourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = 1
	topic.creation.default.replication.factor = 1
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,445 - INFO  [DistributedHerder-connect-1-1:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = 1
	topic.creation.default.replication.factor = 1
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,459 - INFO  [KafkaBasedLog Work Thread - connect-config-topic-connect-cluster:DistributedHerder$ConfigUpdateListener@1543] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Tasks [simple-source-3, simple-source-2, simple-source-1, simple-source-0] configs updated
2022-07-12 17:23:55,459 - INFO  [DistributedHerder-connect-1-1:DistributedHerder@668] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Handling task config update by restarting tasks []
2022-07-12 17:23:55,459 - INFO  [DistributedHerder-connect-1-1:WorkerCoordinator@221] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Rebalance started
2022-07-12 17:23:55,460 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator@538] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] (Re-)joining group
2022-07-12 17:23:55,460 - INFO  [data-plane-kafka-request-handler-7:Logging@66] - [GroupCoordinator 0]: Preparing to rebalance group connect-integration-test-connect-cluster in state PreparingRebalance with old generation 2 (__consumer_offsets-8) (reason: leader connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e re-joining group during Stable)
2022-07-12 17:23:55,461 - INFO  [data-plane-kafka-request-handler-7:Logging@66] - [GroupCoordinator 0]: Stabilized group connect-integration-test-connect-cluster generation 3 (__consumer_offsets-8)
2022-07-12 17:23:55,461 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator$JoinGroupResponseHandler@594] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Successfully joined group with generation Generation{generationId=3, memberId='connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e', protocol='sessioned'}
2022-07-12 17:23:55,463 - INFO  [data-plane-kafka-request-handler-2:Logging@66] - [GroupCoordinator 0]: Assignment received from leader for group connect-integration-test-connect-cluster for generation 3
2022-07-12 17:23:55,465 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator$SyncGroupResponseHandler@758] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Successfully synced group in generation Generation{generationId=3, memberId='connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e', protocol='sessioned'}
2022-07-12 17:23:55,465 - INFO  [DistributedHerder-connect-1-1:DistributedHerder$RebalanceListener@1683] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Joined group at generation 3 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e', leaderUrl='http://localhost:38783/', offset=7, connectorIds=[simple-source], taskIds=[simple-source-0, simple-source-1, simple-source-2, simple-source-3], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0
2022-07-12 17:23:55,466 - INFO  [DistributedHerder-connect-1-1:DistributedHerder@1234] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Starting connectors and tasks using config offset 7
2022-07-12 17:23:55,466 - INFO  [StartAndStopExecutor-connect-1-2:DistributedHerder@1276] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Starting task simple-source-0
2022-07-12 17:23:55,466 - INFO  [StartAndStopExecutor-connect-1-3:DistributedHerder@1276] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Starting task simple-source-1
2022-07-12 17:23:55,466 - INFO  [StartAndStopExecutor-connect-1-4:DistributedHerder@1276] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Starting task simple-source-2
2022-07-12 17:23:55,466 - INFO  [StartAndStopExecutor-connect-1-2:Worker@509] - Creating task simple-source-0
2022-07-12 17:23:55,466 - INFO  [StartAndStopExecutor-connect-1-5:DistributedHerder@1276] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Starting task simple-source-3
2022-07-12 17:23:55,466 - INFO  [StartAndStopExecutor-connect-1-3:Worker@509] - Creating task simple-source-1
2022-07-12 17:23:55,467 - INFO  [StartAndStopExecutor-connect-1-4:Worker@509] - Creating task simple-source-2
2022-07-12 17:23:55,467 - INFO  [StartAndStopExecutor-connect-1-5:Worker@509] - Creating task simple-source-3
2022-07-12 17:23:55,468 - INFO  [StartAndStopExecutor-connect-1-2:AbstractConfig@372] - ConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,468 - INFO  [StartAndStopExecutor-connect-1-4:AbstractConfig@372] - ConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,468 - INFO  [StartAndStopExecutor-connect-1-3:AbstractConfig@372] - ConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,468 - INFO  [StartAndStopExecutor-connect-1-5:AbstractConfig@372] - ConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,468 - INFO  [StartAndStopExecutor-connect-1-4:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,468 - INFO  [StartAndStopExecutor-connect-1-2:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,468 - INFO  [StartAndStopExecutor-connect-1-5:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,468 - INFO  [StartAndStopExecutor-connect-1-3:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,469 - INFO  [StartAndStopExecutor-connect-1-3:AbstractConfig@372] - TaskConfig values: 
	task.class = class org.apache.kafka.connect.integration.MonitorableSourceConnector$MonitorableSourceTask

2022-07-12 17:23:55,469 - INFO  [StartAndStopExecutor-connect-1-5:AbstractConfig@372] - TaskConfig values: 
	task.class = class org.apache.kafka.connect.integration.MonitorableSourceConnector$MonitorableSourceTask

2022-07-12 17:23:55,469 - INFO  [StartAndStopExecutor-connect-1-2:AbstractConfig@372] - TaskConfig values: 
	task.class = class org.apache.kafka.connect.integration.MonitorableSourceConnector$MonitorableSourceTask

2022-07-12 17:23:55,469 - INFO  [StartAndStopExecutor-connect-1-4:AbstractConfig@372] - TaskConfig values: 
	task.class = class org.apache.kafka.connect.integration.MonitorableSourceConnector$MonitorableSourceTask

2022-07-12 17:23:55,469 - INFO  [StartAndStopExecutor-connect-1-2:Worker@524] - Instantiated task simple-source-0 with version unknown of type org.apache.kafka.connect.integration.MonitorableSourceConnector$MonitorableSourceTask
2022-07-12 17:23:55,469 - INFO  [StartAndStopExecutor-connect-1-5:Worker@524] - Instantiated task simple-source-3 with version unknown of type org.apache.kafka.connect.integration.MonitorableSourceConnector$MonitorableSourceTask
2022-07-12 17:23:55,469 - INFO  [StartAndStopExecutor-connect-1-3:Worker@524] - Instantiated task simple-source-1 with version unknown of type org.apache.kafka.connect.integration.MonitorableSourceConnector$MonitorableSourceTask
2022-07-12 17:23:55,469 - INFO  [StartAndStopExecutor-connect-1-4:Worker@524] - Instantiated task simple-source-2 with version unknown of type org.apache.kafka.connect.integration.MonitorableSourceConnector$MonitorableSourceTask
2022-07-12 17:23:55,470 - INFO  [StartAndStopExecutor-connect-1-5:AbstractConfig@372] - StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key

2022-07-12 17:23:55,470 - INFO  [StartAndStopExecutor-connect-1-3:AbstractConfig@372] - StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key

2022-07-12 17:23:55,470 - INFO  [StartAndStopExecutor-connect-1-5:AbstractConfig@372] - StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = value

2022-07-12 17:23:55,470 - INFO  [StartAndStopExecutor-connect-1-3:AbstractConfig@372] - StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = value

2022-07-12 17:23:55,470 - INFO  [StartAndStopExecutor-connect-1-2:AbstractConfig@372] - StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key

2022-07-12 17:23:55,470 - INFO  [StartAndStopExecutor-connect-1-4:AbstractConfig@372] - StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key

2022-07-12 17:23:55,470 - INFO  [StartAndStopExecutor-connect-1-2:AbstractConfig@372] - StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = value

2022-07-12 17:23:55,470 - INFO  [StartAndStopExecutor-connect-1-3:Worker@539] - Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task simple-source-1 using the connector config
2022-07-12 17:23:55,470 - INFO  [StartAndStopExecutor-connect-1-5:Worker@539] - Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task simple-source-3 using the connector config
2022-07-12 17:23:55,471 - INFO  [StartAndStopExecutor-connect-1-3:Worker@545] - Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task simple-source-1 using the connector config
2022-07-12 17:23:55,471 - INFO  [StartAndStopExecutor-connect-1-2:Worker@539] - Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task simple-source-0 using the connector config
2022-07-12 17:23:55,471 - INFO  [StartAndStopExecutor-connect-1-4:AbstractConfig@372] - StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = value

2022-07-12 17:23:55,471 - INFO  [StartAndStopExecutor-connect-1-3:Worker@550] - Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task simple-source-1 using the worker config
2022-07-12 17:23:55,471 - INFO  [StartAndStopExecutor-connect-1-2:Worker@545] - Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task simple-source-0 using the connector config
2022-07-12 17:23:55,471 - INFO  [StartAndStopExecutor-connect-1-5:Worker@545] - Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task simple-source-3 using the connector config
2022-07-12 17:23:55,471 - INFO  [StartAndStopExecutor-connect-1-2:Worker@550] - Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task simple-source-0 using the worker config
2022-07-12 17:23:55,471 - INFO  [StartAndStopExecutor-connect-1-5:Worker@550] - Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task simple-source-3 using the worker config
2022-07-12 17:23:55,471 - INFO  [StartAndStopExecutor-connect-1-4:Worker@539] - Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task simple-source-2 using the connector config
2022-07-12 17:23:55,471 - INFO  [StartAndStopExecutor-connect-1-4:Worker@545] - Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task simple-source-2 using the connector config
2022-07-12 17:23:55,471 - INFO  [StartAndStopExecutor-connect-1-4:Worker@550] - Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task simple-source-2 using the worker config
2022-07-12 17:23:55,474 - INFO  [StartAndStopExecutor-connect-1-2:AbstractConfig@372] - SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,474 - INFO  [StartAndStopExecutor-connect-1-5:AbstractConfig@372] - SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,474 - INFO  [StartAndStopExecutor-connect-1-4:AbstractConfig@372] - SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,474 - INFO  [StartAndStopExecutor-connect-1-3:AbstractConfig@372] - SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,474 - INFO  [StartAndStopExecutor-connect-1-5:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,474 - INFO  [StartAndStopExecutor-connect-1-2:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,474 - INFO  [StartAndStopExecutor-connect-1-3:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,474 - INFO  [StartAndStopExecutor-connect-1-4:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,475 - INFO  [StartAndStopExecutor-connect-1-2:AbstractConfig@372] - EnrichedSourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = 1
	topic.creation.default.replication.factor = 1
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,475 - INFO  [StartAndStopExecutor-connect-1-3:AbstractConfig@372] - EnrichedSourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = 1
	topic.creation.default.replication.factor = 1
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,475 - INFO  [StartAndStopExecutor-connect-1-2:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = 1
	topic.creation.default.replication.factor = 1
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,475 - INFO  [StartAndStopExecutor-connect-1-4:AbstractConfig@372] - EnrichedSourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = 1
	topic.creation.default.replication.factor = 1
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,475 - INFO  [StartAndStopExecutor-connect-1-5:AbstractConfig@372] - EnrichedSourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = 1
	topic.creation.default.replication.factor = 1
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,475 - INFO  [StartAndStopExecutor-connect-1-4:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = 1
	topic.creation.default.replication.factor = 1
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,475 - INFO  [StartAndStopExecutor-connect-1-3:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = 1
	topic.creation.default.replication.factor = 1
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,475 - INFO  [StartAndStopExecutor-connect-1-5:AbstractConfig@372] - EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = MonitorableSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = simple-source
	predicates = []
	tasks.max = 4
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = 1
	topic.creation.default.replication.factor = 1
	topic.creation.groups = []
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter

2022-07-12 17:23:55,476 - INFO  [StartAndStopExecutor-connect-1-2:Worker@606] - Initializing: org.apache.kafka.connect.runtime.TransformationChain{}
2022-07-12 17:23:55,476 - INFO  [StartAndStopExecutor-connect-1-4:Worker@606] - Initializing: org.apache.kafka.connect.runtime.TransformationChain{}
2022-07-12 17:23:55,476 - INFO  [StartAndStopExecutor-connect-1-3:Worker@606] - Initializing: org.apache.kafka.connect.runtime.TransformationChain{}
2022-07-12 17:23:55,476 - INFO  [StartAndStopExecutor-connect-1-5:Worker@606] - Initializing: org.apache.kafka.connect.runtime.TransformationChain{}
2022-07-12 17:23:55,477 - INFO  [StartAndStopExecutor-connect-1-4:AbstractConfig@372] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:39653]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-simple-source-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2022-07-12 17:23:55,477 - INFO  [StartAndStopExecutor-connect-1-3:AbstractConfig@372] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:39653]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-simple-source-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2022-07-12 17:23:55,477 - INFO  [StartAndStopExecutor-connect-1-2:AbstractConfig@372] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:39653]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-simple-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2022-07-12 17:23:55,477 - INFO  [StartAndStopExecutor-connect-1-5:AbstractConfig@372] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:39653]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-simple-source-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2022-07-12 17:23:55,481 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:55,481 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:55,481 - INFO  [StartAndStopExecutor-connect-1-5:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:55,481 - INFO  [StartAndStopExecutor-connect-1-5:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:55,481 - INFO  [StartAndStopExecutor-connect-1-5:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661035481
2022-07-12 17:23:55,482 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:55,482 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:55,482 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:55,483 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:55,483 - INFO  [StartAndStopExecutor-connect-1-4:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:55,483 - INFO  [StartAndStopExecutor-connect-1-4:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:55,483 - INFO  [StartAndStopExecutor-connect-1-4:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661035483
2022-07-12 17:23:55,484 - INFO  [StartAndStopExecutor-connect-1-5:AbstractConfig@372] - AdminClientConfig values: 
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = connector-adminclient-simple-source-3
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-12 17:23:55,484 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:55,484 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:55,484 - INFO  [StartAndStopExecutor-connect-1-2:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:55,485 - INFO  [StartAndStopExecutor-connect-1-2:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:55,485 - INFO  [StartAndStopExecutor-connect-1-2:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661035483
2022-07-12 17:23:55,485 - INFO  [StartAndStopExecutor-connect-1-4:AbstractConfig@372] - AdminClientConfig values: 
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = connector-adminclient-simple-source-2
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-12 17:23:55,485 - INFO  [StartAndStopExecutor-connect-1-3:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:55,486 - INFO  [StartAndStopExecutor-connect-1-3:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:55,486 - INFO  [StartAndStopExecutor-connect-1-3:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661035484
2022-07-12 17:23:55,486 - INFO  [StartAndStopExecutor-connect-1-2:AbstractConfig@372] - AdminClientConfig values: 
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = connector-adminclient-simple-source-0
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-12 17:23:55,486 - INFO  [kafka-producer-network-thread | connector-producer-simple-source-3:Metadata@279] - [Producer clientId=connector-producer-simple-source-3] Cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:55,486 - INFO  [kafka-producer-network-thread | connector-producer-simple-source-0:Metadata@279] - [Producer clientId=connector-producer-simple-source-0] Cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:55,486 - INFO  [StartAndStopExecutor-connect-1-3:AbstractConfig@372] - AdminClientConfig values: 
	bootstrap.servers = [localhost:39653]
	client.dns.lookup = use_all_dns_ips
	client.id = connector-adminclient-simple-source-1
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-07-12 17:23:55,486 - INFO  [kafka-producer-network-thread | connector-producer-simple-source-2:Metadata@279] - [Producer clientId=connector-producer-simple-source-2] Cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:55,486 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - WARN  [StartAndStopExecutor-connect-1-5:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:55,487 - INFO  [StartAndStopExecutor-connect-1-5:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:55,487 - INFO  [kafka-producer-network-thread | connector-producer-simple-source-1:Metadata@279] - [Producer clientId=connector-producer-simple-source-1] Cluster ID: nB904s1USwG7jo_IqFsyWg
2022-07-12 17:23:55,488 - INFO  [StartAndStopExecutor-connect-1-5:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - INFO  [StartAndStopExecutor-connect-1-5:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661035487
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-4:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:55,489 - INFO  [StartAndStopExecutor-connect-1-4:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:55,490 - INFO  [StartAndStopExecutor-connect-1-4:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:55,490 - INFO  [StartAndStopExecutor-connect-1-4:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661035489
2022-07-12 17:23:55,488 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'config.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:55,490 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:55,490 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:55,490 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:55,490 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:55,490 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:55,490 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:55,490 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:55,490 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:55,490 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:55,490 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:55,490 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:55,491 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:55,491 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:55,491 - WARN  [StartAndStopExecutor-connect-1-2:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:55,490 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'connector.client.config.override.policy' was supplied but isn't a known config.
2022-07-12 17:23:55,491 - INFO  [StartAndStopExecutor-connect-1-2:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:55,491 - INFO  [StartAndStopExecutor-connect-1-2:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:55,491 - INFO  [StartAndStopExecutor-connect-1-2:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661035491
2022-07-12 17:23:55,491 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.
2022-07-12 17:23:55,491 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'status.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:55,491 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'group.id' was supplied but isn't a known config.
2022-07-12 17:23:55,491 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'rest.host.name' was supplied but isn't a known config.
2022-07-12 17:23:55,491 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:55,491 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'rest.port' was supplied but isn't a known config.
2022-07-12 17:23:55,491 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'offset.flush.interval.ms' was supplied but isn't a known config.
2022-07-12 17:23:55,492 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.
2022-07-12 17:23:55,492 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:55,492 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
2022-07-12 17:23:55,492 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'offset.storage.topic' was supplied but isn't a known config.
2022-07-12 17:23:55,492 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'value.converter' was supplied but isn't a known config.
2022-07-12 17:23:55,492 - WARN  [StartAndStopExecutor-connect-1-3:AbstractConfig@380] - The configuration 'key.converter' was supplied but isn't a known config.
2022-07-12 17:23:55,492 - INFO  [StartAndStopExecutor-connect-1-3:AppInfoParser$AppInfo@119] - Kafka version: unknown
2022-07-12 17:23:55,492 - INFO  [StartAndStopExecutor-connect-1-3:AppInfoParser$AppInfo@120] - Kafka commitId: unknown
2022-07-12 17:23:55,493 - INFO  [StartAndStopExecutor-connect-1-3:AppInfoParser$AppInfo@121] - Kafka startTimeMs: 1657661035492
2022-07-12 17:23:55,503 - INFO  [DistributedHerder-connect-1-1:DistributedHerder@1262] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Finished starting connectors and tasks
2022-07-12 17:23:55,514 - INFO  [task-thread-simple-source-3:MonitorableSourceConnector$MonitorableSourceTask@121] - Started MonitorableSourceTask task simple-source-3 with properties {connector.class=MonitorableSourceConnector, messages.per.poll=10, topic.creation.default.partitions=1, tasks.max=4, connector.name=simple-source, task.class=org.apache.kafka.connect.integration.MonitorableSourceConnector$MonitorableSourceTask, topic.creation.default.replication.factor=1, name=simple-source, topic=nonexistenttopic, task.id=simple-source-3, throughput=10, value.converter=org.apache.kafka.connect.storage.StringConverter, key.converter=org.apache.kafka.connect.storage.StringConverter}
2022-07-12 17:23:55,514 - INFO  [task-thread-simple-source-1:MonitorableSourceConnector$MonitorableSourceTask@121] - Started MonitorableSourceTask task simple-source-1 with properties {connector.class=MonitorableSourceConnector, messages.per.poll=10, topic.creation.default.partitions=1, tasks.max=4, connector.name=simple-source, task.class=org.apache.kafka.connect.integration.MonitorableSourceConnector$MonitorableSourceTask, topic.creation.default.replication.factor=1, name=simple-source, topic=nonexistenttopic, task.id=simple-source-1, throughput=10, value.converter=org.apache.kafka.connect.storage.StringConverter, key.converter=org.apache.kafka.connect.storage.StringConverter}
2022-07-12 17:23:55,514 - INFO  [task-thread-simple-source-0:MonitorableSourceConnector$MonitorableSourceTask@121] - Started MonitorableSourceTask task simple-source-0 with properties {connector.class=MonitorableSourceConnector, messages.per.poll=10, topic.creation.default.partitions=1, tasks.max=4, connector.name=simple-source, task.class=org.apache.kafka.connect.integration.MonitorableSourceConnector$MonitorableSourceTask, topic.creation.default.replication.factor=1, name=simple-source, topic=nonexistenttopic, task.id=simple-source-0, throughput=10, value.converter=org.apache.kafka.connect.storage.StringConverter, key.converter=org.apache.kafka.connect.storage.StringConverter}
2022-07-12 17:23:55,514 - INFO  [task-thread-simple-source-2:MonitorableSourceConnector$MonitorableSourceTask@121] - Started MonitorableSourceTask task simple-source-2 with properties {connector.class=MonitorableSourceConnector, messages.per.poll=10, topic.creation.default.partitions=1, tasks.max=4, connector.name=simple-source, task.class=org.apache.kafka.connect.integration.MonitorableSourceConnector$MonitorableSourceTask, topic.creation.default.replication.factor=1, name=simple-source, topic=nonexistenttopic, task.id=simple-source-2, throughput=10, value.converter=org.apache.kafka.connect.storage.StringConverter, key.converter=org.apache.kafka.connect.storage.StringConverter}
2022-07-12 17:23:55,515 - INFO  [task-thread-simple-source-2:WorkerSourceTask@225] - WorkerSourceTask{id=simple-source-2} Source task finished initialization and start
2022-07-12 17:23:55,515 - INFO  [task-thread-simple-source-0:WorkerSourceTask@225] - WorkerSourceTask{id=simple-source-0} Source task finished initialization and start
2022-07-12 17:23:55,515 - INFO  [task-thread-simple-source-1:WorkerSourceTask@225] - WorkerSourceTask{id=simple-source-1} Source task finished initialization and start
2022-07-12 17:23:55,515 - INFO  [task-thread-simple-source-3:WorkerSourceTask@225] - WorkerSourceTask{id=simple-source-3} Source task finished initialization and start
2022-07-12 17:23:55,523 - INFO  [task-thread-simple-source-1:WorkerSourceTask@401] - The task will send records to topic 'nonexistenttopic' for the first time. Checking whether topic exists
2022-07-12 17:23:55,523 - INFO  [task-thread-simple-source-3:WorkerSourceTask@401] - The task will send records to topic 'nonexistenttopic' for the first time. Checking whether topic exists
2022-07-12 17:23:55,523 - INFO  [task-thread-simple-source-2:WorkerSourceTask@401] - The task will send records to topic 'nonexistenttopic' for the first time. Checking whether topic exists
2022-07-12 17:23:55,523 - INFO  [task-thread-simple-source-0:WorkerSourceTask@401] - The task will send records to topic 'nonexistenttopic' for the first time. Checking whether topic exists
2022-07-12 17:23:55,527 - INFO  [task-thread-simple-source-1:WorkerSourceTask@410] - Creating topic 'nonexistenttopic'
2022-07-12 17:23:55,527 - INFO  [task-thread-simple-source-0:WorkerSourceTask@410] - Creating topic 'nonexistenttopic'
2022-07-12 17:23:55,527 - INFO  [task-thread-simple-source-3:WorkerSourceTask@410] - Creating topic 'nonexistenttopic'
2022-07-12 17:23:55,527 - INFO  [task-thread-simple-source-2:WorkerSourceTask@410] - Creating topic 'nonexistenttopic'
2022-07-12 17:23:55,531 - INFO  [data-plane-kafka-request-handler-7:Logging@66] - Creating topic nonexistenttopic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2022-07-12 17:23:55,531 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Creating topic nonexistenttopic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2022-07-12 17:23:55,532 - INFO  [data-plane-kafka-request-handler-6:Logging@66] - Creating topic nonexistenttopic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2022-07-12 17:23:55,532 - INFO  [data-plane-kafka-request-handler-2:Logging@66] - Creating topic nonexistenttopic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2022-07-12 17:23:55,534 - INFO  [task-thread-simple-source-0:WorkerSourceTask@421] - Found existing topic '(name=nonexistenttopic, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={})'
2022-07-12 17:23:55,535 - INFO  [task-thread-simple-source-2:WorkerSourceTask@421] - Found existing topic '(name=nonexistenttopic, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={})'
2022-07-12 17:23:55,535 - INFO  [task-thread-simple-source-1:WorkerSourceTask@421] - Found existing topic '(name=nonexistenttopic, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={})'
2022-07-12 17:23:55,538 - WARN  [kafka-producer-network-thread | connector-producer-simple-source-0:NetworkClient$DefaultMetadataUpdater@1100] - [Producer clientId=connector-producer-simple-source-0] Error while fetching metadata with correlation id 3 : {nonexistenttopic=UNKNOWN_TOPIC_OR_PARTITION}
2022-07-12 17:23:55,538 - WARN  [kafka-producer-network-thread | connector-producer-simple-source-2:NetworkClient$DefaultMetadataUpdater@1100] - [Producer clientId=connector-producer-simple-source-2] Error while fetching metadata with correlation id 3 : {nonexistenttopic=UNKNOWN_TOPIC_OR_PARTITION}
2022-07-12 17:23:55,538 - WARN  [kafka-producer-network-thread | connector-producer-simple-source-1:NetworkClient$DefaultMetadataUpdater@1100] - [Producer clientId=connector-producer-simple-source-1] Error while fetching metadata with correlation id 3 : {nonexistenttopic=UNKNOWN_TOPIC_OR_PARTITION}
2022-07-12 17:23:55,540 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(nonexistenttopic-0)
2022-07-12 17:23:55,543 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Log partition=nonexistenttopic-0, dir=/tmp/EmbeddedKafkaCluster7379043744743579021] Loading producer state till offset 0 with message format version 2
2022-07-12 17:23:55,543 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - Created log for partition nonexistenttopic-0 in /tmp/EmbeddedKafkaCluster7379043744743579021/nonexistenttopic-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.8-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}.
2022-07-12 17:23:55,544 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition nonexistenttopic-0 broker=0] No checkpointed highwatermark is found for partition nonexistenttopic-0
2022-07-12 17:23:55,544 - INFO  [data-plane-kafka-request-handler-3:Logging@66] - [Partition nonexistenttopic-0 broker=0] Log loaded for partition nonexistenttopic-0 with initial high watermark 0
2022-07-12 17:23:55,549 - INFO  [task-thread-simple-source-3:TopicAdmin@389] - Created topic (name=nonexistenttopic, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={}) on brokers at localhost:39653
2022-07-12 17:23:55,549 - INFO  [task-thread-simple-source-3:WorkerSourceTask@418] - Created topic '(name=nonexistenttopic, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={})' using creation group TopicCreationGroup{name='default', inclusionPattern=.*, exclusionPattern=, numPartitions=1, replicationFactor=1, otherConfigs={}}
2022-07-12 17:23:55,555 - INFO  [main:EmbeddedConnectCluster@696] - GET response for URL=http://localhost:38783/connectors/simple-source/status is {"name":"simple-source","connector":{"state":"RUNNING","worker_id":"localhost:38783"},"tasks":[{"id":0,"state":"RUNNING","worker_id":"localhost:38783"},{"id":1,"state":"RUNNING","worker_id":"localhost:38783"},{"id":2,"state":"RUNNING","worker_id":"localhost:38783"},{"id":3,"state":"RUNNING","worker_id":"localhost:38783"}],"type":"source"}
2022-07-12 17:23:55,579 - INFO  [KafkaBasedLog Work Thread - connect-config-topic-connect-cluster:KafkaConfigBackingStore$ConsumeCallback@597] - Successfully processed removal of connector 'simple-source'
2022-07-12 17:23:55,579 - INFO  [KafkaBasedLog Work Thread - connect-config-topic-connect-cluster:DistributedHerder$ConfigUpdateListener@1515] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Connector simple-source config removed
2022-07-12 17:23:55,579 - INFO  [DistributedHerder-connect-1-1:DistributedHerder@614] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Handling connector-only config update by stopping connector simple-source
2022-07-12 17:23:55,579 - INFO  [DistributedHerder-connect-1-1:Worker@387] - Stopping connector simple-source
2022-07-12 17:23:55,579 - INFO  [DistributedHerder-connect-1-1:WorkerConnector@248] - Scheduled shutdown for WorkerConnector{id=simple-source}
2022-07-12 17:23:55,579 - INFO  [connector-thread-simple-source:MonitorableSourceConnector@82] - Stopped MonitorableSourceConnector connector simple-source
2022-07-12 17:23:55,580 - INFO  [connector-thread-simple-source:WorkerConnector@268] - Completed shutdown for WorkerConnector{id=simple-source}
2022-07-12 17:23:55,581 - INFO  [DistributedHerder-connect-1-1:WorkerCoordinator@221] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Rebalance started
2022-07-12 17:23:55,581 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator@538] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] (Re-)joining group
2022-07-12 17:23:55,581 - INFO  [main:EmbeddedConnectCluster@696] - DELETE response for URL=http://localhost:38783/connectors/simple-source is empty
2022-07-12 17:23:55,582 - INFO  [data-plane-kafka-request-handler-6:Logging@66] - [GroupCoordinator 0]: Preparing to rebalance group connect-integration-test-connect-cluster in state PreparingRebalance with old generation 3 (__consumer_offsets-8) (reason: leader connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e re-joining group during Stable)
2022-07-12 17:23:55,582 - INFO  [data-plane-kafka-request-handler-6:Logging@66] - [GroupCoordinator 0]: Stabilized group connect-integration-test-connect-cluster generation 4 (__consumer_offsets-8)
2022-07-12 17:23:55,583 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator$JoinGroupResponseHandler@594] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Successfully joined group with generation Generation{generationId=4, memberId='connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e', protocol='sessioned'}
2022-07-12 17:23:55,585 - INFO  [data-plane-kafka-request-handler-5:Logging@66] - [GroupCoordinator 0]: Assignment received from leader for group connect-integration-test-connect-cluster for generation 4
2022-07-12 17:23:55,587 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator$SyncGroupResponseHandler@758] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Successfully synced group in generation Generation{generationId=4, memberId='connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e', protocol='sessioned'}
2022-07-12 17:23:55,588 - INFO  [StartAndStopExecutor-connect-1-6:Worker@387] - Stopping connector simple-source
2022-07-12 17:23:55,588 - WARN  [StartAndStopExecutor-connect-1-6:Worker@390] - Ignoring stop request for unowned connector simple-source
2022-07-12 17:23:55,588 - INFO  [StartAndStopExecutor-connect-1-7:Worker@835] - Stopping task simple-source-0
2022-07-12 17:23:55,588 - WARN  [StartAndStopExecutor-connect-1-6:Worker@415] - Ignoring await stop request for non-present connector simple-source
2022-07-12 17:23:55,588 - INFO  [StartAndStopExecutor-connect-1-8:Worker@835] - Stopping task simple-source-1
2022-07-12 17:23:55,588 - INFO  [StartAndStopExecutor-connect-1-1:Worker@835] - Stopping task simple-source-2
2022-07-12 17:23:55,588 - INFO  [StartAndStopExecutor-connect-1-4:Worker@835] - Stopping task simple-source-3
2022-07-12 17:23:55,641 - INFO  [task-thread-simple-source-1:WorkerSourceTask@487] - WorkerSourceTask{id=simple-source-1} flushing 10 outstanding messages for offset commit
2022-07-12 17:23:55,641 - INFO  [task-thread-simple-source-2:WorkerSourceTask@487] - WorkerSourceTask{id=simple-source-2} flushing 10 outstanding messages for offset commit
2022-07-12 17:23:55,641 - INFO  [task-thread-simple-source-0:WorkerSourceTask@487] - WorkerSourceTask{id=simple-source-0} flushing 10 outstanding messages for offset commit
2022-07-12 17:23:55,651 - INFO  [task-thread-simple-source-2:MonitorableSourceConnector$MonitorableSourceTask@152] - Task simple-source-2 committing offsets
2022-07-12 17:23:55,651 - INFO  [task-thread-simple-source-1:MonitorableSourceConnector$MonitorableSourceTask@152] - Task simple-source-1 committing offsets
2022-07-12 17:23:55,651 - INFO  [task-thread-simple-source-0:MonitorableSourceConnector$MonitorableSourceTask@152] - Task simple-source-0 committing offsets
2022-07-12 17:23:55,652 - INFO  [task-thread-simple-source-1:MonitorableSourceConnector$MonitorableSourceTask@164] - Stopped MonitorableSourceTask task simple-source-1
2022-07-12 17:23:55,652 - INFO  [task-thread-simple-source-2:MonitorableSourceConnector$MonitorableSourceTask@164] - Stopped MonitorableSourceTask task simple-source-2
2022-07-12 17:23:55,652 - INFO  [task-thread-simple-source-0:MonitorableSourceConnector$MonitorableSourceTask@164] - Stopped MonitorableSourceTask task simple-source-0
2022-07-12 17:23:55,652 - INFO  [task-thread-simple-source-2:KafkaProducer@1204] - [Producer clientId=connector-producer-simple-source-2] Closing the Kafka producer with timeoutMillis = 30000 ms.
2022-07-12 17:23:55,652 - INFO  [task-thread-simple-source-1:KafkaProducer@1204] - [Producer clientId=connector-producer-simple-source-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2022-07-12 17:23:55,652 - INFO  [task-thread-simple-source-0:KafkaProducer@1204] - [Producer clientId=connector-producer-simple-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms.
2022-07-12 17:23:55,654 - INFO  [task-thread-simple-source-3:WorkerSourceTask@487] - WorkerSourceTask{id=simple-source-3} flushing 10 outstanding messages for offset commit
2022-07-12 17:23:55,655 - INFO  [task-thread-simple-source-1:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,655 - INFO  [task-thread-simple-source-1:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,655 - INFO  [task-thread-simple-source-1:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,655 - INFO  [task-thread-simple-source-1:AppInfoParser@83] - App info kafka.producer for connector-producer-simple-source-1 unregistered
2022-07-12 17:23:55,656 - INFO  [task-thread-simple-source-2:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,656 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-1:AppInfoParser@83] - App info kafka.admin.client for connector-adminclient-simple-source-1 unregistered
2022-07-12 17:23:55,656 - INFO  [task-thread-simple-source-2:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,656 - INFO  [task-thread-simple-source-0:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,656 - INFO  [task-thread-simple-source-2:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,656 - INFO  [task-thread-simple-source-0:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,657 - INFO  [task-thread-simple-source-2:AppInfoParser@83] - App info kafka.producer for connector-producer-simple-source-2 unregistered
2022-07-12 17:23:55,657 - INFO  [task-thread-simple-source-0:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,657 - INFO  [task-thread-simple-source-0:AppInfoParser@83] - App info kafka.producer for connector-producer-simple-source-0 unregistered
2022-07-12 17:23:55,658 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-2:AppInfoParser@83] - App info kafka.admin.client for connector-adminclient-simple-source-2 unregistered
2022-07-12 17:23:55,658 - INFO  [task-thread-simple-source-3:MonitorableSourceConnector$MonitorableSourceTask@152] - Task simple-source-3 committing offsets
2022-07-12 17:23:55,658 - INFO  [task-thread-simple-source-3:MonitorableSourceConnector$MonitorableSourceTask@164] - Stopped MonitorableSourceTask task simple-source-3
2022-07-12 17:23:55,658 - INFO  [task-thread-simple-source-3:KafkaProducer@1204] - [Producer clientId=connector-producer-simple-source-3] Closing the Kafka producer with timeoutMillis = 30000 ms.
2022-07-12 17:23:55,658 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-0:AppInfoParser@83] - App info kafka.admin.client for connector-adminclient-simple-source-0 unregistered
2022-07-12 17:23:55,659 - INFO  [main:EmbeddedConnectCluster@212] - Stopping worker WorkerHandle{workerName='connect-worker-0'workerURL='http://localhost:38783/'}
2022-07-12 17:23:55,659 - INFO  [main:Connect@67] - Kafka Connect stopping
2022-07-12 17:23:55,660 - INFO  [main:RestServer@328] - Stopping REST server
2022-07-12 17:23:55,660 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-1:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,660 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-1:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,660 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-1:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,662 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-2:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,662 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-2:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,663 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-2:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,663 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-0:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,663 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-0:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,663 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-0:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,665 - INFO  [task-thread-simple-source-3:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,665 - INFO  [task-thread-simple-source-3:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,665 - INFO  [task-thread-simple-source-3:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,666 - INFO  [task-thread-simple-source-3:AppInfoParser@83] - App info kafka.producer for connector-producer-simple-source-3 unregistered
2022-07-12 17:23:55,666 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-3:AppInfoParser@83] - App info kafka.admin.client for connector-adminclient-simple-source-3 unregistered
2022-07-12 17:23:55,667 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-3:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,667 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-3:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,667 - INFO  [kafka-admin-client-thread | connector-adminclient-simple-source-3:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,668 - INFO  [DistributedHerder-connect-1-1:DistributedHerder$RebalanceListener@1761] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Finished stopping tasks in preparation for rebalance
2022-07-12 17:23:55,669 - INFO  [main:AbstractConnector@381] - Stopped http_localhost0@9fec931{HTTP/1.1, (http/1.1)}{localhost:0}
2022-07-12 17:23:55,669 - INFO  [main:HouseKeeper@149] - node0 Stopped scavenging
2022-07-12 17:23:55,670 - INFO  [main:RestServer@345] - REST server stopped
2022-07-12 17:23:55,670 - INFO  [main:DistributedHerder@712] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Herder stopping
2022-07-12 17:23:55,673 - INFO  [DistributedHerder-connect-1-1:DistributedHerder$RebalanceListener@1780] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Finished flushing status backing store in preparation for rebalance
2022-07-12 17:23:55,673 - INFO  [DistributedHerder-connect-1-1:DistributedHerder$RebalanceListener@1683] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Joined group at generation 4 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e', leaderUrl='http://localhost:38783/', offset=9, connectorIds=[], taskIds=[], revokedConnectorIds=[simple-source], revokedTaskIds=[simple-source-0, simple-source-1, simple-source-2, simple-source-3], delay=0} with rebalance delay: 0
2022-07-12 17:23:55,674 - INFO  [DistributedHerder-connect-1-1:DistributedHerder@677] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Stopping connectors and tasks that are still assigned to this worker.
2022-07-12 17:23:55,674 - INFO  [DistributedHerder-connect-1-1:AbstractCoordinator@1042] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Member connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e sending LeaveGroup request to coordinator localhost:39653 (id: 2147483647 rack: null) due to the consumer is being closed
2022-07-12 17:23:55,675 - WARN  [DistributedHerder-connect-1-1:AbstractCoordinator@1023] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections
2022-07-12 17:23:55,675 - INFO  [DistributedHerder-connect-1-1:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,675 - INFO  [DistributedHerder-connect-1-1:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,675 - INFO  [DistributedHerder-connect-1-1:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,676 - INFO  [DistributedHerder-connect-1-1:AppInfoParser@83] - App info kafka.connect for connect-1 unregistered
2022-07-12 17:23:55,676 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@208] - Stopping KafkaBasedLog for topic connect-storage-topic-connect-cluster
2022-07-12 17:23:55,676 - INFO  [DistributedHerder-connect-1-1:KafkaProducer@1204] - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-07-12 17:23:55,677 - INFO  [DistributedHerder-connect-1-1:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,677 - INFO  [DistributedHerder-connect-1-1:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,677 - INFO  [DistributedHerder-connect-1-1:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,678 - INFO  [DistributedHerder-connect-1-1:AppInfoParser@83] - App info kafka.producer for producer-3 unregistered
2022-07-12 17:23:55,678 - INFO  [DistributedHerder-connect-1-1:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,678 - INFO  [DistributedHerder-connect-1-1:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,678 - INFO  [DistributedHerder-connect-1-1:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,679 - INFO  [data-plane-kafka-request-handler-7:Logging@66] - [GroupCoordinator 0]: Preparing to rebalance group connect-integration-test-connect-cluster in state PreparingRebalance with old generation 4 (__consumer_offsets-8) (reason: removing member connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e on LeaveGroup)
2022-07-12 17:23:55,679 - INFO  [DistributedHerder-connect-1-1:AppInfoParser@83] - App info kafka.consumer for consumer-connect-integration-test-connect-cluster-2 unregistered
2022-07-12 17:23:55,679 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@237] - Stopped KafkaBasedLog for topic connect-storage-topic-connect-cluster
2022-07-12 17:23:55,679 - INFO  [DistributedHerder-connect-1-1:KafkaConfigBackingStore@295] - Closing KafkaConfigBackingStore
2022-07-12 17:23:55,680 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@208] - Stopping KafkaBasedLog for topic connect-config-topic-connect-cluster
2022-07-12 17:23:55,680 - INFO  [data-plane-kafka-request-handler-7:Logging@66] - [GroupCoordinator 0]: Group connect-integration-test-connect-cluster with generation 5 is now empty (__consumer_offsets-8)
2022-07-12 17:23:55,680 - INFO  [DistributedHerder-connect-1-1:KafkaProducer@1204] - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-07-12 17:23:55,681 - INFO  [DistributedHerder-connect-1-1:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,681 - INFO  [DistributedHerder-connect-1-1:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,681 - INFO  [DistributedHerder-connect-1-1:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,681 - INFO  [DistributedHerder-connect-1-1:AppInfoParser@83] - App info kafka.producer for producer-4 unregistered
2022-07-12 17:23:55,681 - INFO  [DistributedHerder-connect-1-1:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,681 - INFO  [DistributedHerder-connect-1-1:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,681 - INFO  [DistributedHerder-connect-1-1:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,682 - INFO  [DistributedHerder-connect-1-1:AppInfoParser@83] - App info kafka.consumer for consumer-connect-integration-test-connect-cluster-3 unregistered
2022-07-12 17:23:55,683 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@237] - Stopped KafkaBasedLog for topic connect-config-topic-connect-cluster
2022-07-12 17:23:55,683 - INFO  [DistributedHerder-connect-1-1:KafkaConfigBackingStore@303] - Closed KafkaConfigBackingStore
2022-07-12 17:23:55,683 - INFO  [DistributedHerder-connect-1-1:Worker@209] - Worker stopping
2022-07-12 17:23:55,683 - INFO  [data-plane-kafka-request-handler-7:Logging@66] - [GroupCoordinator 0]: Member MemberMetadata(memberId=connect-1-7dd811b0-82c2-4215-b803-c0b31d31be6e, groupInstanceId=None, clientId=connect-1, clientHost=/127.0.0.1, sessionTimeoutMs=10000, rebalanceTimeoutMs=60000, supportedProtocols=List(sessioned, compatible, default)) has left group connect-integration-test-connect-cluster through explicit `LeaveGroup` request
2022-07-12 17:23:55,683 - INFO  [DistributedHerder-connect-1-1:KafkaOffsetBackingStore@151] - Stopping KafkaOffsetBackingStore
2022-07-12 17:23:55,683 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@208] - Stopping KafkaBasedLog for topic connect-offset-topic-connect-cluster
2022-07-12 17:23:55,683 - INFO  [DistributedHerder-connect-1-1:KafkaProducer@1204] - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-07-12 17:23:55,684 - INFO  [DistributedHerder-connect-1-1:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,684 - INFO  [DistributedHerder-connect-1-1:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,684 - INFO  [DistributedHerder-connect-1-1:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,685 - INFO  [DistributedHerder-connect-1-1:AppInfoParser@83] - App info kafka.producer for producer-2 unregistered
2022-07-12 17:23:55,685 - INFO  [DistributedHerder-connect-1-1:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,685 - INFO  [DistributedHerder-connect-1-1:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,685 - INFO  [DistributedHerder-connect-1-1:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,686 - INFO  [DistributedHerder-connect-1-1:AppInfoParser@83] - App info kafka.consumer for consumer-connect-integration-test-connect-cluster-1 unregistered
2022-07-12 17:23:55,686 - INFO  [DistributedHerder-connect-1-1:KafkaBasedLog@237] - Stopped KafkaBasedLog for topic connect-offset-topic-connect-cluster
2022-07-12 17:23:55,686 - INFO  [DistributedHerder-connect-1-1:KafkaOffsetBackingStore@159] - Stopped KafkaOffsetBackingStore
2022-07-12 17:23:55,686 - INFO  [DistributedHerder-connect-1-1:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,686 - INFO  [DistributedHerder-connect-1-1:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,686 - INFO  [DistributedHerder-connect-1-1:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,686 - INFO  [DistributedHerder-connect-1-1:AppInfoParser@83] - App info kafka.connect for localhost:38783 unregistered
2022-07-12 17:23:55,687 - INFO  [DistributedHerder-connect-1-1:Worker@230] - Worker stopped
2022-07-12 17:23:55,688 - INFO  [kafka-admin-client-thread | adminclient-8:AppInfoParser@83] - App info kafka.admin.client for adminclient-8 unregistered
2022-07-12 17:23:55,688 - INFO  [kafka-admin-client-thread | adminclient-8:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,688 - INFO  [kafka-admin-client-thread | adminclient-8:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,688 - INFO  [kafka-admin-client-thread | adminclient-8:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,688 - INFO  [DistributedHerder-connect-1-1:DistributedHerder@321] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Herder stopped
2022-07-12 17:23:55,690 - INFO  [main:DistributedHerder@732] - [Worker clientId=connect-1, groupId=connect-integration-test-connect-cluster] Herder stopped
2022-07-12 17:23:55,691 - INFO  [main:Connect@72] - Kafka Connect stopped
2022-07-12 17:23:55,691 - INFO  [main:KafkaProducer@1204] - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-07-12 17:23:55,692 - INFO  [main:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:55,692 - INFO  [main:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:55,692 - INFO  [main:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:55,692 - INFO  [main:AppInfoParser@83] - App info kafka.producer for producer-1 unregistered
2022-07-12 17:23:55,692 - INFO  [main:Logging@66] - [KafkaServer id=0] shutting down
2022-07-12 17:23:55,693 - INFO  [main:Logging@66] - [KafkaServer id=0] Starting controlled shutdown
2022-07-12 17:23:55,705 - INFO  [main:Logging@66] - [KafkaServer id=0] Controlled shutdown succeeded
2022-07-12 17:23:55,706 - INFO  [main:Logging@66] - [/config/changes-event-process-thread]: Shutting down
2022-07-12 17:23:55,706 - INFO  [/config/changes-event-process-thread:Logging@66] - [/config/changes-event-process-thread]: Stopped
2022-07-12 17:23:55,706 - INFO  [main:Logging@66] - [/config/changes-event-process-thread]: Shutdown completed
2022-07-12 17:23:55,707 - INFO  [main:Logging@66] - [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2022-07-12 17:23:55,711 - INFO  [main:Logging@66] - [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2022-07-12 17:23:55,711 - INFO  [main:Logging@66] - [data-plane Kafka Request Handler on Broker 0], shutting down
2022-07-12 17:23:55,712 - INFO  [main:Logging@66] - [data-plane Kafka Request Handler on Broker 0], shut down completely
2022-07-12 17:23:55,714 - INFO  [main:Logging@66] - [ExpirationReaper-0-AlterAcls]: Shutting down
2022-07-12 17:23:55,902 - INFO  [ExpirationReaper-0-AlterAcls:Logging@66] - [ExpirationReaper-0-AlterAcls]: Stopped
2022-07-12 17:23:55,902 - INFO  [main:Logging@66] - [ExpirationReaper-0-AlterAcls]: Shutdown completed
2022-07-12 17:23:55,903 - INFO  [main:Logging@66] - [KafkaApi-0] Shutdown complete.
2022-07-12 17:23:55,903 - INFO  [main:Logging@66] - [ExpirationReaper-0-topic]: Shutting down
2022-07-12 17:23:56,097 - INFO  [ExpirationReaper-0-topic:Logging@66] - [ExpirationReaper-0-topic]: Stopped
2022-07-12 17:23:56,097 - INFO  [main:Logging@66] - [ExpirationReaper-0-topic]: Shutdown completed
2022-07-12 17:23:56,098 - INFO  [main:Logging@66] - [TransactionCoordinator id=0] Shutting down.
2022-07-12 17:23:56,099 - INFO  [main:Logging@66] - [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2022-07-12 17:23:56,099 - INFO  [main:Logging@66] - [Transaction State Manager 0]: Shutdown complete
2022-07-12 17:23:56,099 - INFO  [main:Logging@66] - [Transaction Marker Channel Manager 0]: Shutting down
2022-07-12 17:23:56,100 - INFO  [TxnMarkerSenderThread-0:Logging@66] - [Transaction Marker Channel Manager 0]: Stopped
2022-07-12 17:23:56,100 - INFO  [main:Logging@66] - [Transaction Marker Channel Manager 0]: Shutdown completed
2022-07-12 17:23:56,100 - INFO  [main:Logging@66] - [TransactionCoordinator id=0] Shutdown complete.
2022-07-12 17:23:56,100 - INFO  [main:Logging@66] - [GroupCoordinator 0]: Shutting down.
2022-07-12 17:23:56,101 - INFO  [main:Logging@66] - [ExpirationReaper-0-Heartbeat]: Shutting down
2022-07-12 17:23:56,297 - INFO  [ExpirationReaper-0-Heartbeat:Logging@66] - [ExpirationReaper-0-Heartbeat]: Stopped
2022-07-12 17:23:56,297 - INFO  [main:Logging@66] - [ExpirationReaper-0-Heartbeat]: Shutdown completed
2022-07-12 17:23:56,297 - INFO  [main:Logging@66] - [ExpirationReaper-0-Rebalance]: Shutting down
2022-07-12 17:23:56,319 - INFO  [ExpirationReaper-0-Rebalance:Logging@66] - [ExpirationReaper-0-Rebalance]: Stopped
2022-07-12 17:23:56,319 - INFO  [main:Logging@66] - [ExpirationReaper-0-Rebalance]: Shutdown completed
2022-07-12 17:23:56,319 - INFO  [main:Logging@66] - [GroupCoordinator 0]: Shutdown complete.
2022-07-12 17:23:56,320 - INFO  [main:Logging@66] - [ReplicaManager broker=0] Shutting down
2022-07-12 17:23:56,320 - INFO  [main:Logging@66] - [LogDirFailureHandler]: Shutting down
2022-07-12 17:23:56,320 - INFO  [LogDirFailureHandler:Logging@66] - [LogDirFailureHandler]: Stopped
2022-07-12 17:23:56,320 - INFO  [main:Logging@66] - [LogDirFailureHandler]: Shutdown completed
2022-07-12 17:23:56,321 - INFO  [main:Logging@66] - [ReplicaFetcherManager on broker 0] shutting down
2022-07-12 17:23:56,322 - INFO  [main:Logging@66] - [ReplicaFetcherManager on broker 0] shutdown completed
2022-07-12 17:23:56,322 - INFO  [main:Logging@66] - [ReplicaAlterLogDirsManager on broker 0] shutting down
2022-07-12 17:23:56,322 - INFO  [main:Logging@66] - [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2022-07-12 17:23:56,322 - INFO  [main:Logging@66] - [ExpirationReaper-0-Fetch]: Shutting down
2022-07-12 17:23:56,363 - INFO  [ExpirationReaper-0-Fetch:Logging@66] - [ExpirationReaper-0-Fetch]: Stopped
2022-07-12 17:23:56,363 - INFO  [main:Logging@66] - [ExpirationReaper-0-Fetch]: Shutdown completed
2022-07-12 17:23:56,363 - INFO  [main:Logging@66] - [ExpirationReaper-0-Produce]: Shutting down
2022-07-12 17:23:56,497 - INFO  [ExpirationReaper-0-Produce:Logging@66] - [ExpirationReaper-0-Produce]: Stopped
2022-07-12 17:23:56,497 - INFO  [main:Logging@66] - [ExpirationReaper-0-Produce]: Shutdown completed
2022-07-12 17:23:56,497 - INFO  [main:Logging@66] - [ExpirationReaper-0-DeleteRecords]: Shutting down
2022-07-12 17:23:56,697 - INFO  [ExpirationReaper-0-DeleteRecords:Logging@66] - [ExpirationReaper-0-DeleteRecords]: Stopped
2022-07-12 17:23:56,697 - INFO  [main:Logging@66] - [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2022-07-12 17:23:56,697 - INFO  [main:Logging@66] - [ExpirationReaper-0-ElectLeader]: Shutting down
2022-07-12 17:23:56,897 - INFO  [ExpirationReaper-0-ElectLeader:Logging@66] - [ExpirationReaper-0-ElectLeader]: Stopped
2022-07-12 17:23:56,897 - INFO  [main:Logging@66] - [ExpirationReaper-0-ElectLeader]: Shutdown completed
2022-07-12 17:23:56,899 - INFO  [main:Logging@66] - [ReplicaManager broker=0] Shut down completely
2022-07-12 17:23:56,899 - INFO  [main:Logging@66] - [broker-0-to-controller-send-thread]: Shutting down
2022-07-12 17:23:56,900 - INFO  [broker-0-to-controller-send-thread:Logging@66] - [broker-0-to-controller-send-thread]: Stopped
2022-07-12 17:23:56,900 - INFO  [main:Logging@66] - [broker-0-to-controller-send-thread]: Shutdown completed
2022-07-12 17:23:56,900 - INFO  [main:Logging@66] - Broker to controller channel manager for alterIsrChannel shutdown
2022-07-12 17:23:56,901 - INFO  [main:Logging@66] - Shutting down.
2022-07-12 17:23:56,919 - INFO  [pool-11-thread-1:Logging@66] - [ProducerStateManager partition=connect-offset-topic-connect-cluster-9] Writing producer snapshot at offset 1
2022-07-12 17:23:56,934 - INFO  [pool-11-thread-1:Logging@66] - [ProducerStateManager partition=connect-storage-topic-connect-cluster-1] Writing producer snapshot at offset 8
2022-07-12 17:23:56,951 - INFO  [pool-11-thread-1:Logging@66] - [ProducerStateManager partition=nonexistenttopic-0] Writing producer snapshot at offset 50
2022-07-12 17:23:56,967 - INFO  [pool-11-thread-1:Logging@66] - [ProducerStateManager partition=connect-offset-topic-connect-cluster-16] Writing producer snapshot at offset 1
2022-07-12 17:23:56,984 - INFO  [pool-11-thread-1:Logging@66] - [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 5
2022-07-12 17:23:57,001 - INFO  [pool-11-thread-1:Logging@66] - [ProducerStateManager partition=connect-storage-topic-connect-cluster-2] Writing producer snapshot at offset 4
2022-07-12 17:23:57,017 - INFO  [pool-11-thread-1:Logging@66] - [ProducerStateManager partition=connect-offset-topic-connect-cluster-7] Writing producer snapshot at offset 1
2022-07-12 17:23:57,034 - INFO  [pool-11-thread-1:Logging@66] - [ProducerStateManager partition=connect-offset-topic-connect-cluster-0] Writing producer snapshot at offset 1
2022-07-12 17:23:57,050 - INFO  [pool-11-thread-1:Logging@66] - [ProducerStateManager partition=connect-storage-topic-connect-cluster-0] Writing producer snapshot at offset 7
2022-07-12 17:23:57,067 - INFO  [pool-11-thread-1:Logging@66] - [ProducerStateManager partition=connect-storage-topic-connect-cluster-3] Writing producer snapshot at offset 12
2022-07-12 17:23:57,084 - INFO  [pool-11-thread-1:Logging@66] - [ProducerStateManager partition=connect-config-topic-connect-cluster-0] Writing producer snapshot at offset 9
2022-07-12 17:23:57,110 - INFO  [main:Logging@66] - Shutdown complete.
2022-07-12 17:23:57,115 - INFO  [main:Logging@66] - [feature-zk-node-event-process-thread]: Shutting down
2022-07-12 17:23:57,115 - INFO  [feature-zk-node-event-process-thread:Logging@66] - [feature-zk-node-event-process-thread]: Stopped
2022-07-12 17:23:57,115 - INFO  [main:Logging@66] - [feature-zk-node-event-process-thread]: Shutdown completed
2022-07-12 17:23:57,116 - INFO  [main:Logging@66] - [ZooKeeperClient Kafka server] Closing.
2022-07-12 17:23:57,218 - INFO  [main:ZooKeeper@1422] - Session: 0x100cb920a040000 closed
2022-07-12 17:23:57,218 - INFO  [main-EventThread:ClientCnxn$EventThread@524] - EventThread shut down for session: 0x100cb920a040000
2022-07-12 17:23:57,219 - INFO  [main:Logging@66] - [ZooKeeperClient Kafka server] Closed.
2022-07-12 17:23:57,219 - INFO  [main:Logging@66] - [ThrottledChannelReaper-Fetch]: Shutting down
2022-07-12 17:23:58,137 - INFO  [ThrottledChannelReaper-Fetch:Logging@66] - [ThrottledChannelReaper-Fetch]: Stopped
2022-07-12 17:23:58,137 - INFO  [main:Logging@66] - [ThrottledChannelReaper-Fetch]: Shutdown completed
2022-07-12 17:23:58,138 - INFO  [main:Logging@66] - [ThrottledChannelReaper-Produce]: Shutting down
2022-07-12 17:23:59,138 - INFO  [ThrottledChannelReaper-Produce:Logging@66] - [ThrottledChannelReaper-Produce]: Stopped
2022-07-12 17:23:59,138 - INFO  [main:Logging@66] - [ThrottledChannelReaper-Produce]: Shutdown completed
2022-07-12 17:23:59,138 - INFO  [main:Logging@66] - [ThrottledChannelReaper-Request]: Shutting down
2022-07-12 17:23:59,139 - INFO  [main:Logging@66] - [ThrottledChannelReaper-Request]: Shutdown completed
2022-07-12 17:23:59,139 - INFO  [ThrottledChannelReaper-Request:Logging@66] - [ThrottledChannelReaper-Request]: Stopped
2022-07-12 17:23:59,139 - INFO  [main:Logging@66] - [ThrottledChannelReaper-ControllerMutation]: Shutting down
2022-07-12 17:23:59,140 - INFO  [ThrottledChannelReaper-ControllerMutation:Logging@66] - [ThrottledChannelReaper-ControllerMutation]: Stopped
2022-07-12 17:23:59,140 - INFO  [main:Logging@66] - [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2022-07-12 17:23:59,140 - INFO  [main:Logging@66] - [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2022-07-12 17:23:59,156 - INFO  [main:Logging@66] - [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2022-07-12 17:23:59,157 - INFO  [main:Metrics@659] - Metrics scheduler closed
2022-07-12 17:23:59,157 - INFO  [main:Metrics@663] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-07-12 17:23:59,157 - INFO  [main:Metrics@669] - Metrics reporters closed
2022-07-12 17:23:59,160 - INFO  [main:Logging@66] - Broker and topic stats closed
2022-07-12 17:23:59,161 - INFO  [main:AppInfoParser@83] - App info kafka.server for 0 unregistered
2022-07-12 17:23:59,161 - INFO  [main:Logging@66] - [KafkaServer id=0] shut down completed
2022-07-12 17:23:59,161 - INFO  [main:EmbeddedKafkaCluster@191] - Cleaning up kafka log dirs at ArraySeq(/tmp/EmbeddedKafkaCluster7379043744743579021)
2022-07-12 17:23:59,176 - INFO  [ConnnectionExpirer:NIOServerCnxnFactory$ConnectionExpirerThread@583] - ConnnectionExpirerThread interrupted
2022-07-12 17:23:59,177 - INFO  [NIOServerCxnFactory.SelectorThread-1:NIOServerCnxnFactory$SelectorThread@420] - selector thread exitted run method
2022-07-12 17:23:59,177 - INFO  [NIOServerCxnFactory.SelectorThread-0:NIOServerCnxnFactory$SelectorThread@420] - selector thread exitted run method
2022-07-12 17:23:59,177 - INFO  [NIOServerCxnFactory.SelectorThread-2:NIOServerCnxnFactory$SelectorThread@420] - selector thread exitted run method
2022-07-12 17:23:59,178 - INFO  [NIOServerCxnFactory.AcceptThread:/127.0.0.1:0:NIOServerCnxnFactory$AcceptThread@219] - accept thread exitted run method
2022-07-12 17:23:59,178 - INFO  [main:ZooKeeperServer@573] - shutting down
2022-07-12 17:23:59,178 - INFO  [main:SessionTrackerImpl@237] - Shutting down
2022-07-12 17:23:59,178 - INFO  [main:PrepRequestProcessor@1008] - Shutting down
2022-07-12 17:23:59,178 - INFO  [main:SyncRequestProcessor@191] - Shutting down
2022-07-12 17:23:59,178 - INFO  [ProcessThread(sid:0 cport:37769)::PrepRequestProcessor@156] - PrepRequestProcessor exited loop!
2022-07-12 17:23:59,179 - INFO  [SyncThread:0:SyncRequestProcessor@169] - SyncRequestProcessor exited!
2022-07-12 17:23:59,179 - INFO  [main:FinalRequestProcessor@514] - shutdown of request processor complete
2022-07-12 17:23:59,187 - INFO  [main:ConnectIntegrationTestUtils$1@39] - Finished test testSourceTaskNotBlockedOnShutdownWithNonExistentTopic

Time: 9.144

OK (1 test)

