// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: MasterProcedure.proto

package org.apache.hadoop.hbase.protobuf.generated;

public final class MasterProcedureProtos {
  private MasterProcedureProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  /**
   * Protobuf enum {@code hbase.pb.CreateTableState}
   */
  public enum CreateTableState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CREATE_TABLE_PRE_OPERATION = 1;</code>
     */
    CREATE_TABLE_PRE_OPERATION(0, 1),
    /**
     * <code>CREATE_TABLE_WRITE_FS_LAYOUT = 2;</code>
     */
    CREATE_TABLE_WRITE_FS_LAYOUT(1, 2),
    /**
     * <code>CREATE_TABLE_ADD_TO_META = 3;</code>
     */
    CREATE_TABLE_ADD_TO_META(2, 3),
    /**
     * <code>CREATE_TABLE_ASSIGN_REGIONS = 4;</code>
     */
    CREATE_TABLE_ASSIGN_REGIONS(3, 4),
    /**
     * <code>CREATE_TABLE_UPDATE_DESC_CACHE = 5;</code>
     */
    CREATE_TABLE_UPDATE_DESC_CACHE(4, 5),
    /**
     * <code>CREATE_TABLE_POST_OPERATION = 6;</code>
     */
    CREATE_TABLE_POST_OPERATION(5, 6),
    ;

    /**
     * <code>CREATE_TABLE_PRE_OPERATION = 1;</code>
     */
    public static final int CREATE_TABLE_PRE_OPERATION_VALUE = 1;
    /**
     * <code>CREATE_TABLE_WRITE_FS_LAYOUT = 2;</code>
     */
    public static final int CREATE_TABLE_WRITE_FS_LAYOUT_VALUE = 2;
    /**
     * <code>CREATE_TABLE_ADD_TO_META = 3;</code>
     */
    public static final int CREATE_TABLE_ADD_TO_META_VALUE = 3;
    /**
     * <code>CREATE_TABLE_ASSIGN_REGIONS = 4;</code>
     */
    public static final int CREATE_TABLE_ASSIGN_REGIONS_VALUE = 4;
    /**
     * <code>CREATE_TABLE_UPDATE_DESC_CACHE = 5;</code>
     */
    public static final int CREATE_TABLE_UPDATE_DESC_CACHE_VALUE = 5;
    /**
     * <code>CREATE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int CREATE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() { return value; }

    public static CreateTableState valueOf(int value) {
      switch (value) {
        case 1: return CREATE_TABLE_PRE_OPERATION;
        case 2: return CREATE_TABLE_WRITE_FS_LAYOUT;
        case 3: return CREATE_TABLE_ADD_TO_META;
        case 4: return CREATE_TABLE_ASSIGN_REGIONS;
        case 5: return CREATE_TABLE_UPDATE_DESC_CACHE;
        case 6: return CREATE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<CreateTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<CreateTableState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<CreateTableState>() {
            public CreateTableState findValueByNumber(int number) {
              return CreateTableState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final CreateTableState[] VALUES = values();

    public static CreateTableState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private CreateTableState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.CreateTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ModifyTableState}
   */
  public enum ModifyTableState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MODIFY_TABLE_PREPARE = 1;</code>
     */
    MODIFY_TABLE_PREPARE(0, 1),
    /**
     * <code>MODIFY_TABLE_PRE_OPERATION = 2;</code>
     */
    MODIFY_TABLE_PRE_OPERATION(1, 2),
    /**
     * <code>MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR(2, 3),
    /**
     * <code>MODIFY_TABLE_REMOVE_REPLICA_COLUMN = 4;</code>
     */
    MODIFY_TABLE_REMOVE_REPLICA_COLUMN(3, 4),
    /**
     * <code>MODIFY_TABLE_DELETE_FS_LAYOUT = 5;</code>
     */
    MODIFY_TABLE_DELETE_FS_LAYOUT(4, 5),
    /**
     * <code>MODIFY_TABLE_POST_OPERATION = 6;</code>
     */
    MODIFY_TABLE_POST_OPERATION(5, 6),
    /**
     * <code>MODIFY_TABLE_REOPEN_ALL_REGIONS = 7;</code>
     */
    MODIFY_TABLE_REOPEN_ALL_REGIONS(6, 7),
    ;

    /**
     * <code>MODIFY_TABLE_PREPARE = 1;</code>
     */
    public static final int MODIFY_TABLE_PREPARE_VALUE = 1;
    /**
     * <code>MODIFY_TABLE_PRE_OPERATION = 2;</code>
     */
    public static final int MODIFY_TABLE_PRE_OPERATION_VALUE = 2;
    /**
     * <code>MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    public static final int MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR_VALUE = 3;
    /**
     * <code>MODIFY_TABLE_REMOVE_REPLICA_COLUMN = 4;</code>
     */
    public static final int MODIFY_TABLE_REMOVE_REPLICA_COLUMN_VALUE = 4;
    /**
     * <code>MODIFY_TABLE_DELETE_FS_LAYOUT = 5;</code>
     */
    public static final int MODIFY_TABLE_DELETE_FS_LAYOUT_VALUE = 5;
    /**
     * <code>MODIFY_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int MODIFY_TABLE_POST_OPERATION_VALUE = 6;
    /**
     * <code>MODIFY_TABLE_REOPEN_ALL_REGIONS = 7;</code>
     */
    public static final int MODIFY_TABLE_REOPEN_ALL_REGIONS_VALUE = 7;


    public final int getNumber() { return value; }

    public static ModifyTableState valueOf(int value) {
      switch (value) {
        case 1: return MODIFY_TABLE_PREPARE;
        case 2: return MODIFY_TABLE_PRE_OPERATION;
        case 3: return MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR;
        case 4: return MODIFY_TABLE_REMOVE_REPLICA_COLUMN;
        case 5: return MODIFY_TABLE_DELETE_FS_LAYOUT;
        case 6: return MODIFY_TABLE_POST_OPERATION;
        case 7: return MODIFY_TABLE_REOPEN_ALL_REGIONS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ModifyTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ModifyTableState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ModifyTableState>() {
            public ModifyTableState findValueByNumber(int number) {
              return ModifyTableState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(1);
    }

    private static final ModifyTableState[] VALUES = values();

    public static ModifyTableState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ModifyTableState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ModifyTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.TruncateTableState}
   */
  public enum TruncateTableState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>TRUNCATE_TABLE_PRE_OPERATION = 1;</code>
     */
    TRUNCATE_TABLE_PRE_OPERATION(0, 1),
    /**
     * <code>TRUNCATE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    TRUNCATE_TABLE_REMOVE_FROM_META(1, 2),
    /**
     * <code>TRUNCATE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    TRUNCATE_TABLE_CLEAR_FS_LAYOUT(2, 3),
    /**
     * <code>TRUNCATE_TABLE_CREATE_FS_LAYOUT = 4;</code>
     */
    TRUNCATE_TABLE_CREATE_FS_LAYOUT(3, 4),
    /**
     * <code>TRUNCATE_TABLE_ADD_TO_META = 5;</code>
     */
    TRUNCATE_TABLE_ADD_TO_META(4, 5),
    /**
     * <code>TRUNCATE_TABLE_ASSIGN_REGIONS = 6;</code>
     */
    TRUNCATE_TABLE_ASSIGN_REGIONS(5, 6),
    /**
     * <code>TRUNCATE_TABLE_POST_OPERATION = 7;</code>
     */
    TRUNCATE_TABLE_POST_OPERATION(6, 7),
    ;

    /**
     * <code>TRUNCATE_TABLE_PRE_OPERATION = 1;</code>
     */
    public static final int TRUNCATE_TABLE_PRE_OPERATION_VALUE = 1;
    /**
     * <code>TRUNCATE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    public static final int TRUNCATE_TABLE_REMOVE_FROM_META_VALUE = 2;
    /**
     * <code>TRUNCATE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    public static final int TRUNCATE_TABLE_CLEAR_FS_LAYOUT_VALUE = 3;
    /**
     * <code>TRUNCATE_TABLE_CREATE_FS_LAYOUT = 4;</code>
     */
    public static final int TRUNCATE_TABLE_CREATE_FS_LAYOUT_VALUE = 4;
    /**
     * <code>TRUNCATE_TABLE_ADD_TO_META = 5;</code>
     */
    public static final int TRUNCATE_TABLE_ADD_TO_META_VALUE = 5;
    /**
     * <code>TRUNCATE_TABLE_ASSIGN_REGIONS = 6;</code>
     */
    public static final int TRUNCATE_TABLE_ASSIGN_REGIONS_VALUE = 6;
    /**
     * <code>TRUNCATE_TABLE_POST_OPERATION = 7;</code>
     */
    public static final int TRUNCATE_TABLE_POST_OPERATION_VALUE = 7;


    public final int getNumber() { return value; }

    public static TruncateTableState valueOf(int value) {
      switch (value) {
        case 1: return TRUNCATE_TABLE_PRE_OPERATION;
        case 2: return TRUNCATE_TABLE_REMOVE_FROM_META;
        case 3: return TRUNCATE_TABLE_CLEAR_FS_LAYOUT;
        case 4: return TRUNCATE_TABLE_CREATE_FS_LAYOUT;
        case 5: return TRUNCATE_TABLE_ADD_TO_META;
        case 6: return TRUNCATE_TABLE_ASSIGN_REGIONS;
        case 7: return TRUNCATE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<TruncateTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<TruncateTableState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<TruncateTableState>() {
            public TruncateTableState findValueByNumber(int number) {
              return TruncateTableState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(2);
    }

    private static final TruncateTableState[] VALUES = values();

    public static TruncateTableState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private TruncateTableState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.TruncateTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DeleteTableState}
   */
  public enum DeleteTableState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DELETE_TABLE_PRE_OPERATION = 1;</code>
     */
    DELETE_TABLE_PRE_OPERATION(0, 1),
    /**
     * <code>DELETE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    DELETE_TABLE_REMOVE_FROM_META(1, 2),
    /**
     * <code>DELETE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    DELETE_TABLE_CLEAR_FS_LAYOUT(2, 3),
    /**
     * <code>DELETE_TABLE_UPDATE_DESC_CACHE = 4;</code>
     */
    DELETE_TABLE_UPDATE_DESC_CACHE(3, 4),
    /**
     * <code>DELETE_TABLE_UNASSIGN_REGIONS = 5;</code>
     */
    DELETE_TABLE_UNASSIGN_REGIONS(4, 5),
    /**
     * <code>DELETE_TABLE_POST_OPERATION = 6;</code>
     */
    DELETE_TABLE_POST_OPERATION(5, 6),
    ;

    /**
     * <code>DELETE_TABLE_PRE_OPERATION = 1;</code>
     */
    public static final int DELETE_TABLE_PRE_OPERATION_VALUE = 1;
    /**
     * <code>DELETE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    public static final int DELETE_TABLE_REMOVE_FROM_META_VALUE = 2;
    /**
     * <code>DELETE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    public static final int DELETE_TABLE_CLEAR_FS_LAYOUT_VALUE = 3;
    /**
     * <code>DELETE_TABLE_UPDATE_DESC_CACHE = 4;</code>
     */
    public static final int DELETE_TABLE_UPDATE_DESC_CACHE_VALUE = 4;
    /**
     * <code>DELETE_TABLE_UNASSIGN_REGIONS = 5;</code>
     */
    public static final int DELETE_TABLE_UNASSIGN_REGIONS_VALUE = 5;
    /**
     * <code>DELETE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int DELETE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() { return value; }

    public static DeleteTableState valueOf(int value) {
      switch (value) {
        case 1: return DELETE_TABLE_PRE_OPERATION;
        case 2: return DELETE_TABLE_REMOVE_FROM_META;
        case 3: return DELETE_TABLE_CLEAR_FS_LAYOUT;
        case 4: return DELETE_TABLE_UPDATE_DESC_CACHE;
        case 5: return DELETE_TABLE_UNASSIGN_REGIONS;
        case 6: return DELETE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<DeleteTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<DeleteTableState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<DeleteTableState>() {
            public DeleteTableState findValueByNumber(int number) {
              return DeleteTableState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(3);
    }

    private static final DeleteTableState[] VALUES = values();

    public static DeleteTableState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private DeleteTableState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DeleteTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.CreateNamespaceState}
   */
  public enum CreateNamespaceState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CREATE_NAMESPACE_PREPARE = 1;</code>
     */
    CREATE_NAMESPACE_PREPARE(0, 1),
    /**
     * <code>CREATE_NAMESPACE_CREATE_DIRECTORY = 2;</code>
     */
    CREATE_NAMESPACE_CREATE_DIRECTORY(1, 2),
    /**
     * <code>CREATE_NAMESPACE_INSERT_INTO_NS_TABLE = 3;</code>
     */
    CREATE_NAMESPACE_INSERT_INTO_NS_TABLE(2, 3),
    /**
     * <code>CREATE_NAMESPACE_UPDATE_ZK = 4;</code>
     */
    CREATE_NAMESPACE_UPDATE_ZK(3, 4),
    /**
     * <code>CREATE_NAMESPACE_SET_NAMESPACE_QUOTA = 5;</code>
     */
    CREATE_NAMESPACE_SET_NAMESPACE_QUOTA(4, 5),
    ;

    /**
     * <code>CREATE_NAMESPACE_PREPARE = 1;</code>
     */
    public static final int CREATE_NAMESPACE_PREPARE_VALUE = 1;
    /**
     * <code>CREATE_NAMESPACE_CREATE_DIRECTORY = 2;</code>
     */
    public static final int CREATE_NAMESPACE_CREATE_DIRECTORY_VALUE = 2;
    /**
     * <code>CREATE_NAMESPACE_INSERT_INTO_NS_TABLE = 3;</code>
     */
    public static final int CREATE_NAMESPACE_INSERT_INTO_NS_TABLE_VALUE = 3;
    /**
     * <code>CREATE_NAMESPACE_UPDATE_ZK = 4;</code>
     */
    public static final int CREATE_NAMESPACE_UPDATE_ZK_VALUE = 4;
    /**
     * <code>CREATE_NAMESPACE_SET_NAMESPACE_QUOTA = 5;</code>
     */
    public static final int CREATE_NAMESPACE_SET_NAMESPACE_QUOTA_VALUE = 5;


    public final int getNumber() { return value; }

    public static CreateNamespaceState valueOf(int value) {
      switch (value) {
        case 1: return CREATE_NAMESPACE_PREPARE;
        case 2: return CREATE_NAMESPACE_CREATE_DIRECTORY;
        case 3: return CREATE_NAMESPACE_INSERT_INTO_NS_TABLE;
        case 4: return CREATE_NAMESPACE_UPDATE_ZK;
        case 5: return CREATE_NAMESPACE_SET_NAMESPACE_QUOTA;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<CreateNamespaceState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<CreateNamespaceState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<CreateNamespaceState>() {
            public CreateNamespaceState findValueByNumber(int number) {
              return CreateNamespaceState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(4);
    }

    private static final CreateNamespaceState[] VALUES = values();

    public static CreateNamespaceState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private CreateNamespaceState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.CreateNamespaceState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ModifyNamespaceState}
   */
  public enum ModifyNamespaceState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MODIFY_NAMESPACE_PREPARE = 1;</code>
     */
    MODIFY_NAMESPACE_PREPARE(0, 1),
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_NS_TABLE = 2;</code>
     */
    MODIFY_NAMESPACE_UPDATE_NS_TABLE(1, 2),
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_ZK = 3;</code>
     */
    MODIFY_NAMESPACE_UPDATE_ZK(2, 3),
    ;

    /**
     * <code>MODIFY_NAMESPACE_PREPARE = 1;</code>
     */
    public static final int MODIFY_NAMESPACE_PREPARE_VALUE = 1;
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_NS_TABLE = 2;</code>
     */
    public static final int MODIFY_NAMESPACE_UPDATE_NS_TABLE_VALUE = 2;
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_ZK = 3;</code>
     */
    public static final int MODIFY_NAMESPACE_UPDATE_ZK_VALUE = 3;


    public final int getNumber() { return value; }

    public static ModifyNamespaceState valueOf(int value) {
      switch (value) {
        case 1: return MODIFY_NAMESPACE_PREPARE;
        case 2: return MODIFY_NAMESPACE_UPDATE_NS_TABLE;
        case 3: return MODIFY_NAMESPACE_UPDATE_ZK;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ModifyNamespaceState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ModifyNamespaceState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ModifyNamespaceState>() {
            public ModifyNamespaceState findValueByNumber(int number) {
              return ModifyNamespaceState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(5);
    }

    private static final ModifyNamespaceState[] VALUES = values();

    public static ModifyNamespaceState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ModifyNamespaceState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ModifyNamespaceState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DeleteNamespaceState}
   */
  public enum DeleteNamespaceState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DELETE_NAMESPACE_PREPARE = 1;</code>
     */
    DELETE_NAMESPACE_PREPARE(0, 1),
    /**
     * <code>DELETE_NAMESPACE_DELETE_FROM_NS_TABLE = 2;</code>
     */
    DELETE_NAMESPACE_DELETE_FROM_NS_TABLE(1, 2),
    /**
     * <code>DELETE_NAMESPACE_REMOVE_FROM_ZK = 3;</code>
     */
    DELETE_NAMESPACE_REMOVE_FROM_ZK(2, 3),
    /**
     * <code>DELETE_NAMESPACE_DELETE_DIRECTORIES = 4;</code>
     */
    DELETE_NAMESPACE_DELETE_DIRECTORIES(3, 4),
    /**
     * <code>DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA = 5;</code>
     */
    DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA(4, 5),
    ;

    /**
     * <code>DELETE_NAMESPACE_PREPARE = 1;</code>
     */
    public static final int DELETE_NAMESPACE_PREPARE_VALUE = 1;
    /**
     * <code>DELETE_NAMESPACE_DELETE_FROM_NS_TABLE = 2;</code>
     */
    public static final int DELETE_NAMESPACE_DELETE_FROM_NS_TABLE_VALUE = 2;
    /**
     * <code>DELETE_NAMESPACE_REMOVE_FROM_ZK = 3;</code>
     */
    public static final int DELETE_NAMESPACE_REMOVE_FROM_ZK_VALUE = 3;
    /**
     * <code>DELETE_NAMESPACE_DELETE_DIRECTORIES = 4;</code>
     */
    public static final int DELETE_NAMESPACE_DELETE_DIRECTORIES_VALUE = 4;
    /**
     * <code>DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA = 5;</code>
     */
    public static final int DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA_VALUE = 5;


    public final int getNumber() { return value; }

    public static DeleteNamespaceState valueOf(int value) {
      switch (value) {
        case 1: return DELETE_NAMESPACE_PREPARE;
        case 2: return DELETE_NAMESPACE_DELETE_FROM_NS_TABLE;
        case 3: return DELETE_NAMESPACE_REMOVE_FROM_ZK;
        case 4: return DELETE_NAMESPACE_DELETE_DIRECTORIES;
        case 5: return DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<DeleteNamespaceState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<DeleteNamespaceState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<DeleteNamespaceState>() {
            public DeleteNamespaceState findValueByNumber(int number) {
              return DeleteNamespaceState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(6);
    }

    private static final DeleteNamespaceState[] VALUES = values();

    public static DeleteNamespaceState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private DeleteNamespaceState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DeleteNamespaceState)
  }

  /**
   * Protobuf enum {@code hbase.pb.AddColumnFamilyState}
   */
  public enum AddColumnFamilyState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ADD_COLUMN_FAMILY_PREPARE = 1;</code>
     */
    ADD_COLUMN_FAMILY_PREPARE(0, 1),
    /**
     * <code>ADD_COLUMN_FAMILY_PRE_OPERATION = 2;</code>
     */
    ADD_COLUMN_FAMILY_PRE_OPERATION(1, 2),
    /**
     * <code>ADD_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    ADD_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR(2, 3),
    /**
     * <code>ADD_COLUMN_FAMILY_POST_OPERATION = 4;</code>
     */
    ADD_COLUMN_FAMILY_POST_OPERATION(3, 4),
    /**
     * <code>ADD_COLUMN_FAMILY_REOPEN_ALL_REGIONS = 5;</code>
     */
    ADD_COLUMN_FAMILY_REOPEN_ALL_REGIONS(4, 5),
    ;

    /**
     * <code>ADD_COLUMN_FAMILY_PREPARE = 1;</code>
     */
    public static final int ADD_COLUMN_FAMILY_PREPARE_VALUE = 1;
    /**
     * <code>ADD_COLUMN_FAMILY_PRE_OPERATION = 2;</code>
     */
    public static final int ADD_COLUMN_FAMILY_PRE_OPERATION_VALUE = 2;
    /**
     * <code>ADD_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    public static final int ADD_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR_VALUE = 3;
    /**
     * <code>ADD_COLUMN_FAMILY_POST_OPERATION = 4;</code>
     */
    public static final int ADD_COLUMN_FAMILY_POST_OPERATION_VALUE = 4;
    /**
     * <code>ADD_COLUMN_FAMILY_REOPEN_ALL_REGIONS = 5;</code>
     */
    public static final int ADD_COLUMN_FAMILY_REOPEN_ALL_REGIONS_VALUE = 5;


    public final int getNumber() { return value; }

    public static AddColumnFamilyState valueOf(int value) {
      switch (value) {
        case 1: return ADD_COLUMN_FAMILY_PREPARE;
        case 2: return ADD_COLUMN_FAMILY_PRE_OPERATION;
        case 3: return ADD_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR;
        case 4: return ADD_COLUMN_FAMILY_POST_OPERATION;
        case 5: return ADD_COLUMN_FAMILY_REOPEN_ALL_REGIONS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<AddColumnFamilyState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<AddColumnFamilyState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<AddColumnFamilyState>() {
            public AddColumnFamilyState findValueByNumber(int number) {
              return AddColumnFamilyState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(7);
    }

    private static final AddColumnFamilyState[] VALUES = values();

    public static AddColumnFamilyState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private AddColumnFamilyState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.AddColumnFamilyState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ModifyColumnFamilyState}
   */
  public enum ModifyColumnFamilyState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MODIFY_COLUMN_FAMILY_PREPARE = 1;</code>
     */
    MODIFY_COLUMN_FAMILY_PREPARE(0, 1),
    /**
     * <code>MODIFY_COLUMN_FAMILY_PRE_OPERATION = 2;</code>
     */
    MODIFY_COLUMN_FAMILY_PRE_OPERATION(1, 2),
    /**
     * <code>MODIFY_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    MODIFY_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR(2, 3),
    /**
     * <code>MODIFY_COLUMN_FAMILY_POST_OPERATION = 4;</code>
     */
    MODIFY_COLUMN_FAMILY_POST_OPERATION(3, 4),
    /**
     * <code>MODIFY_COLUMN_FAMILY_REOPEN_ALL_REGIONS = 5;</code>
     */
    MODIFY_COLUMN_FAMILY_REOPEN_ALL_REGIONS(4, 5),
    ;

    /**
     * <code>MODIFY_COLUMN_FAMILY_PREPARE = 1;</code>
     */
    public static final int MODIFY_COLUMN_FAMILY_PREPARE_VALUE = 1;
    /**
     * <code>MODIFY_COLUMN_FAMILY_PRE_OPERATION = 2;</code>
     */
    public static final int MODIFY_COLUMN_FAMILY_PRE_OPERATION_VALUE = 2;
    /**
     * <code>MODIFY_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    public static final int MODIFY_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR_VALUE = 3;
    /**
     * <code>MODIFY_COLUMN_FAMILY_POST_OPERATION = 4;</code>
     */
    public static final int MODIFY_COLUMN_FAMILY_POST_OPERATION_VALUE = 4;
    /**
     * <code>MODIFY_COLUMN_FAMILY_REOPEN_ALL_REGIONS = 5;</code>
     */
    public static final int MODIFY_COLUMN_FAMILY_REOPEN_ALL_REGIONS_VALUE = 5;


    public final int getNumber() { return value; }

    public static ModifyColumnFamilyState valueOf(int value) {
      switch (value) {
        case 1: return MODIFY_COLUMN_FAMILY_PREPARE;
        case 2: return MODIFY_COLUMN_FAMILY_PRE_OPERATION;
        case 3: return MODIFY_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR;
        case 4: return MODIFY_COLUMN_FAMILY_POST_OPERATION;
        case 5: return MODIFY_COLUMN_FAMILY_REOPEN_ALL_REGIONS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ModifyColumnFamilyState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ModifyColumnFamilyState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ModifyColumnFamilyState>() {
            public ModifyColumnFamilyState findValueByNumber(int number) {
              return ModifyColumnFamilyState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(8);
    }

    private static final ModifyColumnFamilyState[] VALUES = values();

    public static ModifyColumnFamilyState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ModifyColumnFamilyState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ModifyColumnFamilyState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DeleteColumnFamilyState}
   */
  public enum DeleteColumnFamilyState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DELETE_COLUMN_FAMILY_PREPARE = 1;</code>
     */
    DELETE_COLUMN_FAMILY_PREPARE(0, 1),
    /**
     * <code>DELETE_COLUMN_FAMILY_PRE_OPERATION = 2;</code>
     */
    DELETE_COLUMN_FAMILY_PRE_OPERATION(1, 2),
    /**
     * <code>DELETE_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    DELETE_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR(2, 3),
    /**
     * <code>DELETE_COLUMN_FAMILY_DELETE_FS_LAYOUT = 4;</code>
     */
    DELETE_COLUMN_FAMILY_DELETE_FS_LAYOUT(3, 4),
    /**
     * <code>DELETE_COLUMN_FAMILY_POST_OPERATION = 5;</code>
     */
    DELETE_COLUMN_FAMILY_POST_OPERATION(4, 5),
    /**
     * <code>DELETE_COLUMN_FAMILY_REOPEN_ALL_REGIONS = 6;</code>
     */
    DELETE_COLUMN_FAMILY_REOPEN_ALL_REGIONS(5, 6),
    ;

    /**
     * <code>DELETE_COLUMN_FAMILY_PREPARE = 1;</code>
     */
    public static final int DELETE_COLUMN_FAMILY_PREPARE_VALUE = 1;
    /**
     * <code>DELETE_COLUMN_FAMILY_PRE_OPERATION = 2;</code>
     */
    public static final int DELETE_COLUMN_FAMILY_PRE_OPERATION_VALUE = 2;
    /**
     * <code>DELETE_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    public static final int DELETE_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR_VALUE = 3;
    /**
     * <code>DELETE_COLUMN_FAMILY_DELETE_FS_LAYOUT = 4;</code>
     */
    public static final int DELETE_COLUMN_FAMILY_DELETE_FS_LAYOUT_VALUE = 4;
    /**
     * <code>DELETE_COLUMN_FAMILY_POST_OPERATION = 5;</code>
     */
    public static final int DELETE_COLUMN_FAMILY_POST_OPERATION_VALUE = 5;
    /**
     * <code>DELETE_COLUMN_FAMILY_REOPEN_ALL_REGIONS = 6;</code>
     */
    public static final int DELETE_COLUMN_FAMILY_REOPEN_ALL_REGIONS_VALUE = 6;


    public final int getNumber() { return value; }

    public static DeleteColumnFamilyState valueOf(int value) {
      switch (value) {
        case 1: return DELETE_COLUMN_FAMILY_PREPARE;
        case 2: return DELETE_COLUMN_FAMILY_PRE_OPERATION;
        case 3: return DELETE_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR;
        case 4: return DELETE_COLUMN_FAMILY_DELETE_FS_LAYOUT;
        case 5: return DELETE_COLUMN_FAMILY_POST_OPERATION;
        case 6: return DELETE_COLUMN_FAMILY_REOPEN_ALL_REGIONS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<DeleteColumnFamilyState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<DeleteColumnFamilyState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<DeleteColumnFamilyState>() {
            public DeleteColumnFamilyState findValueByNumber(int number) {
              return DeleteColumnFamilyState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(9);
    }

    private static final DeleteColumnFamilyState[] VALUES = values();

    public static DeleteColumnFamilyState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private DeleteColumnFamilyState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DeleteColumnFamilyState)
  }

  /**
   * Protobuf enum {@code hbase.pb.EnableTableState}
   */
  public enum EnableTableState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ENABLE_TABLE_PREPARE = 1;</code>
     */
    ENABLE_TABLE_PREPARE(0, 1),
    /**
     * <code>ENABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    ENABLE_TABLE_PRE_OPERATION(1, 2),
    /**
     * <code>ENABLE_TABLE_SET_ENABLING_TABLE_STATE = 3;</code>
     */
    ENABLE_TABLE_SET_ENABLING_TABLE_STATE(2, 3),
    /**
     * <code>ENABLE_TABLE_MARK_REGIONS_ONLINE = 4;</code>
     */
    ENABLE_TABLE_MARK_REGIONS_ONLINE(3, 4),
    /**
     * <code>ENABLE_TABLE_SET_ENABLED_TABLE_STATE = 5;</code>
     */
    ENABLE_TABLE_SET_ENABLED_TABLE_STATE(4, 5),
    /**
     * <code>ENABLE_TABLE_POST_OPERATION = 6;</code>
     */
    ENABLE_TABLE_POST_OPERATION(5, 6),
    ;

    /**
     * <code>ENABLE_TABLE_PREPARE = 1;</code>
     */
    public static final int ENABLE_TABLE_PREPARE_VALUE = 1;
    /**
     * <code>ENABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    public static final int ENABLE_TABLE_PRE_OPERATION_VALUE = 2;
    /**
     * <code>ENABLE_TABLE_SET_ENABLING_TABLE_STATE = 3;</code>
     */
    public static final int ENABLE_TABLE_SET_ENABLING_TABLE_STATE_VALUE = 3;
    /**
     * <code>ENABLE_TABLE_MARK_REGIONS_ONLINE = 4;</code>
     */
    public static final int ENABLE_TABLE_MARK_REGIONS_ONLINE_VALUE = 4;
    /**
     * <code>ENABLE_TABLE_SET_ENABLED_TABLE_STATE = 5;</code>
     */
    public static final int ENABLE_TABLE_SET_ENABLED_TABLE_STATE_VALUE = 5;
    /**
     * <code>ENABLE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int ENABLE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() { return value; }

    public static EnableTableState valueOf(int value) {
      switch (value) {
        case 1: return ENABLE_TABLE_PREPARE;
        case 2: return ENABLE_TABLE_PRE_OPERATION;
        case 3: return ENABLE_TABLE_SET_ENABLING_TABLE_STATE;
        case 4: return ENABLE_TABLE_MARK_REGIONS_ONLINE;
        case 5: return ENABLE_TABLE_SET_ENABLED_TABLE_STATE;
        case 6: return ENABLE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<EnableTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<EnableTableState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<EnableTableState>() {
            public EnableTableState findValueByNumber(int number) {
              return EnableTableState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(10);
    }

    private static final EnableTableState[] VALUES = values();

    public static EnableTableState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private EnableTableState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.EnableTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DisableTableState}
   */
  public enum DisableTableState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DISABLE_TABLE_PREPARE = 1;</code>
     */
    DISABLE_TABLE_PREPARE(0, 1),
    /**
     * <code>DISABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    DISABLE_TABLE_PRE_OPERATION(1, 2),
    /**
     * <code>DISABLE_TABLE_SET_DISABLING_TABLE_STATE = 3;</code>
     */
    DISABLE_TABLE_SET_DISABLING_TABLE_STATE(2, 3),
    /**
     * <code>DISABLE_TABLE_MARK_REGIONS_OFFLINE = 4;</code>
     */
    DISABLE_TABLE_MARK_REGIONS_OFFLINE(3, 4),
    /**
     * <code>DISABLE_TABLE_SET_DISABLED_TABLE_STATE = 5;</code>
     */
    DISABLE_TABLE_SET_DISABLED_TABLE_STATE(4, 5),
    /**
     * <code>DISABLE_TABLE_POST_OPERATION = 6;</code>
     */
    DISABLE_TABLE_POST_OPERATION(5, 6),
    ;

    /**
     * <code>DISABLE_TABLE_PREPARE = 1;</code>
     */
    public static final int DISABLE_TABLE_PREPARE_VALUE = 1;
    /**
     * <code>DISABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    public static final int DISABLE_TABLE_PRE_OPERATION_VALUE = 2;
    /**
     * <code>DISABLE_TABLE_SET_DISABLING_TABLE_STATE = 3;</code>
     */
    public static final int DISABLE_TABLE_SET_DISABLING_TABLE_STATE_VALUE = 3;
    /**
     * <code>DISABLE_TABLE_MARK_REGIONS_OFFLINE = 4;</code>
     */
    public static final int DISABLE_TABLE_MARK_REGIONS_OFFLINE_VALUE = 4;
    /**
     * <code>DISABLE_TABLE_SET_DISABLED_TABLE_STATE = 5;</code>
     */
    public static final int DISABLE_TABLE_SET_DISABLED_TABLE_STATE_VALUE = 5;
    /**
     * <code>DISABLE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int DISABLE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() { return value; }

    public static DisableTableState valueOf(int value) {
      switch (value) {
        case 1: return DISABLE_TABLE_PREPARE;
        case 2: return DISABLE_TABLE_PRE_OPERATION;
        case 3: return DISABLE_TABLE_SET_DISABLING_TABLE_STATE;
        case 4: return DISABLE_TABLE_MARK_REGIONS_OFFLINE;
        case 5: return DISABLE_TABLE_SET_DISABLED_TABLE_STATE;
        case 6: return DISABLE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<DisableTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<DisableTableState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<DisableTableState>() {
            public DisableTableState findValueByNumber(int number) {
              return DisableTableState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(11);
    }

    private static final DisableTableState[] VALUES = values();

    public static DisableTableState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private DisableTableState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DisableTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ServerCrashState}
   */
  public enum ServerCrashState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>SERVER_CRASH_START = 1;</code>
     */
    SERVER_CRASH_START(0, 1),
    /**
     * <code>SERVER_CRASH_PROCESS_META = 2;</code>
     */
    SERVER_CRASH_PROCESS_META(1, 2),
    /**
     * <code>SERVER_CRASH_GET_REGIONS = 3;</code>
     */
    SERVER_CRASH_GET_REGIONS(2, 3),
    /**
     * <code>SERVER_CRASH_NO_SPLIT_LOGS = 4;</code>
     */
    SERVER_CRASH_NO_SPLIT_LOGS(3, 4),
    /**
     * <code>SERVER_CRASH_SPLIT_LOGS = 5;</code>
     */
    SERVER_CRASH_SPLIT_LOGS(4, 5),
    /**
     * <code>SERVER_CRASH_PREPARE_LOG_REPLAY = 6;</code>
     */
    SERVER_CRASH_PREPARE_LOG_REPLAY(5, 6),
    /**
     * <code>SERVER_CRASH_ASSIGN = 8;</code>
     *
     * <pre>
     * Removed SERVER_CRASH_CALC_REGIONS_TO_ASSIGN = 7;
     * </pre>
     */
    SERVER_CRASH_ASSIGN(6, 8),
    /**
     * <code>SERVER_CRASH_WAIT_ON_ASSIGN = 9;</code>
     */
    SERVER_CRASH_WAIT_ON_ASSIGN(7, 9),
    /**
     * <code>SERVER_CRASH_FINISH = 100;</code>
     */
    SERVER_CRASH_FINISH(8, 100),
    ;

    /**
     * <code>SERVER_CRASH_START = 1;</code>
     */
    public static final int SERVER_CRASH_START_VALUE = 1;
    /**
     * <code>SERVER_CRASH_PROCESS_META = 2;</code>
     */
    public static final int SERVER_CRASH_PROCESS_META_VALUE = 2;
    /**
     * <code>SERVER_CRASH_GET_REGIONS = 3;</code>
     */
    public static final int SERVER_CRASH_GET_REGIONS_VALUE = 3;
    /**
     * <code>SERVER_CRASH_NO_SPLIT_LOGS = 4;</code>
     */
    public static final int SERVER_CRASH_NO_SPLIT_LOGS_VALUE = 4;
    /**
     * <code>SERVER_CRASH_SPLIT_LOGS = 5;</code>
     */
    public static final int SERVER_CRASH_SPLIT_LOGS_VALUE = 5;
    /**
     * <code>SERVER_CRASH_PREPARE_LOG_REPLAY = 6;</code>
     */
    public static final int SERVER_CRASH_PREPARE_LOG_REPLAY_VALUE = 6;
    /**
     * <code>SERVER_CRASH_ASSIGN = 8;</code>
     *
     * <pre>
     * Removed SERVER_CRASH_CALC_REGIONS_TO_ASSIGN = 7;
     * </pre>
     */
    public static final int SERVER_CRASH_ASSIGN_VALUE = 8;
    /**
     * <code>SERVER_CRASH_WAIT_ON_ASSIGN = 9;</code>
     */
    public static final int SERVER_CRASH_WAIT_ON_ASSIGN_VALUE = 9;
    /**
     * <code>SERVER_CRASH_FINISH = 100;</code>
     */
    public static final int SERVER_CRASH_FINISH_VALUE = 100;


    public final int getNumber() { return value; }

    public static ServerCrashState valueOf(int value) {
      switch (value) {
        case 1: return SERVER_CRASH_START;
        case 2: return SERVER_CRASH_PROCESS_META;
        case 3: return SERVER_CRASH_GET_REGIONS;
        case 4: return SERVER_CRASH_NO_SPLIT_LOGS;
        case 5: return SERVER_CRASH_SPLIT_LOGS;
        case 6: return SERVER_CRASH_PREPARE_LOG_REPLAY;
        case 8: return SERVER_CRASH_ASSIGN;
        case 9: return SERVER_CRASH_WAIT_ON_ASSIGN;
        case 100: return SERVER_CRASH_FINISH;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ServerCrashState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<ServerCrashState>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ServerCrashState>() {
            public ServerCrashState findValueByNumber(int number) {
              return ServerCrashState.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(12);
    }

    private static final ServerCrashState[] VALUES = values();

    public static ServerCrashState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private ServerCrashState(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ServerCrashState)
  }

  public interface CreateTableStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.UserInformation user_info = 1;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    // required .hbase.pb.TableSchema table_schema = 2;
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    boolean hasTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder();

    // repeated .hbase.pb.RegionInfo region_info = 3;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.CreateTableStateData}
   */
  public static final class CreateTableStateData extends
      com.google.protobuf.GeneratedMessage
      implements CreateTableStateDataOrBuilder {
    // Use CreateTableStateData.newBuilder() to construct.
    private CreateTableStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private CreateTableStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final CreateTableStateData defaultInstance;
    public static CreateTableStateData getDefaultInstance() {
      return defaultInstance;
    }

    public CreateTableStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private CreateTableStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableSchema_.toBuilder();
              }
              tableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableSchema_);
                tableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              regionInfo_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<CreateTableStateData> PARSER =
        new com.google.protobuf.AbstractParser<CreateTableStateData>() {
      public CreateTableStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CreateTableStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<CreateTableStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.UserInformation user_info = 1;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_;
    }

    // required .hbase.pb.TableSchema table_schema = 2;
    public static final int TABLE_SCHEMA_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    public boolean hasTableSchema() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
      return tableSchema_;
    }
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
      return tableSchema_;
    }

    // repeated .hbase.pb.RegionInfo region_info = 3;
    public static final int REGION_INFO_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private void initFields() {
      userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      tableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
      regionInfo_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableSchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableSchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, tableSchema_);
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(3, regionInfo_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, tableSchema_);
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionInfo_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasTableSchema() == other.hasTableSchema());
      if (hasTableSchema()) {
        result = result && getTableSchema()
            .equals(other.getTableSchema());
      }
      result = result && getRegionInfoList()
          .equals(other.getRegionInfoList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableSchema()) {
        hash = (37 * hash) + TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getTableSchema().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CreateTableStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableSchemaFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableSchemaBuilder_ == null) {
          result.tableSchema_ = tableSchema_;
        } else {
          result.tableSchema_ = tableSchemaBuilder_.build();
        }
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableSchema()) {
          mergeTableSchema(other.getTableSchema());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionInfoBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          
          return false;
        }
        if (!hasTableSchema()) {
          
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          
          return false;
        }
        if (!getTableSchema().isInitialized()) {
          
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.UserInformation user_info = 1;
      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  userInfo_,
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      // required .hbase.pb.TableSchema table_schema = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema tableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> tableSchemaBuilder_;
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public boolean hasTableSchema() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
        if (tableSchemaBuilder_ == null) {
          return tableSchema_;
        } else {
          return tableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder setTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableSchema_ = value;
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder setTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = builderForValue.build();
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder mergeTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            tableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(tableSchema_).mergeFrom(value).buildPartial();
          } else {
            tableSchema_ = value;
          }
          onChanged();
        } else {
          tableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder clearTableSchema() {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
          onChanged();
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getTableSchemaBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
        if (tableSchemaBuilder_ != null) {
          return tableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return tableSchema_;
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getTableSchemaFieldBuilder() {
        if (tableSchemaBuilder_ == null) {
          tableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  tableSchema_,
                  getParentForChildren(),
                  isClean());
          tableSchema_ = null;
        }
        return tableSchemaBuilder_;
      }

      // repeated .hbase.pb.RegionInfo region_info = 3;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          super.addAll(values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.CreateTableStateData)
    }

    static {
      defaultInstance = new CreateTableStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CreateTableStateData)
  }

  public interface ModifyTableStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.UserInformation user_info = 1;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    // optional .hbase.pb.TableSchema unmodified_table_schema = 2;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    boolean hasUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder();

    // required .hbase.pb.TableSchema modified_table_schema = 3;
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    boolean hasModifiedTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder();

    // required bool delete_column_family_in_modify = 4;
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     */
    boolean hasDeleteColumnFamilyInModify();
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     */
    boolean getDeleteColumnFamilyInModify();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyTableStateData}
   */
  public static final class ModifyTableStateData extends
      com.google.protobuf.GeneratedMessage
      implements ModifyTableStateDataOrBuilder {
    // Use ModifyTableStateData.newBuilder() to construct.
    private ModifyTableStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ModifyTableStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ModifyTableStateData defaultInstance;
    public static ModifyTableStateData getDefaultInstance() {
      return defaultInstance;
    }

    public ModifyTableStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ModifyTableStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = unmodifiedTableSchema_.toBuilder();
              }
              unmodifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(unmodifiedTableSchema_);
                unmodifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = modifiedTableSchema_.toBuilder();
              }
              modifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(modifiedTableSchema_);
                modifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              deleteColumnFamilyInModify_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<ModifyTableStateData> PARSER =
        new com.google.protobuf.AbstractParser<ModifyTableStateData>() {
      public ModifyTableStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ModifyTableStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ModifyTableStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.UserInformation user_info = 1;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_;
    }

    // optional .hbase.pb.TableSchema unmodified_table_schema = 2;
    public static final int UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    public boolean hasUnmodifiedTableSchema() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
      return unmodifiedTableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
      return unmodifiedTableSchema_;
    }

    // required .hbase.pb.TableSchema modified_table_schema = 3;
    public static final int MODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_;
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    public boolean hasModifiedTableSchema() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
      return modifiedTableSchema_;
    }
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
      return modifiedTableSchema_;
    }

    // required bool delete_column_family_in_modify = 4;
    public static final int DELETE_COLUMN_FAMILY_IN_MODIFY_FIELD_NUMBER = 4;
    private boolean deleteColumnFamilyInModify_;
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     */
    public boolean hasDeleteColumnFamilyInModify() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     */
    public boolean getDeleteColumnFamilyInModify() {
      return deleteColumnFamilyInModify_;
    }

    private void initFields() {
      userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
      modifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
      deleteColumnFamilyInModify_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasModifiedTableSchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasDeleteColumnFamilyInModify()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (!getModifiedTableSchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, unmodifiedTableSchema_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, modifiedTableSchema_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBool(4, deleteColumnFamilyInModify_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, unmodifiedTableSchema_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, modifiedTableSchema_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, deleteColumnFamilyInModify_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasUnmodifiedTableSchema() == other.hasUnmodifiedTableSchema());
      if (hasUnmodifiedTableSchema()) {
        result = result && getUnmodifiedTableSchema()
            .equals(other.getUnmodifiedTableSchema());
      }
      result = result && (hasModifiedTableSchema() == other.hasModifiedTableSchema());
      if (hasModifiedTableSchema()) {
        result = result && getModifiedTableSchema()
            .equals(other.getModifiedTableSchema());
      }
      result = result && (hasDeleteColumnFamilyInModify() == other.hasDeleteColumnFamilyInModify());
      if (hasDeleteColumnFamilyInModify()) {
        result = result && (getDeleteColumnFamilyInModify()
            == other.getDeleteColumnFamilyInModify());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasUnmodifiedTableSchema()) {
        hash = (37 * hash) + UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedTableSchema().hashCode();
      }
      if (hasModifiedTableSchema()) {
        hash = (37 * hash) + MODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getModifiedTableSchema().hashCode();
      }
      if (hasDeleteColumnFamilyInModify()) {
        hash = (37 * hash) + DELETE_COLUMN_FAMILY_IN_MODIFY_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getDeleteColumnFamilyInModify());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyTableStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getUnmodifiedTableSchemaFieldBuilder();
          getModifiedTableSchemaFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
        } else {
          modifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        deleteColumnFamilyInModify_ = false;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (unmodifiedTableSchemaBuilder_ == null) {
          result.unmodifiedTableSchema_ = unmodifiedTableSchema_;
        } else {
          result.unmodifiedTableSchema_ = unmodifiedTableSchemaBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (modifiedTableSchemaBuilder_ == null) {
          result.modifiedTableSchema_ = modifiedTableSchema_;
        } else {
          result.modifiedTableSchema_ = modifiedTableSchemaBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.deleteColumnFamilyInModify_ = deleteColumnFamilyInModify_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasUnmodifiedTableSchema()) {
          mergeUnmodifiedTableSchema(other.getUnmodifiedTableSchema());
        }
        if (other.hasModifiedTableSchema()) {
          mergeModifiedTableSchema(other.getModifiedTableSchema());
        }
        if (other.hasDeleteColumnFamilyInModify()) {
          setDeleteColumnFamilyInModify(other.getDeleteColumnFamilyInModify());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          
          return false;
        }
        if (!hasModifiedTableSchema()) {
          
          return false;
        }
        if (!hasDeleteColumnFamilyInModify()) {
          
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          
          return false;
        }
        if (hasUnmodifiedTableSchema()) {
          if (!getUnmodifiedTableSchema().isInitialized()) {
            
            return false;
          }
        }
        if (!getModifiedTableSchema().isInitialized()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.UserInformation user_info = 1;
      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  userInfo_,
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      // optional .hbase.pb.TableSchema unmodified_table_schema = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> unmodifiedTableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public boolean hasUnmodifiedTableSchema() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          return unmodifiedTableSchema_;
        } else {
          return unmodifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder setUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedTableSchema_ = value;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder setUnmodifiedTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder mergeUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              unmodifiedTableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            unmodifiedTableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(unmodifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            unmodifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder clearUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getUnmodifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getUnmodifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
        if (unmodifiedTableSchemaBuilder_ != null) {
          return unmodifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedTableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getUnmodifiedTableSchemaFieldBuilder() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  unmodifiedTableSchema_,
                  getParentForChildren(),
                  isClean());
          unmodifiedTableSchema_ = null;
        }
        return unmodifiedTableSchemaBuilder_;
      }

      // required .hbase.pb.TableSchema modified_table_schema = 3;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> modifiedTableSchemaBuilder_;
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public boolean hasModifiedTableSchema() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
        if (modifiedTableSchemaBuilder_ == null) {
          return modifiedTableSchema_;
        } else {
          return modifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder setModifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          modifiedTableSchema_ = value;
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder setModifiedTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder mergeModifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              modifiedTableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            modifiedTableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(modifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            modifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder clearModifiedTableSchema() {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getModifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getModifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
        if (modifiedTableSchemaBuilder_ != null) {
          return modifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return modifiedTableSchema_;
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getModifiedTableSchemaFieldBuilder() {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  modifiedTableSchema_,
                  getParentForChildren(),
                  isClean());
          modifiedTableSchema_ = null;
        }
        return modifiedTableSchemaBuilder_;
      }

      // required bool delete_column_family_in_modify = 4;
      private boolean deleteColumnFamilyInModify_ ;
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       */
      public boolean hasDeleteColumnFamilyInModify() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       */
      public boolean getDeleteColumnFamilyInModify() {
        return deleteColumnFamilyInModify_;
      }
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       */
      public Builder setDeleteColumnFamilyInModify(boolean value) {
        bitField0_ |= 0x00000008;
        deleteColumnFamilyInModify_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       */
      public Builder clearDeleteColumnFamilyInModify() {
        bitField0_ = (bitField0_ & ~0x00000008);
        deleteColumnFamilyInModify_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyTableStateData)
    }

    static {
      defaultInstance = new ModifyTableStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyTableStateData)
  }

  public interface TruncateTableStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.UserInformation user_info = 1;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    // required bool preserve_splits = 2;
    /**
     * <code>required bool preserve_splits = 2;</code>
     */
    boolean hasPreserveSplits();
    /**
     * <code>required bool preserve_splits = 2;</code>
     */
    boolean getPreserveSplits();

    // optional .hbase.pb.TableName table_name = 3;
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    boolean hasTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    // optional .hbase.pb.TableSchema table_schema = 4;
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    boolean hasTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder();

    // repeated .hbase.pb.RegionInfo region_info = 5;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.TruncateTableStateData}
   */
  public static final class TruncateTableStateData extends
      com.google.protobuf.GeneratedMessage
      implements TruncateTableStateDataOrBuilder {
    // Use TruncateTableStateData.newBuilder() to construct.
    private TruncateTableStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private TruncateTableStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final TruncateTableStateData defaultInstance;
    public static TruncateTableStateData getDefaultInstance() {
      return defaultInstance;
    }

    public TruncateTableStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private TruncateTableStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              preserveSplits_ = input.readBool();
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = tableSchema_.toBuilder();
              }
              tableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableSchema_);
                tableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000010;
              }
              regionInfo_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<TruncateTableStateData> PARSER =
        new com.google.protobuf.AbstractParser<TruncateTableStateData>() {
      public TruncateTableStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new TruncateTableStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<TruncateTableStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.UserInformation user_info = 1;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_;
    }

    // required bool preserve_splits = 2;
    public static final int PRESERVE_SPLITS_FIELD_NUMBER = 2;
    private boolean preserveSplits_;
    /**
     * <code>required bool preserve_splits = 2;</code>
     */
    public boolean hasPreserveSplits() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required bool preserve_splits = 2;</code>
     */
    public boolean getPreserveSplits() {
      return preserveSplits_;
    }

    // optional .hbase.pb.TableName table_name = 3;
    public static final int TABLE_NAME_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_;
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_;
    }

    // optional .hbase.pb.TableSchema table_schema = 4;
    public static final int TABLE_SCHEMA_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    public boolean hasTableSchema() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
      return tableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
      return tableSchema_;
    }

    // repeated .hbase.pb.RegionInfo region_info = 5;
    public static final int REGION_INFO_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private void initFields() {
      userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      preserveSplits_ = false;
      tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      tableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
      regionInfo_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasPreserveSplits()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasTableName()) {
        if (!getTableName().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasTableSchema()) {
        if (!getTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, preserveSplits_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, tableName_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, tableSchema_);
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(5, regionInfo_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, preserveSplits_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, tableName_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, tableSchema_);
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, regionInfo_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasPreserveSplits() == other.hasPreserveSplits());
      if (hasPreserveSplits()) {
        result = result && (getPreserveSplits()
            == other.getPreserveSplits());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && (hasTableSchema() == other.hasTableSchema());
      if (hasTableSchema()) {
        result = result && getTableSchema()
            .equals(other.getTableSchema());
      }
      result = result && getRegionInfoList()
          .equals(other.getRegionInfoList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasPreserveSplits()) {
        hash = (37 * hash) + PRESERVE_SPLITS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getPreserveSplits());
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasTableSchema()) {
        hash = (37 * hash) + TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getTableSchema().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.TruncateTableStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getTableSchemaFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        preserveSplits_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.preserveSplits_ = preserveSplits_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (tableSchemaBuilder_ == null) {
          result.tableSchema_ = tableSchema_;
        } else {
          result.tableSchema_ = tableSchemaBuilder_.build();
        }
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasPreserveSplits()) {
          setPreserveSplits(other.getPreserveSplits());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasTableSchema()) {
          mergeTableSchema(other.getTableSchema());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000010);
              regionInfoBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          
          return false;
        }
        if (!hasPreserveSplits()) {
          
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          
          return false;
        }
        if (hasTableName()) {
          if (!getTableName().isInitialized()) {
            
            return false;
          }
        }
        if (hasTableSchema()) {
          if (!getTableSchema().isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.UserInformation user_info = 1;
      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  userInfo_,
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      // required bool preserve_splits = 2;
      private boolean preserveSplits_ ;
      /**
       * <code>required bool preserve_splits = 2;</code>
       */
      public boolean hasPreserveSplits() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required bool preserve_splits = 2;</code>
       */
      public boolean getPreserveSplits() {
        return preserveSplits_;
      }
      /**
       * <code>required bool preserve_splits = 2;</code>
       */
      public Builder setPreserveSplits(boolean value) {
        bitField0_ |= 0x00000002;
        preserveSplits_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool preserve_splits = 2;</code>
       */
      public Builder clearPreserveSplits() {
        bitField0_ = (bitField0_ & ~0x00000002);
        preserveSplits_ = false;
        onChanged();
        return this;
      }

      // optional .hbase.pb.TableName table_name = 3;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  tableName_,
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      // optional .hbase.pb.TableSchema table_schema = 4;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema tableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> tableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public boolean hasTableSchema() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
        if (tableSchemaBuilder_ == null) {
          return tableSchema_;
        } else {
          return tableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder setTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableSchema_ = value;
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder setTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = builderForValue.build();
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder mergeTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              tableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            tableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(tableSchema_).mergeFrom(value).buildPartial();
          } else {
            tableSchema_ = value;
          }
          onChanged();
        } else {
          tableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder clearTableSchema() {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
          onChanged();
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getTableSchemaBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
        if (tableSchemaBuilder_ != null) {
          return tableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return tableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getTableSchemaFieldBuilder() {
        if (tableSchemaBuilder_ == null) {
          tableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  tableSchema_,
                  getParentForChildren(),
                  isClean());
          tableSchema_ = null;
        }
        return tableSchemaBuilder_;
      }

      // repeated .hbase.pb.RegionInfo region_info = 5;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000010;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          super.addAll(values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.TruncateTableStateData)
    }

    static {
      defaultInstance = new TruncateTableStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.TruncateTableStateData)
  }

  public interface DeleteTableStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.UserInformation user_info = 1;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    // required .hbase.pb.TableName table_name = 2;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    // repeated .hbase.pb.RegionInfo region_info = 3;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.DeleteTableStateData}
   */
  public static final class DeleteTableStateData extends
      com.google.protobuf.GeneratedMessage
      implements DeleteTableStateDataOrBuilder {
    // Use DeleteTableStateData.newBuilder() to construct.
    private DeleteTableStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private DeleteTableStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final DeleteTableStateData defaultInstance;
    public static DeleteTableStateData getDefaultInstance() {
      return defaultInstance;
    }

    public DeleteTableStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private DeleteTableStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              regionInfo_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<DeleteTableStateData> PARSER =
        new com.google.protobuf.AbstractParser<DeleteTableStateData>() {
      public DeleteTableStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DeleteTableStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<DeleteTableStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.UserInformation user_info = 1;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_;
    }

    // required .hbase.pb.TableName table_name = 2;
    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_;
    }

    // repeated .hbase.pb.RegionInfo region_info = 3;
    public static final int REGION_INFO_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private void initFields() {
      userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      regionInfo_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, tableName_);
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(3, regionInfo_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, tableName_);
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionInfo_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && getRegionInfoList()
          .equals(other.getRegionInfoList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DeleteTableStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionInfoBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          
          return false;
        }
        if (!hasTableName()) {
          
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          
          return false;
        }
        if (!getTableName().isInitialized()) {
          
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.UserInformation user_info = 1;
      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  userInfo_,
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      // required .hbase.pb.TableName table_name = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  tableName_,
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      // repeated .hbase.pb.RegionInfo region_info = 3;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          super.addAll(values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.DeleteTableStateData)
    }

    static {
      defaultInstance = new DeleteTableStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DeleteTableStateData)
  }

  public interface CreateNamespaceStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    boolean hasNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.CreateNamespaceStateData}
   */
  public static final class CreateNamespaceStateData extends
      com.google.protobuf.GeneratedMessage
      implements CreateNamespaceStateDataOrBuilder {
    // Use CreateNamespaceStateData.newBuilder() to construct.
    private CreateNamespaceStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private CreateNamespaceStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final CreateNamespaceStateData defaultInstance;
    public static CreateNamespaceStateData getDefaultInstance() {
      return defaultInstance;
    }

    public CreateNamespaceStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private CreateNamespaceStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = namespaceDescriptor_.toBuilder();
              }
              namespaceDescriptor_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(namespaceDescriptor_);
                namespaceDescriptor_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<CreateNamespaceStateData> PARSER =
        new com.google.protobuf.AbstractParser<CreateNamespaceStateData>() {
      public CreateNamespaceStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CreateNamespaceStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<CreateNamespaceStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;
    public static final int NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public boolean hasNamespaceDescriptor() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
      return namespaceDescriptor_;
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
      return namespaceDescriptor_;
    }

    private void initFields() {
      namespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasNamespaceDescriptor()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getNamespaceDescriptor().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, namespaceDescriptor_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, namespaceDescriptor_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData) obj;

      boolean result = true;
      result = result && (hasNamespaceDescriptor() == other.hasNamespaceDescriptor());
      if (hasNamespaceDescriptor()) {
        result = result && getNamespaceDescriptor()
            .equals(other.getNamespaceDescriptor());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNamespaceDescriptor()) {
        hash = (37 * hash) + NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceDescriptor().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CreateNamespaceStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNamespaceDescriptorFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (namespaceDescriptorBuilder_ == null) {
          result.namespaceDescriptor_ = namespaceDescriptor_;
        } else {
          result.namespaceDescriptor_ = namespaceDescriptorBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.getDefaultInstance()) return this;
        if (other.hasNamespaceDescriptor()) {
          mergeNamespaceDescriptor(other.getNamespaceDescriptor());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasNamespaceDescriptor()) {
          
          return false;
        }
        if (!getNamespaceDescriptor().isInitialized()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> namespaceDescriptorBuilder_;
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public boolean hasNamespaceDescriptor() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          return namespaceDescriptor_;
        } else {
          return namespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespaceDescriptor_ = value;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = builderForValue.build();
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder mergeNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              namespaceDescriptor_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            namespaceDescriptor_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.newBuilder(namespaceDescriptor_).mergeFrom(value).buildPartial();
          } else {
            namespaceDescriptor_ = value;
          }
          onChanged();
        } else {
          namespaceDescriptorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder clearNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
          onChanged();
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
        if (namespaceDescriptorBuilder_ != null) {
          return namespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return namespaceDescriptor_;
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getNamespaceDescriptorFieldBuilder() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptorBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  namespaceDescriptor_,
                  getParentForChildren(),
                  isClean());
          namespaceDescriptor_ = null;
        }
        return namespaceDescriptorBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.CreateNamespaceStateData)
    }

    static {
      defaultInstance = new CreateNamespaceStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CreateNamespaceStateData)
  }

  public interface ModifyNamespaceStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    boolean hasNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder();

    // optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    boolean hasUnmodifiedNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getUnmodifiedNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getUnmodifiedNamespaceDescriptorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyNamespaceStateData}
   */
  public static final class ModifyNamespaceStateData extends
      com.google.protobuf.GeneratedMessage
      implements ModifyNamespaceStateDataOrBuilder {
    // Use ModifyNamespaceStateData.newBuilder() to construct.
    private ModifyNamespaceStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ModifyNamespaceStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ModifyNamespaceStateData defaultInstance;
    public static ModifyNamespaceStateData getDefaultInstance() {
      return defaultInstance;
    }

    public ModifyNamespaceStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ModifyNamespaceStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = namespaceDescriptor_.toBuilder();
              }
              namespaceDescriptor_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(namespaceDescriptor_);
                namespaceDescriptor_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = unmodifiedNamespaceDescriptor_.toBuilder();
              }
              unmodifiedNamespaceDescriptor_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(unmodifiedNamespaceDescriptor_);
                unmodifiedNamespaceDescriptor_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<ModifyNamespaceStateData> PARSER =
        new com.google.protobuf.AbstractParser<ModifyNamespaceStateData>() {
      public ModifyNamespaceStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ModifyNamespaceStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ModifyNamespaceStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;
    public static final int NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public boolean hasNamespaceDescriptor() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
      return namespaceDescriptor_;
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
      return namespaceDescriptor_;
    }

    // optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;
    public static final int UNMODIFIED_NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor unmodifiedNamespaceDescriptor_;
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    public boolean hasUnmodifiedNamespaceDescriptor() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getUnmodifiedNamespaceDescriptor() {
      return unmodifiedNamespaceDescriptor_;
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getUnmodifiedNamespaceDescriptorOrBuilder() {
      return unmodifiedNamespaceDescriptor_;
    }

    private void initFields() {
      namespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
      unmodifiedNamespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasNamespaceDescriptor()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getNamespaceDescriptor().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedNamespaceDescriptor()) {
        if (!getUnmodifiedNamespaceDescriptor().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, namespaceDescriptor_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, unmodifiedNamespaceDescriptor_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, namespaceDescriptor_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, unmodifiedNamespaceDescriptor_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData) obj;

      boolean result = true;
      result = result && (hasNamespaceDescriptor() == other.hasNamespaceDescriptor());
      if (hasNamespaceDescriptor()) {
        result = result && getNamespaceDescriptor()
            .equals(other.getNamespaceDescriptor());
      }
      result = result && (hasUnmodifiedNamespaceDescriptor() == other.hasUnmodifiedNamespaceDescriptor());
      if (hasUnmodifiedNamespaceDescriptor()) {
        result = result && getUnmodifiedNamespaceDescriptor()
            .equals(other.getUnmodifiedNamespaceDescriptor());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNamespaceDescriptor()) {
        hash = (37 * hash) + NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceDescriptor().hashCode();
      }
      if (hasUnmodifiedNamespaceDescriptor()) {
        hash = (37 * hash) + UNMODIFIED_NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedNamespaceDescriptor().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyNamespaceStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNamespaceDescriptorFieldBuilder();
          getUnmodifiedNamespaceDescriptorFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (namespaceDescriptorBuilder_ == null) {
          result.namespaceDescriptor_ = namespaceDescriptor_;
        } else {
          result.namespaceDescriptor_ = namespaceDescriptorBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          result.unmodifiedNamespaceDescriptor_ = unmodifiedNamespaceDescriptor_;
        } else {
          result.unmodifiedNamespaceDescriptor_ = unmodifiedNamespaceDescriptorBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.getDefaultInstance()) return this;
        if (other.hasNamespaceDescriptor()) {
          mergeNamespaceDescriptor(other.getNamespaceDescriptor());
        }
        if (other.hasUnmodifiedNamespaceDescriptor()) {
          mergeUnmodifiedNamespaceDescriptor(other.getUnmodifiedNamespaceDescriptor());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasNamespaceDescriptor()) {
          
          return false;
        }
        if (!getNamespaceDescriptor().isInitialized()) {
          
          return false;
        }
        if (hasUnmodifiedNamespaceDescriptor()) {
          if (!getUnmodifiedNamespaceDescriptor().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> namespaceDescriptorBuilder_;
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public boolean hasNamespaceDescriptor() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          return namespaceDescriptor_;
        } else {
          return namespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespaceDescriptor_ = value;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = builderForValue.build();
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder mergeNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              namespaceDescriptor_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            namespaceDescriptor_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.newBuilder(namespaceDescriptor_).mergeFrom(value).buildPartial();
          } else {
            namespaceDescriptor_ = value;
          }
          onChanged();
        } else {
          namespaceDescriptorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder clearNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
          onChanged();
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
        if (namespaceDescriptorBuilder_ != null) {
          return namespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return namespaceDescriptor_;
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getNamespaceDescriptorFieldBuilder() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptorBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  namespaceDescriptor_,
                  getParentForChildren(),
                  isClean());
          namespaceDescriptor_ = null;
        }
        return namespaceDescriptorBuilder_;
      }

      // optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor unmodifiedNamespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> unmodifiedNamespaceDescriptorBuilder_;
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public boolean hasUnmodifiedNamespaceDescriptor() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getUnmodifiedNamespaceDescriptor() {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          return unmodifiedNamespaceDescriptor_;
        } else {
          return unmodifiedNamespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder setUnmodifiedNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedNamespaceDescriptor_ = value;
          onChanged();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder setUnmodifiedNamespaceDescriptor(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptor_ = builderForValue.build();
          onChanged();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder mergeUnmodifiedNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              unmodifiedNamespaceDescriptor_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            unmodifiedNamespaceDescriptor_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.newBuilder(unmodifiedNamespaceDescriptor_).mergeFrom(value).buildPartial();
          } else {
            unmodifiedNamespaceDescriptor_ = value;
          }
          onChanged();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder clearUnmodifiedNamespaceDescriptor() {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
          onChanged();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getUnmodifiedNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getUnmodifiedNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getUnmodifiedNamespaceDescriptorOrBuilder() {
        if (unmodifiedNamespaceDescriptorBuilder_ != null) {
          return unmodifiedNamespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedNamespaceDescriptor_;
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getUnmodifiedNamespaceDescriptorFieldBuilder() {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptorBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  unmodifiedNamespaceDescriptor_,
                  getParentForChildren(),
                  isClean());
          unmodifiedNamespaceDescriptor_ = null;
        }
        return unmodifiedNamespaceDescriptorBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyNamespaceStateData)
    }

    static {
      defaultInstance = new ModifyNamespaceStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyNamespaceStateData)
  }

  public interface DeleteNamespaceStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required string namespace_name = 1;
    /**
     * <code>required string namespace_name = 1;</code>
     */
    boolean hasNamespaceName();
    /**
     * <code>required string namespace_name = 1;</code>
     */
    java.lang.String getNamespaceName();
    /**
     * <code>required string namespace_name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNamespaceNameBytes();

    // optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    boolean hasNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.DeleteNamespaceStateData}
   */
  public static final class DeleteNamespaceStateData extends
      com.google.protobuf.GeneratedMessage
      implements DeleteNamespaceStateDataOrBuilder {
    // Use DeleteNamespaceStateData.newBuilder() to construct.
    private DeleteNamespaceStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private DeleteNamespaceStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final DeleteNamespaceStateData defaultInstance;
    public static DeleteNamespaceStateData getDefaultInstance() {
      return defaultInstance;
    }

    public DeleteNamespaceStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private DeleteNamespaceStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              namespaceName_ = input.readBytes();
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = namespaceDescriptor_.toBuilder();
              }
              namespaceDescriptor_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(namespaceDescriptor_);
                namespaceDescriptor_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<DeleteNamespaceStateData> PARSER =
        new com.google.protobuf.AbstractParser<DeleteNamespaceStateData>() {
      public DeleteNamespaceStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DeleteNamespaceStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<DeleteNamespaceStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required string namespace_name = 1;
    public static final int NAMESPACE_NAME_FIELD_NUMBER = 1;
    private java.lang.Object namespaceName_;
    /**
     * <code>required string namespace_name = 1;</code>
     */
    public boolean hasNamespaceName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string namespace_name = 1;</code>
     */
    public java.lang.String getNamespaceName() {
      java.lang.Object ref = namespaceName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          namespaceName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string namespace_name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNamespaceNameBytes() {
      java.lang.Object ref = namespaceName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        namespaceName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;
    public static final int NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    public boolean hasNamespaceDescriptor() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
      return namespaceDescriptor_;
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
      return namespaceDescriptor_;
    }

    private void initFields() {
      namespaceName_ = "";
      namespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasNamespaceName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasNamespaceDescriptor()) {
        if (!getNamespaceDescriptor().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getNamespaceNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, namespaceDescriptor_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getNamespaceNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, namespaceDescriptor_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData) obj;

      boolean result = true;
      result = result && (hasNamespaceName() == other.hasNamespaceName());
      if (hasNamespaceName()) {
        result = result && getNamespaceName()
            .equals(other.getNamespaceName());
      }
      result = result && (hasNamespaceDescriptor() == other.hasNamespaceDescriptor());
      if (hasNamespaceDescriptor()) {
        result = result && getNamespaceDescriptor()
            .equals(other.getNamespaceDescriptor());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNamespaceName()) {
        hash = (37 * hash) + NAMESPACE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceName().hashCode();
      }
      if (hasNamespaceDescriptor()) {
        hash = (37 * hash) + NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceDescriptor().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DeleteNamespaceStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNamespaceDescriptorFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        namespaceName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.namespaceName_ = namespaceName_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (namespaceDescriptorBuilder_ == null) {
          result.namespaceDescriptor_ = namespaceDescriptor_;
        } else {
          result.namespaceDescriptor_ = namespaceDescriptorBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.getDefaultInstance()) return this;
        if (other.hasNamespaceName()) {
          bitField0_ |= 0x00000001;
          namespaceName_ = other.namespaceName_;
          onChanged();
        }
        if (other.hasNamespaceDescriptor()) {
          mergeNamespaceDescriptor(other.getNamespaceDescriptor());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasNamespaceName()) {
          
          return false;
        }
        if (hasNamespaceDescriptor()) {
          if (!getNamespaceDescriptor().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required string namespace_name = 1;
      private java.lang.Object namespaceName_ = "";
      /**
       * <code>required string namespace_name = 1;</code>
       */
      public boolean hasNamespaceName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string namespace_name = 1;</code>
       */
      public java.lang.String getNamespaceName() {
        java.lang.Object ref = namespaceName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          namespaceName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string namespace_name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNamespaceNameBytes() {
        java.lang.Object ref = namespaceName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          namespaceName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string namespace_name = 1;</code>
       */
      public Builder setNamespaceName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        namespaceName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string namespace_name = 1;</code>
       */
      public Builder clearNamespaceName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        namespaceName_ = getDefaultInstance().getNamespaceName();
        onChanged();
        return this;
      }
      /**
       * <code>required string namespace_name = 1;</code>
       */
      public Builder setNamespaceNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        namespaceName_ = value;
        onChanged();
        return this;
      }

      // optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> namespaceDescriptorBuilder_;
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public boolean hasNamespaceDescriptor() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          return namespaceDescriptor_;
        } else {
          return namespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder setNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespaceDescriptor_ = value;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder setNamespaceDescriptor(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = builderForValue.build();
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder mergeNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              namespaceDescriptor_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            namespaceDescriptor_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.newBuilder(namespaceDescriptor_).mergeFrom(value).buildPartial();
          } else {
            namespaceDescriptor_ = value;
          }
          onChanged();
        } else {
          namespaceDescriptorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder clearNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance();
          onChanged();
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
        if (namespaceDescriptorBuilder_ != null) {
          return namespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return namespaceDescriptor_;
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getNamespaceDescriptorFieldBuilder() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptorBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  namespaceDescriptor_,
                  getParentForChildren(),
                  isClean());
          namespaceDescriptor_ = null;
        }
        return namespaceDescriptorBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.DeleteNamespaceStateData)
    }

    static {
      defaultInstance = new DeleteNamespaceStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DeleteNamespaceStateData)
  }

  public interface AddColumnFamilyStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.UserInformation user_info = 1;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    // required .hbase.pb.TableName table_name = 2;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    // required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    boolean hasColumnfamilySchema();
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnfamilySchema();
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnfamilySchemaOrBuilder();

    // optional .hbase.pb.TableSchema unmodified_table_schema = 4;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    boolean hasUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.AddColumnFamilyStateData}
   */
  public static final class AddColumnFamilyStateData extends
      com.google.protobuf.GeneratedMessage
      implements AddColumnFamilyStateDataOrBuilder {
    // Use AddColumnFamilyStateData.newBuilder() to construct.
    private AddColumnFamilyStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private AddColumnFamilyStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final AddColumnFamilyStateData defaultInstance;
    public static AddColumnFamilyStateData getDefaultInstance() {
      return defaultInstance;
    }

    public AddColumnFamilyStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private AddColumnFamilyStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = columnfamilySchema_.toBuilder();
              }
              columnfamilySchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(columnfamilySchema_);
                columnfamilySchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = unmodifiedTableSchema_.toBuilder();
              }
              unmodifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(unmodifiedTableSchema_);
                unmodifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddColumnFamilyStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddColumnFamilyStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<AddColumnFamilyStateData> PARSER =
        new com.google.protobuf.AbstractParser<AddColumnFamilyStateData>() {
      public AddColumnFamilyStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new AddColumnFamilyStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<AddColumnFamilyStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.UserInformation user_info = 1;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_;
    }

    // required .hbase.pb.TableName table_name = 2;
    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_;
    }

    // required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;
    public static final int COLUMNFAMILY_SCHEMA_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema columnfamilySchema_;
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    public boolean hasColumnfamilySchema() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnfamilySchema() {
      return columnfamilySchema_;
    }
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnfamilySchemaOrBuilder() {
      return columnfamilySchema_;
    }

    // optional .hbase.pb.TableSchema unmodified_table_schema = 4;
    public static final int UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    public boolean hasUnmodifiedTableSchema() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
      return unmodifiedTableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
      return unmodifiedTableSchema_;
    }

    private void initFields() {
      userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      columnfamilySchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance();
      unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasColumnfamilySchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getColumnfamilySchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, columnfamilySchema_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, unmodifiedTableSchema_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, columnfamilySchema_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, unmodifiedTableSchema_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && (hasColumnfamilySchema() == other.hasColumnfamilySchema());
      if (hasColumnfamilySchema()) {
        result = result && getColumnfamilySchema()
            .equals(other.getColumnfamilySchema());
      }
      result = result && (hasUnmodifiedTableSchema() == other.hasUnmodifiedTableSchema());
      if (hasUnmodifiedTableSchema()) {
        result = result && getUnmodifiedTableSchema()
            .equals(other.getUnmodifiedTableSchema());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasColumnfamilySchema()) {
        hash = (37 * hash) + COLUMNFAMILY_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getColumnfamilySchema().hashCode();
      }
      if (hasUnmodifiedTableSchema()) {
        hash = (37 * hash) + UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedTableSchema().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.AddColumnFamilyStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddColumnFamilyStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddColumnFamilyStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getColumnfamilySchemaFieldBuilder();
          getUnmodifiedTableSchemaFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance();
        } else {
          columnfamilySchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddColumnFamilyStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (columnfamilySchemaBuilder_ == null) {
          result.columnfamilySchema_ = columnfamilySchema_;
        } else {
          result.columnfamilySchema_ = columnfamilySchemaBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (unmodifiedTableSchemaBuilder_ == null) {
          result.unmodifiedTableSchema_ = unmodifiedTableSchema_;
        } else {
          result.unmodifiedTableSchema_ = unmodifiedTableSchemaBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasColumnfamilySchema()) {
          mergeColumnfamilySchema(other.getColumnfamilySchema());
        }
        if (other.hasUnmodifiedTableSchema()) {
          mergeUnmodifiedTableSchema(other.getUnmodifiedTableSchema());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          
          return false;
        }
        if (!hasTableName()) {
          
          return false;
        }
        if (!hasColumnfamilySchema()) {
          
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          
          return false;
        }
        if (!getTableName().isInitialized()) {
          
          return false;
        }
        if (!getColumnfamilySchema().isInitialized()) {
          
          return false;
        }
        if (hasUnmodifiedTableSchema()) {
          if (!getUnmodifiedTableSchema().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.UserInformation user_info = 1;
      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  userInfo_,
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      // required .hbase.pb.TableName table_name = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  tableName_,
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      // required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema columnfamilySchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> columnfamilySchemaBuilder_;
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public boolean hasColumnfamilySchema() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnfamilySchema() {
        if (columnfamilySchemaBuilder_ == null) {
          return columnfamilySchema_;
        } else {
          return columnfamilySchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder setColumnfamilySchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema value) {
        if (columnfamilySchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          columnfamilySchema_ = value;
          onChanged();
        } else {
          columnfamilySchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder setColumnfamilySchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder builderForValue) {
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchema_ = builderForValue.build();
          onChanged();
        } else {
          columnfamilySchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder mergeColumnfamilySchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema value) {
        if (columnfamilySchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              columnfamilySchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance()) {
            columnfamilySchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.newBuilder(columnfamilySchema_).mergeFrom(value).buildPartial();
          } else {
            columnfamilySchema_ = value;
          }
          onChanged();
        } else {
          columnfamilySchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder clearColumnfamilySchema() {
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance();
          onChanged();
        } else {
          columnfamilySchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder getColumnfamilySchemaBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getColumnfamilySchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnfamilySchemaOrBuilder() {
        if (columnfamilySchemaBuilder_ != null) {
          return columnfamilySchemaBuilder_.getMessageOrBuilder();
        } else {
          return columnfamilySchema_;
        }
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> 
          getColumnfamilySchemaFieldBuilder() {
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchemaBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder>(
                  columnfamilySchema_,
                  getParentForChildren(),
                  isClean());
          columnfamilySchema_ = null;
        }
        return columnfamilySchemaBuilder_;
      }

      // optional .hbase.pb.TableSchema unmodified_table_schema = 4;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> unmodifiedTableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public boolean hasUnmodifiedTableSchema() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          return unmodifiedTableSchema_;
        } else {
          return unmodifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder setUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedTableSchema_ = value;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder setUnmodifiedTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder mergeUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              unmodifiedTableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            unmodifiedTableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(unmodifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            unmodifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder clearUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getUnmodifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getUnmodifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
        if (unmodifiedTableSchemaBuilder_ != null) {
          return unmodifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedTableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getUnmodifiedTableSchemaFieldBuilder() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  unmodifiedTableSchema_,
                  getParentForChildren(),
                  isClean());
          unmodifiedTableSchema_ = null;
        }
        return unmodifiedTableSchemaBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.AddColumnFamilyStateData)
    }

    static {
      defaultInstance = new AddColumnFamilyStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.AddColumnFamilyStateData)
  }

  public interface ModifyColumnFamilyStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.UserInformation user_info = 1;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    // required .hbase.pb.TableName table_name = 2;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    // required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    boolean hasColumnfamilySchema();
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnfamilySchema();
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnfamilySchemaOrBuilder();

    // optional .hbase.pb.TableSchema unmodified_table_schema = 4;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    boolean hasUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyColumnFamilyStateData}
   */
  public static final class ModifyColumnFamilyStateData extends
      com.google.protobuf.GeneratedMessage
      implements ModifyColumnFamilyStateDataOrBuilder {
    // Use ModifyColumnFamilyStateData.newBuilder() to construct.
    private ModifyColumnFamilyStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ModifyColumnFamilyStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ModifyColumnFamilyStateData defaultInstance;
    public static ModifyColumnFamilyStateData getDefaultInstance() {
      return defaultInstance;
    }

    public ModifyColumnFamilyStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ModifyColumnFamilyStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = columnfamilySchema_.toBuilder();
              }
              columnfamilySchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(columnfamilySchema_);
                columnfamilySchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = unmodifiedTableSchema_.toBuilder();
              }
              unmodifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(unmodifiedTableSchema_);
                unmodifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<ModifyColumnFamilyStateData> PARSER =
        new com.google.protobuf.AbstractParser<ModifyColumnFamilyStateData>() {
      public ModifyColumnFamilyStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ModifyColumnFamilyStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ModifyColumnFamilyStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.UserInformation user_info = 1;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_;
    }

    // required .hbase.pb.TableName table_name = 2;
    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_;
    }

    // required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;
    public static final int COLUMNFAMILY_SCHEMA_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema columnfamilySchema_;
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    public boolean hasColumnfamilySchema() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnfamilySchema() {
      return columnfamilySchema_;
    }
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnfamilySchemaOrBuilder() {
      return columnfamilySchema_;
    }

    // optional .hbase.pb.TableSchema unmodified_table_schema = 4;
    public static final int UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    public boolean hasUnmodifiedTableSchema() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
      return unmodifiedTableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
      return unmodifiedTableSchema_;
    }

    private void initFields() {
      userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      columnfamilySchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance();
      unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasColumnfamilySchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getColumnfamilySchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, columnfamilySchema_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, unmodifiedTableSchema_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, columnfamilySchema_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, unmodifiedTableSchema_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && (hasColumnfamilySchema() == other.hasColumnfamilySchema());
      if (hasColumnfamilySchema()) {
        result = result && getColumnfamilySchema()
            .equals(other.getColumnfamilySchema());
      }
      result = result && (hasUnmodifiedTableSchema() == other.hasUnmodifiedTableSchema());
      if (hasUnmodifiedTableSchema()) {
        result = result && getUnmodifiedTableSchema()
            .equals(other.getUnmodifiedTableSchema());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasColumnfamilySchema()) {
        hash = (37 * hash) + COLUMNFAMILY_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getColumnfamilySchema().hashCode();
      }
      if (hasUnmodifiedTableSchema()) {
        hash = (37 * hash) + UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedTableSchema().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyColumnFamilyStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getColumnfamilySchemaFieldBuilder();
          getUnmodifiedTableSchemaFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance();
        } else {
          columnfamilySchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (columnfamilySchemaBuilder_ == null) {
          result.columnfamilySchema_ = columnfamilySchema_;
        } else {
          result.columnfamilySchema_ = columnfamilySchemaBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (unmodifiedTableSchemaBuilder_ == null) {
          result.unmodifiedTableSchema_ = unmodifiedTableSchema_;
        } else {
          result.unmodifiedTableSchema_ = unmodifiedTableSchemaBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasColumnfamilySchema()) {
          mergeColumnfamilySchema(other.getColumnfamilySchema());
        }
        if (other.hasUnmodifiedTableSchema()) {
          mergeUnmodifiedTableSchema(other.getUnmodifiedTableSchema());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          
          return false;
        }
        if (!hasTableName()) {
          
          return false;
        }
        if (!hasColumnfamilySchema()) {
          
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          
          return false;
        }
        if (!getTableName().isInitialized()) {
          
          return false;
        }
        if (!getColumnfamilySchema().isInitialized()) {
          
          return false;
        }
        if (hasUnmodifiedTableSchema()) {
          if (!getUnmodifiedTableSchema().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.UserInformation user_info = 1;
      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  userInfo_,
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      // required .hbase.pb.TableName table_name = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  tableName_,
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      // required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema columnfamilySchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> columnfamilySchemaBuilder_;
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public boolean hasColumnfamilySchema() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnfamilySchema() {
        if (columnfamilySchemaBuilder_ == null) {
          return columnfamilySchema_;
        } else {
          return columnfamilySchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder setColumnfamilySchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema value) {
        if (columnfamilySchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          columnfamilySchema_ = value;
          onChanged();
        } else {
          columnfamilySchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder setColumnfamilySchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder builderForValue) {
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchema_ = builderForValue.build();
          onChanged();
        } else {
          columnfamilySchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder mergeColumnfamilySchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema value) {
        if (columnfamilySchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              columnfamilySchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance()) {
            columnfamilySchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.newBuilder(columnfamilySchema_).mergeFrom(value).buildPartial();
          } else {
            columnfamilySchema_ = value;
          }
          onChanged();
        } else {
          columnfamilySchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder clearColumnfamilySchema() {
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance();
          onChanged();
        } else {
          columnfamilySchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder getColumnfamilySchemaBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getColumnfamilySchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnfamilySchemaOrBuilder() {
        if (columnfamilySchemaBuilder_ != null) {
          return columnfamilySchemaBuilder_.getMessageOrBuilder();
        } else {
          return columnfamilySchema_;
        }
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> 
          getColumnfamilySchemaFieldBuilder() {
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchemaBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder>(
                  columnfamilySchema_,
                  getParentForChildren(),
                  isClean());
          columnfamilySchema_ = null;
        }
        return columnfamilySchemaBuilder_;
      }

      // optional .hbase.pb.TableSchema unmodified_table_schema = 4;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> unmodifiedTableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public boolean hasUnmodifiedTableSchema() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          return unmodifiedTableSchema_;
        } else {
          return unmodifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder setUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedTableSchema_ = value;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder setUnmodifiedTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder mergeUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              unmodifiedTableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            unmodifiedTableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(unmodifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            unmodifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder clearUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getUnmodifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getUnmodifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
        if (unmodifiedTableSchemaBuilder_ != null) {
          return unmodifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedTableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getUnmodifiedTableSchemaFieldBuilder() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  unmodifiedTableSchema_,
                  getParentForChildren(),
                  isClean());
          unmodifiedTableSchema_ = null;
        }
        return unmodifiedTableSchemaBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyColumnFamilyStateData)
    }

    static {
      defaultInstance = new ModifyColumnFamilyStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyColumnFamilyStateData)
  }

  public interface DeleteColumnFamilyStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.UserInformation user_info = 1;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    // required .hbase.pb.TableName table_name = 2;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    // required bytes columnfamily_name = 3;
    /**
     * <code>required bytes columnfamily_name = 3;</code>
     */
    boolean hasColumnfamilyName();
    /**
     * <code>required bytes columnfamily_name = 3;</code>
     */
    com.google.protobuf.ByteString getColumnfamilyName();

    // optional .hbase.pb.TableSchema unmodified_table_schema = 4;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    boolean hasUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.DeleteColumnFamilyStateData}
   */
  public static final class DeleteColumnFamilyStateData extends
      com.google.protobuf.GeneratedMessage
      implements DeleteColumnFamilyStateDataOrBuilder {
    // Use DeleteColumnFamilyStateData.newBuilder() to construct.
    private DeleteColumnFamilyStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private DeleteColumnFamilyStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final DeleteColumnFamilyStateData defaultInstance;
    public static DeleteColumnFamilyStateData getDefaultInstance() {
      return defaultInstance;
    }

    public DeleteColumnFamilyStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private DeleteColumnFamilyStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              columnfamilyName_ = input.readBytes();
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = unmodifiedTableSchema_.toBuilder();
              }
              unmodifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(unmodifiedTableSchema_);
                unmodifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteColumnFamilyStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteColumnFamilyStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<DeleteColumnFamilyStateData> PARSER =
        new com.google.protobuf.AbstractParser<DeleteColumnFamilyStateData>() {
      public DeleteColumnFamilyStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DeleteColumnFamilyStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<DeleteColumnFamilyStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.UserInformation user_info = 1;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_;
    }

    // required .hbase.pb.TableName table_name = 2;
    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_;
    }

    // required bytes columnfamily_name = 3;
    public static final int COLUMNFAMILY_NAME_FIELD_NUMBER = 3;
    private com.google.protobuf.ByteString columnfamilyName_;
    /**
     * <code>required bytes columnfamily_name = 3;</code>
     */
    public boolean hasColumnfamilyName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required bytes columnfamily_name = 3;</code>
     */
    public com.google.protobuf.ByteString getColumnfamilyName() {
      return columnfamilyName_;
    }

    // optional .hbase.pb.TableSchema unmodified_table_schema = 4;
    public static final int UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    public boolean hasUnmodifiedTableSchema() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
      return unmodifiedTableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
      return unmodifiedTableSchema_;
    }

    private void initFields() {
      userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      columnfamilyName_ = com.google.protobuf.ByteString.EMPTY;
      unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasColumnfamilyName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, columnfamilyName_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, unmodifiedTableSchema_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, columnfamilyName_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, unmodifiedTableSchema_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && (hasColumnfamilyName() == other.hasColumnfamilyName());
      if (hasColumnfamilyName()) {
        result = result && getColumnfamilyName()
            .equals(other.getColumnfamilyName());
      }
      result = result && (hasUnmodifiedTableSchema() == other.hasUnmodifiedTableSchema());
      if (hasUnmodifiedTableSchema()) {
        result = result && getUnmodifiedTableSchema()
            .equals(other.getUnmodifiedTableSchema());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasColumnfamilyName()) {
        hash = (37 * hash) + COLUMNFAMILY_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getColumnfamilyName().hashCode();
      }
      if (hasUnmodifiedTableSchema()) {
        hash = (37 * hash) + UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedTableSchema().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DeleteColumnFamilyStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteColumnFamilyStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteColumnFamilyStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getUnmodifiedTableSchemaFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        columnfamilyName_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteColumnFamilyStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.columnfamilyName_ = columnfamilyName_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (unmodifiedTableSchemaBuilder_ == null) {
          result.unmodifiedTableSchema_ = unmodifiedTableSchema_;
        } else {
          result.unmodifiedTableSchema_ = unmodifiedTableSchemaBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasColumnfamilyName()) {
          setColumnfamilyName(other.getColumnfamilyName());
        }
        if (other.hasUnmodifiedTableSchema()) {
          mergeUnmodifiedTableSchema(other.getUnmodifiedTableSchema());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          
          return false;
        }
        if (!hasTableName()) {
          
          return false;
        }
        if (!hasColumnfamilyName()) {
          
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          
          return false;
        }
        if (!getTableName().isInitialized()) {
          
          return false;
        }
        if (hasUnmodifiedTableSchema()) {
          if (!getUnmodifiedTableSchema().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.UserInformation user_info = 1;
      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  userInfo_,
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      // required .hbase.pb.TableName table_name = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  tableName_,
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      // required bytes columnfamily_name = 3;
      private com.google.protobuf.ByteString columnfamilyName_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes columnfamily_name = 3;</code>
       */
      public boolean hasColumnfamilyName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required bytes columnfamily_name = 3;</code>
       */
      public com.google.protobuf.ByteString getColumnfamilyName() {
        return columnfamilyName_;
      }
      /**
       * <code>required bytes columnfamily_name = 3;</code>
       */
      public Builder setColumnfamilyName(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        columnfamilyName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes columnfamily_name = 3;</code>
       */
      public Builder clearColumnfamilyName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        columnfamilyName_ = getDefaultInstance().getColumnfamilyName();
        onChanged();
        return this;
      }

      // optional .hbase.pb.TableSchema unmodified_table_schema = 4;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> unmodifiedTableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public boolean hasUnmodifiedTableSchema() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          return unmodifiedTableSchema_;
        } else {
          return unmodifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder setUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedTableSchema_ = value;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder setUnmodifiedTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder mergeUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              unmodifiedTableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            unmodifiedTableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(unmodifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            unmodifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder clearUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getUnmodifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getUnmodifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
        if (unmodifiedTableSchemaBuilder_ != null) {
          return unmodifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedTableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getUnmodifiedTableSchemaFieldBuilder() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  unmodifiedTableSchema_,
                  getParentForChildren(),
                  isClean());
          unmodifiedTableSchema_ = null;
        }
        return unmodifiedTableSchemaBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.DeleteColumnFamilyStateData)
    }

    static {
      defaultInstance = new DeleteColumnFamilyStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DeleteColumnFamilyStateData)
  }

  public interface EnableTableStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.UserInformation user_info = 1;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    // required .hbase.pb.TableName table_name = 2;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    // required bool skip_table_state_check = 3;
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     */
    boolean hasSkipTableStateCheck();
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     */
    boolean getSkipTableStateCheck();
  }
  /**
   * Protobuf type {@code hbase.pb.EnableTableStateData}
   */
  public static final class EnableTableStateData extends
      com.google.protobuf.GeneratedMessage
      implements EnableTableStateDataOrBuilder {
    // Use EnableTableStateData.newBuilder() to construct.
    private EnableTableStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private EnableTableStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final EnableTableStateData defaultInstance;
    public static EnableTableStateData getDefaultInstance() {
      return defaultInstance;
    }

    public EnableTableStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private EnableTableStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              skipTableStateCheck_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<EnableTableStateData> PARSER =
        new com.google.protobuf.AbstractParser<EnableTableStateData>() {
      public EnableTableStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new EnableTableStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<EnableTableStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.UserInformation user_info = 1;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_;
    }

    // required .hbase.pb.TableName table_name = 2;
    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_;
    }

    // required bool skip_table_state_check = 3;
    public static final int SKIP_TABLE_STATE_CHECK_FIELD_NUMBER = 3;
    private boolean skipTableStateCheck_;
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     */
    public boolean hasSkipTableStateCheck() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     */
    public boolean getSkipTableStateCheck() {
      return skipTableStateCheck_;
    }

    private void initFields() {
      userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      skipTableStateCheck_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSkipTableStateCheck()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, skipTableStateCheck_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, skipTableStateCheck_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && (hasSkipTableStateCheck() == other.hasSkipTableStateCheck());
      if (hasSkipTableStateCheck()) {
        result = result && (getSkipTableStateCheck()
            == other.getSkipTableStateCheck());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasSkipTableStateCheck()) {
        hash = (37 * hash) + SKIP_TABLE_STATE_CHECK_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getSkipTableStateCheck());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.EnableTableStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        skipTableStateCheck_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.skipTableStateCheck_ = skipTableStateCheck_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasSkipTableStateCheck()) {
          setSkipTableStateCheck(other.getSkipTableStateCheck());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          
          return false;
        }
        if (!hasTableName()) {
          
          return false;
        }
        if (!hasSkipTableStateCheck()) {
          
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          
          return false;
        }
        if (!getTableName().isInitialized()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.UserInformation user_info = 1;
      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  userInfo_,
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      // required .hbase.pb.TableName table_name = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  tableName_,
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      // required bool skip_table_state_check = 3;
      private boolean skipTableStateCheck_ ;
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       */
      public boolean hasSkipTableStateCheck() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       */
      public boolean getSkipTableStateCheck() {
        return skipTableStateCheck_;
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       */
      public Builder setSkipTableStateCheck(boolean value) {
        bitField0_ |= 0x00000004;
        skipTableStateCheck_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       */
      public Builder clearSkipTableStateCheck() {
        bitField0_ = (bitField0_ & ~0x00000004);
        skipTableStateCheck_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.EnableTableStateData)
    }

    static {
      defaultInstance = new EnableTableStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.EnableTableStateData)
  }

  public interface DisableTableStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.UserInformation user_info = 1;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    // required .hbase.pb.TableName table_name = 2;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    // required bool skip_table_state_check = 3;
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     */
    boolean hasSkipTableStateCheck();
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     */
    boolean getSkipTableStateCheck();
  }
  /**
   * Protobuf type {@code hbase.pb.DisableTableStateData}
   */
  public static final class DisableTableStateData extends
      com.google.protobuf.GeneratedMessage
      implements DisableTableStateDataOrBuilder {
    // Use DisableTableStateData.newBuilder() to construct.
    private DisableTableStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private DisableTableStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final DisableTableStateData defaultInstance;
    public static DisableTableStateData getDefaultInstance() {
      return defaultInstance;
    }

    public DisableTableStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private DisableTableStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              skipTableStateCheck_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<DisableTableStateData> PARSER =
        new com.google.protobuf.AbstractParser<DisableTableStateData>() {
      public DisableTableStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DisableTableStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<DisableTableStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.UserInformation user_info = 1;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_;
    }

    // required .hbase.pb.TableName table_name = 2;
    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_;
    }

    // required bool skip_table_state_check = 3;
    public static final int SKIP_TABLE_STATE_CHECK_FIELD_NUMBER = 3;
    private boolean skipTableStateCheck_;
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     */
    public boolean hasSkipTableStateCheck() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     */
    public boolean getSkipTableStateCheck() {
      return skipTableStateCheck_;
    }

    private void initFields() {
      userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      skipTableStateCheck_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSkipTableStateCheck()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, skipTableStateCheck_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, skipTableStateCheck_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData) obj;

      boolean result = true;
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && (hasSkipTableStateCheck() == other.hasSkipTableStateCheck());
      if (hasSkipTableStateCheck()) {
        result = result && (getSkipTableStateCheck()
            == other.getSkipTableStateCheck());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasSkipTableStateCheck()) {
        hash = (37 * hash) + SKIP_TABLE_STATE_CHECK_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getSkipTableStateCheck());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DisableTableStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        skipTableStateCheck_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userInfoBuilder_ == null) {
          result.userInfo_ = userInfo_;
        } else {
          result.userInfo_ = userInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.skipTableStateCheck_ = skipTableStateCheck_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasSkipTableStateCheck()) {
          setSkipTableStateCheck(other.getSkipTableStateCheck());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          
          return false;
        }
        if (!hasTableName()) {
          
          return false;
        }
        if (!hasSkipTableStateCheck()) {
          
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          
          return false;
        }
        if (!getTableName().isInitialized()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.UserInformation user_info = 1;
      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance();
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  userInfo_,
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      // required .hbase.pb.TableName table_name = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  tableName_,
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      // required bool skip_table_state_check = 3;
      private boolean skipTableStateCheck_ ;
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       */
      public boolean hasSkipTableStateCheck() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       */
      public boolean getSkipTableStateCheck() {
        return skipTableStateCheck_;
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       */
      public Builder setSkipTableStateCheck(boolean value) {
        bitField0_ |= 0x00000004;
        skipTableStateCheck_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       */
      public Builder clearSkipTableStateCheck() {
        bitField0_ = (bitField0_ & ~0x00000004);
        skipTableStateCheck_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.DisableTableStateData)
    }

    static {
      defaultInstance = new DisableTableStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DisableTableStateData)
  }

  public interface ServerCrashStateDataOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.ServerName server_name = 1;
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    boolean hasServerName();
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getServerName();
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder();

    // optional bool distributed_log_replay = 2;
    /**
     * <code>optional bool distributed_log_replay = 2;</code>
     */
    boolean hasDistributedLogReplay();
    /**
     * <code>optional bool distributed_log_replay = 2;</code>
     */
    boolean getDistributedLogReplay();

    // repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionsOnCrashedServerList();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionsOnCrashedServer(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    int getRegionsOnCrashedServerCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsOnCrashedServerOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsOnCrashedServerOrBuilder(
        int index);

    // repeated .hbase.pb.RegionInfo regions_assigned = 4;
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionsAssignedList();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionsAssigned(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    int getRegionsAssignedCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsAssignedOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsAssignedOrBuilder(
        int index);

    // optional bool carrying_meta = 5;
    /**
     * <code>optional bool carrying_meta = 5;</code>
     */
    boolean hasCarryingMeta();
    /**
     * <code>optional bool carrying_meta = 5;</code>
     */
    boolean getCarryingMeta();

    // optional bool should_split_wal = 6 [default = true];
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     */
    boolean hasShouldSplitWal();
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     */
    boolean getShouldSplitWal();
  }
  /**
   * Protobuf type {@code hbase.pb.ServerCrashStateData}
   */
  public static final class ServerCrashStateData extends
      com.google.protobuf.GeneratedMessage
      implements ServerCrashStateDataOrBuilder {
    // Use ServerCrashStateData.newBuilder() to construct.
    private ServerCrashStateData(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ServerCrashStateData(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ServerCrashStateData defaultInstance;
    public static ServerCrashStateData getDefaultInstance() {
      return defaultInstance;
    }

    public ServerCrashStateData getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ServerCrashStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = serverName_.toBuilder();
              }
              serverName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(serverName_);
                serverName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              distributedLogReplay_ = input.readBool();
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                regionsOnCrashedServer_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              regionsOnCrashedServer_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                regionsAssigned_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000008;
              }
              regionsAssigned_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 40: {
              bitField0_ |= 0x00000004;
              carryingMeta_ = input.readBool();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000008;
              shouldSplitWal_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          regionsOnCrashedServer_ = java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
        }
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          regionsAssigned_ = java.util.Collections.unmodifiableList(regionsAssigned_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.Builder.class);
    }

    public static com.google.protobuf.Parser<ServerCrashStateData> PARSER =
        new com.google.protobuf.AbstractParser<ServerCrashStateData>() {
      public ServerCrashStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ServerCrashStateData(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ServerCrashStateData> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.ServerName server_name = 1;
    public static final int SERVER_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName serverName_;
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    public boolean hasServerName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getServerName() {
      return serverName_;
    }
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
      return serverName_;
    }

    // optional bool distributed_log_replay = 2;
    public static final int DISTRIBUTED_LOG_REPLAY_FIELD_NUMBER = 2;
    private boolean distributedLogReplay_;
    /**
     * <code>optional bool distributed_log_replay = 2;</code>
     */
    public boolean hasDistributedLogReplay() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool distributed_log_replay = 2;</code>
     */
    public boolean getDistributedLogReplay() {
      return distributedLogReplay_;
    }

    // repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;
    public static final int REGIONS_ON_CRASHED_SERVER_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionsOnCrashedServer_;
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionsOnCrashedServerList() {
      return regionsOnCrashedServer_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsOnCrashedServerOrBuilderList() {
      return regionsOnCrashedServer_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public int getRegionsOnCrashedServerCount() {
      return regionsOnCrashedServer_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionsOnCrashedServer(int index) {
      return regionsOnCrashedServer_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsOnCrashedServerOrBuilder(
        int index) {
      return regionsOnCrashedServer_.get(index);
    }

    // repeated .hbase.pb.RegionInfo regions_assigned = 4;
    public static final int REGIONS_ASSIGNED_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionsAssigned_;
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionsAssignedList() {
      return regionsAssigned_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsAssignedOrBuilderList() {
      return regionsAssigned_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public int getRegionsAssignedCount() {
      return regionsAssigned_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionsAssigned(int index) {
      return regionsAssigned_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsAssignedOrBuilder(
        int index) {
      return regionsAssigned_.get(index);
    }

    // optional bool carrying_meta = 5;
    public static final int CARRYING_META_FIELD_NUMBER = 5;
    private boolean carryingMeta_;
    /**
     * <code>optional bool carrying_meta = 5;</code>
     */
    public boolean hasCarryingMeta() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bool carrying_meta = 5;</code>
     */
    public boolean getCarryingMeta() {
      return carryingMeta_;
    }

    // optional bool should_split_wal = 6 [default = true];
    public static final int SHOULD_SPLIT_WAL_FIELD_NUMBER = 6;
    private boolean shouldSplitWal_;
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     */
    public boolean hasShouldSplitWal() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     */
    public boolean getShouldSplitWal() {
      return shouldSplitWal_;
    }

    private void initFields() {
      serverName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
      distributedLogReplay_ = false;
      regionsOnCrashedServer_ = java.util.Collections.emptyList();
      regionsAssigned_ = java.util.Collections.emptyList();
      carryingMeta_ = false;
      shouldSplitWal_ = true;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasServerName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getServerName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionsOnCrashedServerCount(); i++) {
        if (!getRegionsOnCrashedServer(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionsAssignedCount(); i++) {
        if (!getRegionsAssigned(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, serverName_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, distributedLogReplay_);
      }
      for (int i = 0; i < regionsOnCrashedServer_.size(); i++) {
        output.writeMessage(3, regionsOnCrashedServer_.get(i));
      }
      for (int i = 0; i < regionsAssigned_.size(); i++) {
        output.writeMessage(4, regionsAssigned_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(5, carryingMeta_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBool(6, shouldSplitWal_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, serverName_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, distributedLogReplay_);
      }
      for (int i = 0; i < regionsOnCrashedServer_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionsOnCrashedServer_.get(i));
      }
      for (int i = 0; i < regionsAssigned_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, regionsAssigned_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, carryingMeta_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, shouldSplitWal_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData) obj;

      boolean result = true;
      result = result && (hasServerName() == other.hasServerName());
      if (hasServerName()) {
        result = result && getServerName()
            .equals(other.getServerName());
      }
      result = result && (hasDistributedLogReplay() == other.hasDistributedLogReplay());
      if (hasDistributedLogReplay()) {
        result = result && (getDistributedLogReplay()
            == other.getDistributedLogReplay());
      }
      result = result && getRegionsOnCrashedServerList()
          .equals(other.getRegionsOnCrashedServerList());
      result = result && getRegionsAssignedList()
          .equals(other.getRegionsAssignedList());
      result = result && (hasCarryingMeta() == other.hasCarryingMeta());
      if (hasCarryingMeta()) {
        result = result && (getCarryingMeta()
            == other.getCarryingMeta());
      }
      result = result && (hasShouldSplitWal() == other.hasShouldSplitWal());
      if (hasShouldSplitWal()) {
        result = result && (getShouldSplitWal()
            == other.getShouldSplitWal());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasServerName()) {
        hash = (37 * hash) + SERVER_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getServerName().hashCode();
      }
      if (hasDistributedLogReplay()) {
        hash = (37 * hash) + DISTRIBUTED_LOG_REPLAY_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getDistributedLogReplay());
      }
      if (getRegionsOnCrashedServerCount() > 0) {
        hash = (37 * hash) + REGIONS_ON_CRASHED_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getRegionsOnCrashedServerList().hashCode();
      }
      if (getRegionsAssignedCount() > 0) {
        hash = (37 * hash) + REGIONS_ASSIGNED_FIELD_NUMBER;
        hash = (53 * hash) + getRegionsAssignedList().hashCode();
      }
      if (hasCarryingMeta()) {
        hash = (37 * hash) + CARRYING_META_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getCarryingMeta());
      }
      if (hasShouldSplitWal()) {
        hash = (37 * hash) + SHOULD_SPLIT_WAL_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getShouldSplitWal());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ServerCrashStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getServerNameFieldBuilder();
          getRegionsOnCrashedServerFieldBuilder();
          getRegionsAssignedFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (serverNameBuilder_ == null) {
          serverName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
        } else {
          serverNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        distributedLogReplay_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (regionsOnCrashedServerBuilder_ == null) {
          regionsOnCrashedServer_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          regionsOnCrashedServerBuilder_.clear();
        }
        if (regionsAssignedBuilder_ == null) {
          regionsAssigned_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          regionsAssignedBuilder_.clear();
        }
        carryingMeta_ = false;
        bitField0_ = (bitField0_ & ~0x00000010);
        shouldSplitWal_ = true;
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (serverNameBuilder_ == null) {
          result.serverName_ = serverName_;
        } else {
          result.serverName_ = serverNameBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.distributedLogReplay_ = distributedLogReplay_;
        if (regionsOnCrashedServerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            regionsOnCrashedServer_ = java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionsOnCrashedServer_ = regionsOnCrashedServer_;
        } else {
          result.regionsOnCrashedServer_ = regionsOnCrashedServerBuilder_.build();
        }
        if (regionsAssignedBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            regionsAssigned_ = java.util.Collections.unmodifiableList(regionsAssigned_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.regionsAssigned_ = regionsAssigned_;
        } else {
          result.regionsAssigned_ = regionsAssignedBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000004;
        }
        result.carryingMeta_ = carryingMeta_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000008;
        }
        result.shouldSplitWal_ = shouldSplitWal_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.getDefaultInstance()) return this;
        if (other.hasServerName()) {
          mergeServerName(other.getServerName());
        }
        if (other.hasDistributedLogReplay()) {
          setDistributedLogReplay(other.getDistributedLogReplay());
        }
        if (regionsOnCrashedServerBuilder_ == null) {
          if (!other.regionsOnCrashedServer_.isEmpty()) {
            if (regionsOnCrashedServer_.isEmpty()) {
              regionsOnCrashedServer_ = other.regionsOnCrashedServer_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionsOnCrashedServerIsMutable();
              regionsOnCrashedServer_.addAll(other.regionsOnCrashedServer_);
            }
            onChanged();
          }
        } else {
          if (!other.regionsOnCrashedServer_.isEmpty()) {
            if (regionsOnCrashedServerBuilder_.isEmpty()) {
              regionsOnCrashedServerBuilder_.dispose();
              regionsOnCrashedServerBuilder_ = null;
              regionsOnCrashedServer_ = other.regionsOnCrashedServer_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionsOnCrashedServerBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getRegionsOnCrashedServerFieldBuilder() : null;
            } else {
              regionsOnCrashedServerBuilder_.addAllMessages(other.regionsOnCrashedServer_);
            }
          }
        }
        if (regionsAssignedBuilder_ == null) {
          if (!other.regionsAssigned_.isEmpty()) {
            if (regionsAssigned_.isEmpty()) {
              regionsAssigned_ = other.regionsAssigned_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureRegionsAssignedIsMutable();
              regionsAssigned_.addAll(other.regionsAssigned_);
            }
            onChanged();
          }
        } else {
          if (!other.regionsAssigned_.isEmpty()) {
            if (regionsAssignedBuilder_.isEmpty()) {
              regionsAssignedBuilder_.dispose();
              regionsAssignedBuilder_ = null;
              regionsAssigned_ = other.regionsAssigned_;
              bitField0_ = (bitField0_ & ~0x00000008);
              regionsAssignedBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getRegionsAssignedFieldBuilder() : null;
            } else {
              regionsAssignedBuilder_.addAllMessages(other.regionsAssigned_);
            }
          }
        }
        if (other.hasCarryingMeta()) {
          setCarryingMeta(other.getCarryingMeta());
        }
        if (other.hasShouldSplitWal()) {
          setShouldSplitWal(other.getShouldSplitWal());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasServerName()) {
          
          return false;
        }
        if (!getServerName().isInitialized()) {
          
          return false;
        }
        for (int i = 0; i < getRegionsOnCrashedServerCount(); i++) {
          if (!getRegionsOnCrashedServer(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getRegionsAssignedCount(); i++) {
          if (!getRegionsAssigned(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.ServerName server_name = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName serverName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> serverNameBuilder_;
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public boolean hasServerName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getServerName() {
        if (serverNameBuilder_ == null) {
          return serverName_;
        } else {
          return serverNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          serverName_ = value;
          onChanged();
        } else {
          serverNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (serverNameBuilder_ == null) {
          serverName_ = builderForValue.build();
          onChanged();
        } else {
          serverNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder mergeServerName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              serverName_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            serverName_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.newBuilder(serverName_).mergeFrom(value).buildPartial();
          } else {
            serverName_ = value;
          }
          onChanged();
        } else {
          serverNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder clearServerName() {
        if (serverNameBuilder_ == null) {
          serverName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
          onChanged();
        } else {
          serverNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder getServerNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getServerNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
        if (serverNameBuilder_ != null) {
          return serverNameBuilder_.getMessageOrBuilder();
        } else {
          return serverName_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getServerNameFieldBuilder() {
        if (serverNameBuilder_ == null) {
          serverNameBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  serverName_,
                  getParentForChildren(),
                  isClean());
          serverName_ = null;
        }
        return serverNameBuilder_;
      }

      // optional bool distributed_log_replay = 2;
      private boolean distributedLogReplay_ ;
      /**
       * <code>optional bool distributed_log_replay = 2;</code>
       */
      public boolean hasDistributedLogReplay() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bool distributed_log_replay = 2;</code>
       */
      public boolean getDistributedLogReplay() {
        return distributedLogReplay_;
      }
      /**
       * <code>optional bool distributed_log_replay = 2;</code>
       */
      public Builder setDistributedLogReplay(boolean value) {
        bitField0_ |= 0x00000002;
        distributedLogReplay_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool distributed_log_replay = 2;</code>
       */
      public Builder clearDistributedLogReplay() {
        bitField0_ = (bitField0_ & ~0x00000002);
        distributedLogReplay_ = false;
        onChanged();
        return this;
      }

      // repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionsOnCrashedServer_ =
        java.util.Collections.emptyList();
      private void ensureRegionsOnCrashedServerIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          regionsOnCrashedServer_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>(regionsOnCrashedServer_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionsOnCrashedServerBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionsOnCrashedServerList() {
        if (regionsOnCrashedServerBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
        } else {
          return regionsOnCrashedServerBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public int getRegionsOnCrashedServerCount() {
        if (regionsOnCrashedServerBuilder_ == null) {
          return regionsOnCrashedServer_.size();
        } else {
          return regionsOnCrashedServerBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionsOnCrashedServer(int index) {
        if (regionsOnCrashedServerBuilder_ == null) {
          return regionsOnCrashedServer_.get(index);
        } else {
          return regionsOnCrashedServerBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder setRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.set(index, value);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder setRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(value);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(index, value);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(builderForValue.build());
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addAllRegionsOnCrashedServer(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          super.addAll(values, regionsOnCrashedServer_);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder clearRegionsOnCrashedServer() {
        if (regionsOnCrashedServerBuilder_ == null) {
          regionsOnCrashedServer_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder removeRegionsOnCrashedServer(int index) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.remove(index);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionsOnCrashedServerBuilder(
          int index) {
        return getRegionsOnCrashedServerFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsOnCrashedServerOrBuilder(
          int index) {
        if (regionsOnCrashedServerBuilder_ == null) {
          return regionsOnCrashedServer_.get(index);  } else {
          return regionsOnCrashedServerBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionsOnCrashedServerOrBuilderList() {
        if (regionsOnCrashedServerBuilder_ != null) {
          return regionsOnCrashedServerBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsOnCrashedServerBuilder() {
        return getRegionsOnCrashedServerFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsOnCrashedServerBuilder(
          int index) {
        return getRegionsOnCrashedServerFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionsOnCrashedServerBuilderList() {
        return getRegionsOnCrashedServerFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionsOnCrashedServerFieldBuilder() {
        if (regionsOnCrashedServerBuilder_ == null) {
          regionsOnCrashedServerBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionsOnCrashedServer_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          regionsOnCrashedServer_ = null;
        }
        return regionsOnCrashedServerBuilder_;
      }

      // repeated .hbase.pb.RegionInfo regions_assigned = 4;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionsAssigned_ =
        java.util.Collections.emptyList();
      private void ensureRegionsAssignedIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          regionsAssigned_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>(regionsAssigned_);
          bitField0_ |= 0x00000008;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionsAssignedBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionsAssignedList() {
        if (regionsAssignedBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionsAssigned_);
        } else {
          return regionsAssignedBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public int getRegionsAssignedCount() {
        if (regionsAssignedBuilder_ == null) {
          return regionsAssigned_.size();
        } else {
          return regionsAssignedBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionsAssigned(int index) {
        if (regionsAssignedBuilder_ == null) {
          return regionsAssigned_.get(index);
        } else {
          return regionsAssignedBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder setRegionsAssigned(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsAssignedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.set(index, value);
          onChanged();
        } else {
          regionsAssignedBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder setRegionsAssigned(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionsAssignedBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsAssignedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(value);
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsAssignedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(index, value);
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(builderForValue.build());
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addAllRegionsAssigned(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          super.addAll(values, regionsAssigned_);
          onChanged();
        } else {
          regionsAssignedBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder clearRegionsAssigned() {
        if (regionsAssignedBuilder_ == null) {
          regionsAssigned_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          regionsAssignedBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder removeRegionsAssigned(int index) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.remove(index);
          onChanged();
        } else {
          regionsAssignedBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionsAssignedBuilder(
          int index) {
        return getRegionsAssignedFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsAssignedOrBuilder(
          int index) {
        if (regionsAssignedBuilder_ == null) {
          return regionsAssigned_.get(index);  } else {
          return regionsAssignedBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionsAssignedOrBuilderList() {
        if (regionsAssignedBuilder_ != null) {
          return regionsAssignedBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionsAssigned_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsAssignedBuilder() {
        return getRegionsAssignedFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsAssignedBuilder(
          int index) {
        return getRegionsAssignedFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionsAssignedBuilderList() {
        return getRegionsAssignedFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionsAssignedFieldBuilder() {
        if (regionsAssignedBuilder_ == null) {
          regionsAssignedBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionsAssigned_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          regionsAssigned_ = null;
        }
        return regionsAssignedBuilder_;
      }

      // optional bool carrying_meta = 5;
      private boolean carryingMeta_ ;
      /**
       * <code>optional bool carrying_meta = 5;</code>
       */
      public boolean hasCarryingMeta() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional bool carrying_meta = 5;</code>
       */
      public boolean getCarryingMeta() {
        return carryingMeta_;
      }
      /**
       * <code>optional bool carrying_meta = 5;</code>
       */
      public Builder setCarryingMeta(boolean value) {
        bitField0_ |= 0x00000010;
        carryingMeta_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool carrying_meta = 5;</code>
       */
      public Builder clearCarryingMeta() {
        bitField0_ = (bitField0_ & ~0x00000010);
        carryingMeta_ = false;
        onChanged();
        return this;
      }

      // optional bool should_split_wal = 6 [default = true];
      private boolean shouldSplitWal_ = true;
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       */
      public boolean hasShouldSplitWal() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       */
      public boolean getShouldSplitWal() {
        return shouldSplitWal_;
      }
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       */
      public Builder setShouldSplitWal(boolean value) {
        bitField0_ |= 0x00000020;
        shouldSplitWal_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       */
      public Builder clearShouldSplitWal() {
        bitField0_ = (bitField0_ & ~0x00000020);
        shouldSplitWal_ = true;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.ServerCrashStateData)
    }

    static {
      defaultInstance = new ServerCrashStateData(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ServerCrashStateData)
  }

  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CreateTableStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyTableStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_TruncateTableStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DeleteTableStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_AddColumnFamilyStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_AddColumnFamilyStateData_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyColumnFamilyStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_ModifyColumnFamilyStateData_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DeleteColumnFamilyStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_DeleteColumnFamilyStateData_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_EnableTableStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DisableTableStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ServerCrashStateData_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\025MasterProcedure.proto\022\010hbase.pb\032\013HBase" +
      ".proto\032\tRPC.proto\"\234\001\n\024CreateTableStateDa" +
      "ta\022,\n\tuser_info\030\001 \002(\0132\031.hbase.pb.UserInf" +
      "ormation\022+\n\014table_schema\030\002 \002(\0132\025.hbase.p" +
      "b.TableSchema\022)\n\013region_info\030\003 \003(\0132\024.hba" +
      "se.pb.RegionInfo\"\332\001\n\024ModifyTableStateDat" +
      "a\022,\n\tuser_info\030\001 \002(\0132\031.hbase.pb.UserInfo" +
      "rmation\0226\n\027unmodified_table_schema\030\002 \001(\013" +
      "2\025.hbase.pb.TableSchema\0224\n\025modified_tabl" +
      "e_schema\030\003 \002(\0132\025.hbase.pb.TableSchema\022&\n",
      "\036delete_column_family_in_modify\030\004 \002(\010\"\340\001" +
      "\n\026TruncateTableStateData\022,\n\tuser_info\030\001 " +
      "\002(\0132\031.hbase.pb.UserInformation\022\027\n\017preser" +
      "ve_splits\030\002 \002(\010\022\'\n\ntable_name\030\003 \001(\0132\023.hb" +
      "ase.pb.TableName\022+\n\014table_schema\030\004 \001(\0132\025" +
      ".hbase.pb.TableSchema\022)\n\013region_info\030\005 \003" +
      "(\0132\024.hbase.pb.RegionInfo\"\230\001\n\024DeleteTable" +
      "StateData\022,\n\tuser_info\030\001 \002(\0132\031.hbase.pb." +
      "UserInformation\022\'\n\ntable_name\030\002 \002(\0132\023.hb" +
      "ase.pb.TableName\022)\n\013region_info\030\003 \003(\0132\024.",
      "hbase.pb.RegionInfo\"W\n\030CreateNamespaceSt" +
      "ateData\022;\n\024namespace_descriptor\030\001 \002(\0132\035." +
      "hbase.pb.NamespaceDescriptor\"\237\001\n\030ModifyN" +
      "amespaceStateData\022;\n\024namespace_descripto" +
      "r\030\001 \002(\0132\035.hbase.pb.NamespaceDescriptor\022F" +
      "\n\037unmodified_namespace_descriptor\030\002 \001(\0132" +
      "\035.hbase.pb.NamespaceDescriptor\"o\n\030Delete" +
      "NamespaceStateData\022\026\n\016namespace_name\030\001 \002" +
      "(\t\022;\n\024namespace_descriptor\030\002 \001(\0132\035.hbase" +
      ".pb.NamespaceDescriptor\"\344\001\n\030AddColumnFam",
      "ilyStateData\022,\n\tuser_info\030\001 \002(\0132\031.hbase." +
      "pb.UserInformation\022\'\n\ntable_name\030\002 \002(\0132\023" +
      ".hbase.pb.TableName\0229\n\023columnfamily_sche" +
      "ma\030\003 \002(\0132\034.hbase.pb.ColumnFamilySchema\0226" +
      "\n\027unmodified_table_schema\030\004 \001(\0132\025.hbase." +
      "pb.TableSchema\"\347\001\n\033ModifyColumnFamilySta" +
      "teData\022,\n\tuser_info\030\001 \002(\0132\031.hbase.pb.Use" +
      "rInformation\022\'\n\ntable_name\030\002 \002(\0132\023.hbase" +
      ".pb.TableName\0229\n\023columnfamily_schema\030\003 \002" +
      "(\0132\034.hbase.pb.ColumnFamilySchema\0226\n\027unmo",
      "dified_table_schema\030\004 \001(\0132\025.hbase.pb.Tab" +
      "leSchema\"\307\001\n\033DeleteColumnFamilyStateData" +
      "\022,\n\tuser_info\030\001 \002(\0132\031.hbase.pb.UserInfor" +
      "mation\022\'\n\ntable_name\030\002 \002(\0132\023.hbase.pb.Ta" +
      "bleName\022\031\n\021columnfamily_name\030\003 \002(\014\0226\n\027un" +
      "modified_table_schema\030\004 \001(\0132\025.hbase.pb.T" +
      "ableSchema\"\215\001\n\024EnableTableStateData\022,\n\tu" +
      "ser_info\030\001 \002(\0132\031.hbase.pb.UserInformatio" +
      "n\022\'\n\ntable_name\030\002 \002(\0132\023.hbase.pb.TableNa" +
      "me\022\036\n\026skip_table_state_check\030\003 \002(\010\"\216\001\n\025D",
      "isableTableStateData\022,\n\tuser_info\030\001 \002(\0132" +
      "\031.hbase.pb.UserInformation\022\'\n\ntable_name" +
      "\030\002 \002(\0132\023.hbase.pb.TableName\022\036\n\026skip_tabl" +
      "e_state_check\030\003 \002(\010\"\201\002\n\024ServerCrashState" +
      "Data\022)\n\013server_name\030\001 \002(\0132\024.hbase.pb.Ser" +
      "verName\022\036\n\026distributed_log_replay\030\002 \001(\010\022" +
      "7\n\031regions_on_crashed_server\030\003 \003(\0132\024.hba" +
      "se.pb.RegionInfo\022.\n\020regions_assigned\030\004 \003" +
      "(\0132\024.hbase.pb.RegionInfo\022\025\n\rcarrying_met" +
      "a\030\005 \001(\010\022\036\n\020should_split_wal\030\006 \001(\010:\004true*",
      "\330\001\n\020CreateTableState\022\036\n\032CREATE_TABLE_PRE" +
      "_OPERATION\020\001\022 \n\034CREATE_TABLE_WRITE_FS_LA" +
      "YOUT\020\002\022\034\n\030CREATE_TABLE_ADD_TO_META\020\003\022\037\n\033" +
      "CREATE_TABLE_ASSIGN_REGIONS\020\004\022\"\n\036CREATE_" +
      "TABLE_UPDATE_DESC_CACHE\020\005\022\037\n\033CREATE_TABL" +
      "E_POST_OPERATION\020\006*\207\002\n\020ModifyTableState\022" +
      "\030\n\024MODIFY_TABLE_PREPARE\020\001\022\036\n\032MODIFY_TABL" +
      "E_PRE_OPERATION\020\002\022(\n$MODIFY_TABLE_UPDATE" +
      "_TABLE_DESCRIPTOR\020\003\022&\n\"MODIFY_TABLE_REMO" +
      "VE_REPLICA_COLUMN\020\004\022!\n\035MODIFY_TABLE_DELE",
      "TE_FS_LAYOUT\020\005\022\037\n\033MODIFY_TABLE_POST_OPER" +
      "ATION\020\006\022#\n\037MODIFY_TABLE_REOPEN_ALL_REGIO" +
      "NS\020\007*\212\002\n\022TruncateTableState\022 \n\034TRUNCATE_" +
      "TABLE_PRE_OPERATION\020\001\022#\n\037TRUNCATE_TABLE_" +
      "REMOVE_FROM_META\020\002\022\"\n\036TRUNCATE_TABLE_CLE" +
      "AR_FS_LAYOUT\020\003\022#\n\037TRUNCATE_TABLE_CREATE_" +
      "FS_LAYOUT\020\004\022\036\n\032TRUNCATE_TABLE_ADD_TO_MET" +
      "A\020\005\022!\n\035TRUNCATE_TABLE_ASSIGN_REGIONS\020\006\022!" +
      "\n\035TRUNCATE_TABLE_POST_OPERATION\020\007*\337\001\n\020De" +
      "leteTableState\022\036\n\032DELETE_TABLE_PRE_OPERA",
      "TION\020\001\022!\n\035DELETE_TABLE_REMOVE_FROM_META\020" +
      "\002\022 \n\034DELETE_TABLE_CLEAR_FS_LAYOUT\020\003\022\"\n\036D" +
      "ELETE_TABLE_UPDATE_DESC_CACHE\020\004\022!\n\035DELET" +
      "E_TABLE_UNASSIGN_REGIONS\020\005\022\037\n\033DELETE_TAB" +
      "LE_POST_OPERATION\020\006*\320\001\n\024CreateNamespaceS" +
      "tate\022\034\n\030CREATE_NAMESPACE_PREPARE\020\001\022%\n!CR" +
      "EATE_NAMESPACE_CREATE_DIRECTORY\020\002\022)\n%CRE" +
      "ATE_NAMESPACE_INSERT_INTO_NS_TABLE\020\003\022\036\n\032" +
      "CREATE_NAMESPACE_UPDATE_ZK\020\004\022(\n$CREATE_N" +
      "AMESPACE_SET_NAMESPACE_QUOTA\020\005*z\n\024Modify",
      "NamespaceState\022\034\n\030MODIFY_NAMESPACE_PREPA" +
      "RE\020\001\022$\n MODIFY_NAMESPACE_UPDATE_NS_TABLE" +
      "\020\002\022\036\n\032MODIFY_NAMESPACE_UPDATE_ZK\020\003*\332\001\n\024D" +
      "eleteNamespaceState\022\034\n\030DELETE_NAMESPACE_" +
      "PREPARE\020\001\022)\n%DELETE_NAMESPACE_DELETE_FRO" +
      "M_NS_TABLE\020\002\022#\n\037DELETE_NAMESPACE_REMOVE_" +
      "FROM_ZK\020\003\022\'\n#DELETE_NAMESPACE_DELETE_DIR" +
      "ECTORIES\020\004\022+\n\'DELETE_NAMESPACE_REMOVE_NA" +
      "MESPACE_QUOTA\020\005*\331\001\n\024AddColumnFamilyState" +
      "\022\035\n\031ADD_COLUMN_FAMILY_PREPARE\020\001\022#\n\037ADD_C",
      "OLUMN_FAMILY_PRE_OPERATION\020\002\022-\n)ADD_COLU" +
      "MN_FAMILY_UPDATE_TABLE_DESCRIPTOR\020\003\022$\n A" +
      "DD_COLUMN_FAMILY_POST_OPERATION\020\004\022(\n$ADD" +
      "_COLUMN_FAMILY_REOPEN_ALL_REGIONS\020\005*\353\001\n\027" +
      "ModifyColumnFamilyState\022 \n\034MODIFY_COLUMN" +
      "_FAMILY_PREPARE\020\001\022&\n\"MODIFY_COLUMN_FAMIL" +
      "Y_PRE_OPERATION\020\002\0220\n,MODIFY_COLUMN_FAMIL" +
      "Y_UPDATE_TABLE_DESCRIPTOR\020\003\022\'\n#MODIFY_CO" +
      "LUMN_FAMILY_POST_OPERATION\020\004\022+\n\'MODIFY_C" +
      "OLUMN_FAMILY_REOPEN_ALL_REGIONS\020\005*\226\002\n\027De",
      "leteColumnFamilyState\022 \n\034DELETE_COLUMN_F" +
      "AMILY_PREPARE\020\001\022&\n\"DELETE_COLUMN_FAMILY_" +
      "PRE_OPERATION\020\002\0220\n,DELETE_COLUMN_FAMILY_" +
      "UPDATE_TABLE_DESCRIPTOR\020\003\022)\n%DELETE_COLU" +
      "MN_FAMILY_DELETE_FS_LAYOUT\020\004\022\'\n#DELETE_C" +
      "OLUMN_FAMILY_POST_OPERATION\020\005\022+\n\'DELETE_" +
      "COLUMN_FAMILY_REOPEN_ALL_REGIONS\020\006*\350\001\n\020E" +
      "nableTableState\022\030\n\024ENABLE_TABLE_PREPARE\020" +
      "\001\022\036\n\032ENABLE_TABLE_PRE_OPERATION\020\002\022)\n%ENA" +
      "BLE_TABLE_SET_ENABLING_TABLE_STATE\020\003\022$\n ",
      "ENABLE_TABLE_MARK_REGIONS_ONLINE\020\004\022(\n$EN" +
      "ABLE_TABLE_SET_ENABLED_TABLE_STATE\020\005\022\037\n\033" +
      "ENABLE_TABLE_POST_OPERATION\020\006*\362\001\n\021Disabl" +
      "eTableState\022\031\n\025DISABLE_TABLE_PREPARE\020\001\022\037" +
      "\n\033DISABLE_TABLE_PRE_OPERATION\020\002\022+\n\'DISAB" +
      "LE_TABLE_SET_DISABLING_TABLE_STATE\020\003\022&\n\"" +
      "DISABLE_TABLE_MARK_REGIONS_OFFLINE\020\004\022*\n&" +
      "DISABLE_TABLE_SET_DISABLED_TABLE_STATE\020\005" +
      "\022 \n\034DISABLE_TABLE_POST_OPERATION\020\006*\234\002\n\020S" +
      "erverCrashState\022\026\n\022SERVER_CRASH_START\020\001\022",
      "\035\n\031SERVER_CRASH_PROCESS_META\020\002\022\034\n\030SERVER" +
      "_CRASH_GET_REGIONS\020\003\022\036\n\032SERVER_CRASH_NO_" +
      "SPLIT_LOGS\020\004\022\033\n\027SERVER_CRASH_SPLIT_LOGS\020" +
      "\005\022#\n\037SERVER_CRASH_PREPARE_LOG_REPLAY\020\006\022\027" +
      "\n\023SERVER_CRASH_ASSIGN\020\010\022\037\n\033SERVER_CRASH_" +
      "WAIT_ON_ASSIGN\020\t\022\027\n\023SERVER_CRASH_FINISH\020" +
      "dBK\n*org.apache.hadoop.hbase.protobuf.ge" +
      "neratedB\025MasterProcedureProtosH\001\210\001\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_hbase_pb_CreateTableStateData_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_CreateTableStateData_descriptor,
              new java.lang.String[] { "UserInfo", "TableSchema", "RegionInfo", });
          internal_static_hbase_pb_ModifyTableStateData_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_ModifyTableStateData_descriptor,
              new java.lang.String[] { "UserInfo", "UnmodifiedTableSchema", "ModifiedTableSchema", "DeleteColumnFamilyInModify", });
          internal_static_hbase_pb_TruncateTableStateData_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_TruncateTableStateData_descriptor,
              new java.lang.String[] { "UserInfo", "PreserveSplits", "TableName", "TableSchema", "RegionInfo", });
          internal_static_hbase_pb_DeleteTableStateData_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_DeleteTableStateData_descriptor,
              new java.lang.String[] { "UserInfo", "TableName", "RegionInfo", });
          internal_static_hbase_pb_CreateNamespaceStateData_descriptor =
            getDescriptor().getMessageTypes().get(4);
          internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_CreateNamespaceStateData_descriptor,
              new java.lang.String[] { "NamespaceDescriptor", });
          internal_static_hbase_pb_ModifyNamespaceStateData_descriptor =
            getDescriptor().getMessageTypes().get(5);
          internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_ModifyNamespaceStateData_descriptor,
              new java.lang.String[] { "NamespaceDescriptor", "UnmodifiedNamespaceDescriptor", });
          internal_static_hbase_pb_DeleteNamespaceStateData_descriptor =
            getDescriptor().getMessageTypes().get(6);
          internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_DeleteNamespaceStateData_descriptor,
              new java.lang.String[] { "NamespaceName", "NamespaceDescriptor", });
          internal_static_hbase_pb_AddColumnFamilyStateData_descriptor =
            getDescriptor().getMessageTypes().get(7);
          internal_static_hbase_pb_AddColumnFamilyStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_AddColumnFamilyStateData_descriptor,
              new java.lang.String[] { "UserInfo", "TableName", "ColumnfamilySchema", "UnmodifiedTableSchema", });
          internal_static_hbase_pb_ModifyColumnFamilyStateData_descriptor =
            getDescriptor().getMessageTypes().get(8);
          internal_static_hbase_pb_ModifyColumnFamilyStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_ModifyColumnFamilyStateData_descriptor,
              new java.lang.String[] { "UserInfo", "TableName", "ColumnfamilySchema", "UnmodifiedTableSchema", });
          internal_static_hbase_pb_DeleteColumnFamilyStateData_descriptor =
            getDescriptor().getMessageTypes().get(9);
          internal_static_hbase_pb_DeleteColumnFamilyStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_DeleteColumnFamilyStateData_descriptor,
              new java.lang.String[] { "UserInfo", "TableName", "ColumnfamilyName", "UnmodifiedTableSchema", });
          internal_static_hbase_pb_EnableTableStateData_descriptor =
            getDescriptor().getMessageTypes().get(10);
          internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_EnableTableStateData_descriptor,
              new java.lang.String[] { "UserInfo", "TableName", "SkipTableStateCheck", });
          internal_static_hbase_pb_DisableTableStateData_descriptor =
            getDescriptor().getMessageTypes().get(11);
          internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_DisableTableStateData_descriptor,
              new java.lang.String[] { "UserInfo", "TableName", "SkipTableStateCheck", });
          internal_static_hbase_pb_ServerCrashStateData_descriptor =
            getDescriptor().getMessageTypes().get(12);
          internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_ServerCrashStateData_descriptor,
              new java.lang.String[] { "ServerName", "DistributedLogReplay", "RegionsOnCrashedServer", "RegionsAssigned", "CarryingMeta", "ShouldSplitWal", });
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.getDescriptor(),
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.getDescriptor(),
        }, assigner);
  }

  // @@protoc_insertion_point(outer_class_scope)
}
