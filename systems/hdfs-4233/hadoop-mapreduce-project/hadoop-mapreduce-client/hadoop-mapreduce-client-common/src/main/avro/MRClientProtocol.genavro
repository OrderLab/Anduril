@namespace("org.apache.hadoop.mapreduce.v2.api")
protocol MRClientProtocol {

  import idl "./yarn/yarn-api/src/main/avro/yarn-types.genavro";

  enum TaskType {
    MAP,
    REDUCE
  }

  record JobID {
    org.apache.hadoop.yarn.ApplicationID appID;
    int id;
  }

  record TaskID {
    JobID jobID;
    TaskType taskType;
    int id;
  }

  record TaskAttemptID {
    TaskID taskID; 
    int id;
  }

  enum TaskState {
    NEW,
    SCHEDULED,
    RUNNING,
    SUCCEEDED,
    FAILED,
    KILL_WAIT,
    KILLED
  }

  enum Phase {
    STARTING,
    MAP,
    SHUFFLE,
    SORT,
    REDUCE,
    CLEANUP
  }

  record Counter {
    string name;
    string displayName;
    long value; 
  }

  record CounterGroup {
    string name;
    string displayname;
    map<Counter> counters;
  }

  record Counters {
    map<CounterGroup> groups;
  }

  record TaskReport {
    TaskID id;
    TaskState state;
    float progress;
    long startTime;
    long finishTime;
    Counters counters;
    array<TaskAttemptID> runningAttempts;
    union{TaskAttemptID, null} successfulAttempt;
    array<string> diagnostics;
  }

  enum TaskAttemptState {
    NEW,
    UNASSIGNED,
    ASSIGNED,
    RUNNING,
    COMMIT_PENDING,
    SUCCESS_CONTAINER_CLEANUP,
    SUCCEEDED,
    FAIL_CONTAINER_CLEANUP,
    FAIL_TASK_CLEANUP,
    FAILED,
    KILL_CONTAINER_CLEANUP,
    KILL_TASK_CLEANUP,
    KILLED
  }

  record TaskAttemptReport {
    TaskAttemptID id;
    TaskAttemptState state;
    float progress;
    long startTime;
    long finishTime;
    Counters counters;
    string diagnosticInfo;
    string stateString;
    Phase phase;
  }

  enum JobState {
    NEW,
    INITED,
    RUNNING,
    SUCCEEDED,
    FAILED,
    KILL_WAIT,
    KILLED,
    ERROR
  }

  record JobReport {
    JobID id;
    JobState state;
    float mapProgress;
    float reduceProgress;
    float cleanupProgress;
    float setupProgress;
    long startTime;
    long finishTime;
  }

  enum TaskAttemptCompletionEventStatus {
    FAILED,
    KILLED,
    SUCCEEDED,
    OBSOLETE,
    TIPFAILED
  }

  record TaskAttemptCompletionEvent {
    TaskAttemptID attemptId;
    TaskAttemptCompletionEventStatus status;
    string mapOutputServerAddress;
    int attemptRunTime;
    int eventId;
  }

  JobReport getJobReport(JobID jobID) throws org.apache.hadoop.yarn.YarnRemoteException;
  TaskReport getTaskReport(TaskID taskID) throws org.apache.hadoop.yarn.YarnRemoteException;
  TaskAttemptReport getTaskAttemptReport(TaskAttemptID taskAttemptID) throws org.apache.hadoop.yarn.YarnRemoteException;
  Counters getCounters(JobID jobID) throws org.apache.hadoop.yarn.YarnRemoteException;
  array<TaskAttemptCompletionEvent> getTaskAttemptCompletionEvents(JobID jobID, int fromEventId, int maxEvents) throws org.apache.hadoop.yarn.YarnRemoteException;
  array<TaskReport> getTaskReports(JobID jobID, TaskType taskType) throws org.apache.hadoop.yarn.YarnRemoteException;
  array<string> getDiagnostics(TaskAttemptID taskAttemptID) throws org.apache.hadoop.yarn.YarnRemoteException;

  void killJob(JobID jobID) throws org.apache.hadoop.yarn.YarnRemoteException;
  void killTask(TaskID taskID) throws org.apache.hadoop.yarn.YarnRemoteException;
  void killTaskAttempt(TaskAttemptID taskAttemptID) throws org.apache.hadoop.yarn.YarnRemoteException;
  void failTaskAttempt(TaskAttemptID taskAttemptID) throws org.apache.hadoop.yarn.YarnRemoteException;

}
